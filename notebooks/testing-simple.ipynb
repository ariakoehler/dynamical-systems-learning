{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 1,
>>>>>>> 307a442a64d2901942c37942dd13ef724eca32d1
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "device = 'cpu'\n",
    "from torchdiffeq import odeint"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 2,
>>>>>>> 307a442a64d2901942c37942dd13ef724eca32d1
   "metadata": {},
   "outputs": [],
   "source": [
    "def FN_torch(t, V, a=0.2, b=0.2, c=3.0):\n",
    "    return torch.hstack((c * (V[0] - V[0]**3/3 + V[1]), -1/c * (V[0] - a + b*V[1])))\n",
    "\n",
    "def FN_torch_modified(t, V, eta, a=0.2, b=0.2, c=3.0):\n",
    "    V1 = c * (V[0] - V[0]**3/3 + V[1])\n",
    "    V2 = -1/c * (V[0] - a + b*V[1])\n",
    "    dV = torch.hstack((V1, V2))\n",
    "    terms = torch.tensor([V[0]**2, V[1]**2])\n",
    "    dV += torch.matmul(eta, terms)\n",
    "    return dV\n",
    "\n",
    "def FN_torch_vec(t, V, eta, a=0.2, b=0.2, c=3.0):\n",
    "    V1 = c * (V[:,0] - V[:,0]**3/3 + V[:,1])\n",
    "    V2 = -1/c * (V[:,0] - a + b*V[:,1])\n",
    "    dV = torch.vstack((V1, V2))\n",
    "    terms = torch.vstack([V[:,0]**2, V[:,1]**2])\n",
    "    m = torch.matmul(eta, terms)\n",
    "    dV = dV + m\n",
    "#     print(dV.shape)\n",
    "    return dV.T\n",
    "\n",
    "def FN_torch_modified_large(t, V, eta, a=0.2, b=0.2, c=3.0):\n",
    "    V1 = c * (V[0] - V[0]**3/3 + V[1])\n",
    "    V2 = -1/c * (V[0] - a + b*V[1])\n",
    "    dV = torch.hstack((V1, V2))\n",
    "    terms = torch.tensor([V[0]**2, V[1]**2, V[0]*V[1], V[0]**2*V[1], V[0]*V[1]**2, torch.exp(V[0]), torch.exp(V[1]), V[0]**4, V[0]**3*V[1], V[0]**2*V[1]**2, V[0]*V[1]**3, V[1]**4])\n",
    "    dV += torch.matmul(eta, terms)\n",
    "    return dV "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from Matt Levine's GitHub at https://github.com/mattlevine22/contRNN\n",
    "def L63_torch(t, S, sigma=10.0, rho=28.0, beta=8.0/3):\n",
    "    \"\"\" Lorenz-63 dynamical model implemented for torch. \"\"\"\n",
    "    x_1 = sigma*(S[1]-S[0])\n",
    "    x_2 = S[0]*(rho-S[2])-S[1]\n",
    "    x_3 = S[0]*S[1] - beta*S[2]\n",
    "    dS  = torch.hstack((x_1,x_2,x_3))\n",
    "    return dS\n",
    "\n",
    "def L63_torch_modified(t, S, eta, sigma=10.0, rho=28.0, beta=8.0/3):\n",
    "    \"\"\" Lorenz-63 dynamical model with added terms implemented for torch. \"\"\"\n",
    "    x_1 = sigma*(S[1]-S[0])\n",
    "    x_2 = S[0]*(rho-S[2])-S[1]\n",
    "    x_3 = S[0]*S[1] - beta*S[2]\n",
    "    dS  = torch.hstack((x_1,x_2,x_3))\n",
    "    terms = torch.tensor([S[1]*S[2], S[0]**2])\n",
    "    dS += torch.matmul(eta, terms)\n",
    "    return dS"
=======
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(t, x_true, optfitz, batched=False):\n",
    "#     print(optfitz.forward(t, x_true)[:,:].shape)\n",
    "    if not batched:\n",
    "        return optfitz.forward(t, x_true)[:-1,:]\n",
    "    else:\n",
    "        return optfitz.forward(t, x_true)"
>>>>>>> 307a442a64d2901942c37942dd13ef724eca32d1
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 87,
=======
   "execution_count": 29,
>>>>>>> 307a442a64d2901942c37942dd13ef724eca32d1
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffLoss(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(DiffLoss, self).__init__()\n",
    "        \n",
    "    def forward(self, a, b):\n",
    "        \n",
    "        a_diff = torch.diff(a, axis=0)\n",
    "        b_diff = torch.diff(b, axis=0)\n",
    "        \n",
    "        return torch.mean((a_diff - b_diff)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizeFitzhugh(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, x0, t_space, n_terms, eta0):\n",
    "        super(OptimizeFitzhugh, self).__init__()\n",
    "        self.x0 = x0\n",
    "        self.t_space = t_space\n",
    "        self.n_terms = n_terms\n",
    "        self.eta = eta0\n",
    "        self.eta.requires_grad_()\n",
    "        \n",
    "    def rhs(self, x, t):\n",
    "        return FN_torch_vec(t, x, self.eta)\n",
    "    \n",
    "    def forward(self, t, x):\n",
    "        return self.rhs(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1387, -0.1398],\n",
      "        [ 0.0626, -0.0873]])\n",
      "eta_0 = \n",
      "[[-0.1387 -0.1398]\n",
      " [ 0.0626 -0.0873]]\n",
      "\n",
      "Iterarion 1\n",
      "eta = \n",
      "[[-0.1387 -0.1398]\n",
      " [ 0.0626 -0.0873]]\n",
      "loss = 1.9105\n",
      "\n",
      "\n",
      "tensor([[-3.0850, -0.2739],\n",
      "        [ 0.0499, -0.0130]])\n",
      "Iterarion 2\n",
      "eta = \n",
      "[[-0.1287 -0.1298]\n",
      " [ 0.0526 -0.0773]]\n",
      "loss = 1.8705\n",
      "\n",
      "\n",
      "tensor([[-3.1295, -0.2389],\n",
      "        [-0.0667, -0.0187]])\n",
      "Iterarion 3\n",
      "eta = \n",
      "[[-0.1187 -0.1199]\n",
      " [ 0.0545 -0.0674]]\n",
      "loss = 1.9386\n",
      "\n",
      "\n",
      "tensor([[-3.0793, -0.2281],\n",
      "        [-0.1026, -0.0227]])\n",
      "Iterarion 4\n",
      "eta = \n",
      "[[-0.1087 -0.11  ]\n",
      " [ 0.0605 -0.0574]]\n",
      "loss = 1.9460\n",
      "\n",
      "\n",
      "tensor([[-3.0171, -0.2233],\n",
      "        [-0.0139, -0.0095]])\n",
      "Iterarion 5\n",
      "eta = \n",
      "[[-0.0987 -0.1001]\n",
      " [ 0.0659 -0.048 ]]\n",
      "loss = 1.8183\n",
      "\n",
      "\n",
      "tensor([[-2.8238, -0.2470],\n",
      "        [ 0.1002,  0.0063]])\n",
      "Iterarion 6\n",
      "eta = \n",
      "[[-0.0888 -0.0902]\n",
      " [ 0.0663 -0.0411]]\n",
      "loss = 1.8360\n",
      "\n",
      "\n",
      "tensor([[-2.5076e+00, -1.7519e-01],\n",
      "        [ 8.6366e-02, -2.0938e-03]])\n",
      "Iterarion 7\n",
      "eta = \n",
      "[[-0.0789 -0.0804]\n",
      " [ 0.0641 -0.0349]]\n",
      "loss = 1.7597\n",
      "\n",
      "\n",
      "tensor([[-2.5548, -0.1985],\n",
      "        [-0.0196, -0.0039]])\n",
      "Iterarion 8\n",
      "eta = \n",
      "[[-0.0691 -0.0707]\n",
      " [ 0.0628 -0.0289]]\n",
      "loss = 1.6786\n",
      "\n",
      "\n",
      "tensor([[-2.4770, -0.1632],\n",
      "        [ 0.0459,  0.0075]])\n",
      "Iterarion 9\n",
      "eta = \n",
      "[[-0.0594 -0.0612]\n",
      " [ 0.0605 -0.0249]]\n",
      "loss = 1.8606\n",
      "\n",
      "\n",
      "tensor([[-2.3688, -0.0811],\n",
      "        [ 0.0555,  0.0031]])\n",
      "Iterarion 10\n",
      "eta = \n",
      "[[-0.0497 -0.0521]\n",
      " [ 0.0572 -0.0217]]\n",
      "loss = 1.6467\n",
      "\n",
      "\n",
      "tensor([[-2.4418, -0.1380],\n",
      "        [ 0.0226,  0.0050]])\n",
      "Iterarion 11\n",
      "eta = \n",
      "[[-0.04   -0.0432]\n",
      " [ 0.0537 -0.0195]]\n",
      "loss = 1.8331\n",
      "\n",
      "\n",
      "tensor([[-2.3123, -0.1018],\n",
      "        [-0.0443, -0.0035]])\n",
      "Iterarion 12\n",
      "eta = \n",
      "[[-0.0304 -0.0346]\n",
      " [ 0.0517 -0.0172]]\n",
      "loss = 1.6493\n",
      "\n",
      "\n",
      "tensor([[-2.2638e+00, -7.8003e-02],\n",
      "        [-2.6008e-02,  8.3349e-04]])\n",
      "Iterarion 13\n",
      "eta = \n",
      "[[-0.0209 -0.0263]\n",
      " [ 0.0505 -0.0151]]\n",
      "loss = 1.5630\n",
      "\n",
      "\n",
      "tensor([[-2.1764e+00, -1.4987e-01],\n",
      "        [-1.5997e-02, -3.3016e-04]])\n",
      "Iterarion 14\n",
      "eta = \n",
      "[[-0.0114 -0.0179]\n",
      " [ 0.0498 -0.0133]]\n",
      "loss = 1.6446\n",
      "\n",
      "\n",
      "tensor([[-2.1481e+00, -1.4021e-01],\n",
      "        [-5.4824e-02,  8.1573e-04]])\n",
      "Iterarion 15\n",
      "eta = \n",
      "[[-0.002  -0.0095]\n",
      " [ 0.0504 -0.0117]]\n",
      "loss = 1.5453\n",
      "\n",
      "\n",
      "tensor([[-1.9655, -0.1105],\n",
      "        [-0.0622, -0.0029]])\n",
      "Iterarion 16\n",
      "eta = \n",
      "[[ 0.0073 -0.0013]\n",
      " [ 0.0523 -0.0099]]\n",
      "loss = 1.5745\n",
      "\n",
      "\n",
      "tensor([[-1.9538e+00, -8.9472e-02],\n",
      "        [-3.1634e-02,  1.4859e-03]])\n",
      "Iterarion 17\n",
      "eta = \n",
      "[[ 0.0165  0.0068]\n",
      " [ 0.0547 -0.0085]]\n",
      "loss = 1.6237\n",
      "\n",
      "\n",
      "tensor([[-1.8098, -0.0473],\n",
      "        [-0.0144, -0.0022]])\n",
      "Iterarion 18\n",
      "eta = \n",
      "[[ 0.0256  0.0144]\n",
      " [ 0.0571 -0.0069]]\n",
      "loss = 1.6520\n",
      "\n",
      "\n",
      "tensor([[-1.6496e+00, -1.4739e-03],\n",
      "        [-4.0377e-02, -6.5668e-04]])\n",
      "Iterarion 19\n",
      "eta = \n",
      "[[ 0.0346  0.0213]\n",
      " [ 0.0602 -0.0053]]\n",
      "loss = 1.6225\n",
      "\n",
      "\n",
      "tensor([[-1.7215, -0.0650],\n",
      "        [ 0.1147,  0.0237]])\n",
      "Iterarion 20\n",
      "eta = \n",
      "[[ 0.0434  0.028 ]\n",
      " [ 0.0604 -0.0069]]\n",
      "loss = 1.5692\n",
      "\n",
      "\n",
      "tensor([[-1.6024, -0.0109],\n",
      "        [ 0.0426,  0.0119]])\n",
      "Iterarion 21\n",
      "eta = \n",
      "[[ 0.0521  0.0342]\n",
      " [ 0.0598 -0.0096]]\n",
      "loss = 1.4390\n",
      "\n",
      "\n",
      "tensor([[-1.5187, -0.0238],\n",
      "        [ 0.1194,  0.0107]])\n",
      "Iterarion 22\n",
      "eta = \n",
      "[[ 0.0607  0.04  ]\n",
      " [ 0.0572 -0.0133]]\n",
      "loss = 1.4928\n",
      "\n",
      "\n",
      "tensor([[-1.5231, -0.0074],\n",
      "        [ 0.0089,  0.0018]])\n",
      "Iterarion 23\n",
      "eta = \n",
      "[[ 0.0691  0.0454]\n",
      " [ 0.0547 -0.0168]]\n",
      "loss = 1.5765\n",
      "\n",
      "\n",
      "tensor([[-1.5182e+00,  1.0392e-02],\n",
      "        [-4.9075e-02,  1.2628e-03]])\n",
      "Iterarion 24\n",
      "eta = \n",
      "[[ 0.0775  0.0502]\n",
      " [ 0.0533 -0.0201]]\n",
      "loss = 1.4728\n",
      "\n",
      "\n",
      "tensor([[-1.4254,  0.0240],\n",
      "        [-0.0157,  0.0017]])\n",
      "Iterarion 25\n",
      "eta = \n",
      "[[ 0.0857  0.0544]\n",
      " [ 0.0523 -0.0234]]\n",
      "loss = 1.5305\n",
      "\n",
      "\n",
      "tensor([[-1.3250, -0.0315],\n",
      "        [-0.0059,  0.0027]])\n",
      "Iterarion 26\n",
      "eta = \n",
      "[[ 0.0938  0.0584]\n",
      " [ 0.0515 -0.0266]]\n",
      "loss = 1.5509\n",
      "\n",
      "\n",
      "tensor([[-1.1904,  0.0702],\n",
      "        [-0.0708, -0.0048]])\n",
      "Iterarion 27\n",
      "eta = \n",
      "[[ 0.1016  0.0615]\n",
      " [ 0.0521 -0.029 ]]\n",
      "loss = 1.4208\n",
      "\n",
      "\n",
      "tensor([[-1.1789,  0.0484],\n",
      "        [-0.1009, -0.0166]])\n",
      "Iterarion 28\n",
      "eta = \n",
      "[[ 0.1094  0.064 ]\n",
      " [ 0.0543 -0.0292]]\n",
      "loss = 1.4049\n",
      "\n",
      "\n",
      "tensor([[-1.0956,  0.0392],\n",
      "        [-0.0515, -0.0069]])\n",
      "Iterarion 29\n",
      "eta = \n",
      "[[ 0.1169  0.0659]\n",
      " [ 0.0572 -0.0286]]\n",
      "loss = 1.5004\n",
      "\n",
      "\n",
      "tensor([[-0.9582,  0.0871],\n",
      "        [-0.0457, -0.0083]])\n",
      "Iterarion 30\n",
      "eta = \n",
      "[[ 0.1242  0.067 ]\n",
      " [ 0.0606 -0.0271]]\n",
      "loss = 1.3707\n",
      "\n",
      "\n",
      "tensor([[-1.1600,  0.0497],\n",
      "        [-0.0395,  0.0017]])\n",
      "Iterarion 31\n",
      "eta = \n",
      "[[ 0.1314  0.0676]\n",
      " [ 0.0644 -0.026 ]]\n",
      "loss = 1.3898\n",
      "\n",
      "\n",
      "tensor([[-1.0636, -0.0357],\n",
      "        [ 0.0115,  0.0074]])\n",
      "Iterarion 32\n",
      "eta = \n",
      "[[ 0.1385  0.0684]\n",
      " [ 0.0677 -0.0258]]\n",
      "loss = 1.4447\n",
      "\n",
      "\n",
      "tensor([[-0.9853,  0.0613],\n",
      "        [ 0.0488,  0.0096]])\n",
      "Iterarion 33\n",
      "eta = \n",
      "[[ 0.1454  0.0686]\n",
      " [ 0.0697 -0.0267]]\n",
      "loss = 1.4865\n",
      "\n",
      "\n",
      "tensor([[-0.8747,  0.1542],\n",
      "        [ 0.0778,  0.0042]])\n",
      "Iterarion 34\n",
      "eta = \n",
      "[[ 0.1521  0.0676]\n",
      " [ 0.0702 -0.028 ]]\n",
      "loss = 1.3893\n",
      "\n",
      "\n",
      "tensor([[-0.7932,  0.0691],\n",
      "        [ 0.0869,  0.0086]])\n",
      "Iterarion 35\n",
      "eta = \n",
      "[[ 0.1587  0.0661]\n",
      " [ 0.0691 -0.0302]]\n",
      "loss = 1.4578\n",
      "\n",
      "\n",
      "tensor([[-0.6614,  0.1288],\n",
      "        [ 0.0973,  0.0033]])\n",
      "Iterarion 36\n",
      "eta = \n",
      "[[ 0.1649  0.0638]\n",
      " [ 0.0666 -0.0325]]\n",
      "loss = 1.3056\n",
      "\n",
      "\n",
      "tensor([[-0.7492,  0.1053],\n",
      "        [ 0.0642,  0.0061]])\n",
      "Iterarion 37\n",
      "eta = \n",
      "[[ 0.171   0.0608]\n",
      " [ 0.0632 -0.0353]]\n",
      "loss = 1.2576\n",
      "\n",
      "\n",
      "tensor([[-0.8267,  0.0899],\n",
      "        [ 0.0452,  0.0023]])\n",
      "Iterarion 38\n",
      "eta = \n",
      "[[ 0.177   0.0573]\n",
      " [ 0.0594 -0.0381]]\n",
      "loss = 1.4869\n",
      "\n",
      "\n",
      "tensor([[-0.6558,  0.1241],\n",
      "        [-0.0421, -0.0082]])\n",
      "Iterarion 39\n",
      "eta = \n",
      "[[ 0.1828  0.0533]\n",
      " [ 0.0567 -0.0397]]\n",
      "loss = 1.4433\n",
      "\n",
      "\n",
      "tensor([[-0.5391,  0.1377],\n",
      "        [-0.0491, -0.0146]])\n",
      "Iterarion 40\n",
      "eta = \n",
      "[[ 0.1884  0.0485]\n",
      " [ 0.0551 -0.0395]]\n",
      "loss = 1.3562\n",
      "\n",
      "\n",
      "tensor([[-0.5358,  0.1002],\n",
      "        [-0.0206, -0.0095]])\n",
      "Iterarion 41\n",
      "eta = \n",
      "[[ 0.1937  0.0434]\n",
      " [ 0.054  -0.0381]]\n",
      "loss = 1.3433\n",
      "\n",
      "\n",
      "tensor([[-0.5639,  0.0702],\n",
      "        [-0.0500, -0.0095]])\n",
      "Iterarion 42\n",
      "eta = \n",
      "[[ 0.1989  0.0382]\n",
      " [ 0.0538 -0.0359]]\n",
      "loss = 1.4508\n",
      "\n",
      "\n",
      "tensor([[-0.5185,  0.1102],\n",
      "        [-0.0272, -0.0057]])\n",
      "Iterarion 43\n",
      "eta = \n",
      "[[ 0.2039  0.0326]\n",
      " [ 0.0541 -0.0332]]\n",
      "loss = 1.3542\n",
      "\n",
      "\n",
      "tensor([[-0.4301,  0.1066],\n",
      "        [-0.0441, -0.0127]])\n",
      "Iterarion 44\n",
      "eta = \n",
      "[[ 0.2086  0.0267]\n",
      " [ 0.0551 -0.0294]]\n",
      "loss = 1.3345\n",
      "\n",
      "\n",
      "tensor([[-0.4633,  0.1215],\n",
      "        [-0.0518, -0.0083]])\n",
      "Iterarion 45\n",
      "eta = \n",
      "[[ 0.2132  0.0204]\n",
      " [ 0.057  -0.025 ]]\n",
      "loss = 1.4491\n",
      "\n",
      "\n",
      "tensor([[-0.3039,  0.1504],\n",
      "        [ 0.0089, -0.0008]])\n",
      "Iterarion 46\n",
      "eta = \n",
      "[[ 0.2176  0.0135]\n",
      " [ 0.0585 -0.021 ]]\n",
      "loss = 1.3681\n",
      "\n",
      "\n",
      "tensor([[-0.4561,  0.1198],\n",
      "        [-0.0553, -0.0058]])\n",
      "Iterarion 47\n",
      "eta = \n",
      "[[ 0.2218  0.0064]\n",
      " [ 0.0608 -0.0167]]\n",
      "loss = 1.2696\n",
      "\n",
      "\n",
      "tensor([[-0.5308,  0.0606],\n",
      "        [ 0.0454,  0.0167]])\n",
      "Iterarion 48\n",
      "eta = \n",
      "[[ 0.226  -0.0006]\n",
      " [ 0.0621 -0.0147]]\n",
      "loss = 1.3178\n",
      "\n",
      "\n",
      "tensor([[-0.4492,  0.1152],\n",
      "        [ 0.0342,  0.0113]])\n",
      "Iterarion 49\n",
      "eta = \n",
      "[[ 0.23   -0.0078]\n",
      " [ 0.0627 -0.0142]]\n",
      "loss = 1.3292\n",
      "\n",
      "\n",
      "tensor([[-0.2546,  0.1288],\n",
      "        [ 0.0403,  0.0045]])\n",
      "Iterarion 50\n",
      "eta = \n",
      "[[ 0.2338 -0.0153]\n",
      " [ 0.0625 -0.0143]]\n",
      "loss = 1.2869\n",
      "\n",
      "\n",
      "tensor([[-0.4599,  0.0154],\n",
      "        [ 0.0486,  0.0161]])\n",
      "Iterarion 51\n",
      "eta = \n",
      "[[ 0.2376 -0.0223]\n",
      " [ 0.0614 -0.0161]]\n",
      "loss = 1.3042\n",
      "\n",
      "\n",
      "tensor([[-0.2471,  0.1189],\n",
      "        [ 0.0567,  0.0057]])\n",
      "Iterarion 52\n",
      "eta = \n",
      "[[ 0.2412 -0.0296]\n",
      " [ 0.0595 -0.0183]]\n",
      "loss = 1.3992\n",
      "\n",
      "\n",
      "tensor([[-0.2855,  0.1160],\n",
      "        [ 0.0171,  0.0075]])\n",
      "Iterarion 53\n",
      "eta = \n",
      "[[ 0.2446 -0.0371]\n",
      " [ 0.0575 -0.0212]]\n",
      "loss = 1.2962\n",
      "\n",
      "\n",
      "tensor([[-0.2154,  0.1120],\n",
      "        [-0.0781, -0.0051]])\n",
      "Iterarion 54\n",
      "eta = \n",
      "[[ 0.2478 -0.0447]\n",
      " [ 0.057  -0.0232]]\n",
      "loss = 1.3112\n",
      "\n",
      "\n",
      "tensor([[-0.2819,  0.0656],\n",
      "        [-0.0213,  0.0016]])\n",
      "Iterarion 55\n",
      "eta = \n",
      "[[ 0.2509 -0.0522]\n",
      " [ 0.057  -0.0252]]\n",
      "loss = 1.3629\n",
      "\n",
      "\n",
      "tensor([[-0.2959,  0.0516],\n",
      "        [ 0.0219,  0.0074]])\n",
      "Iterarion 56\n",
      "eta = \n",
      "[[ 0.2539 -0.0595]\n",
      " [ 0.0566 -0.0279]]\n",
      "loss = 1.3800\n",
      "\n",
      "\n",
      "tensor([[-0.1465,  0.1637],\n",
      "        [-0.0579, -0.0156]])\n",
      "Iterarion 57\n",
      "eta = \n",
      "[[ 0.2567 -0.0673]\n",
      " [ 0.0572 -0.0285]]\n",
      "loss = 1.4031\n",
      "\n",
      "\n",
      "tensor([[-0.1203,  0.1600],\n",
      "        [ 0.0175, -0.0006]])\n",
      "Iterarion 58\n",
      "eta = \n",
      "[[ 0.2594 -0.0756]\n",
      " [ 0.0575 -0.029 ]]\n",
      "loss = 1.3096\n",
      "\n",
      "\n",
      "tensor([[-0.1570,  0.1634],\n",
      "        [-0.0627, -0.0139]])\n",
      "Iterarion 59\n",
      "eta = \n",
      "[[ 0.2619 -0.0843]\n",
      " [ 0.0589 -0.028 ]]\n",
      "loss = 1.2734\n",
      "\n",
      "\n",
      "tensor([[-0.1332,  0.1367],\n",
      "        [-0.0032, -0.0066]])\n",
      "Iterarion 60\n",
      "eta = \n",
      "[[ 0.2642 -0.0933]\n",
      " [ 0.0602 -0.0263]]\n",
      "loss = 1.3997\n",
      "\n",
      "\n",
      "tensor([[-0.0934,  0.1066],\n",
      "        [ 0.0182, -0.0034]])\n",
      "Iterarion 61\n",
      "eta = \n",
      "[[ 0.2664 -0.1022]\n",
      " [ 0.061  -0.0244]]\n",
      "loss = 1.3012\n",
      "\n",
      "\n",
      "tensor([[-0.2211,  0.0568],\n",
      "        [ 0.0047, -0.0006]])\n",
      "Iterarion 62\n",
      "eta = \n",
      "[[ 0.2686 -0.1108]\n",
      " [ 0.0617 -0.0226]]\n",
      "loss = 1.4232\n",
      "\n",
      "\n",
      "tensor([[-0.1256,  0.0897],\n",
      "        [-0.0178, -0.0030]])\n",
      "Iterarion 63\n",
      "eta = \n",
      "[[ 0.2706 -0.1193]\n",
      " [ 0.0627 -0.0206]]\n",
      "loss = 1.3811\n",
      "\n",
      "\n",
      "tensor([[-0.2265,  0.0664],\n",
      "        [ 0.0215,  0.0082]])\n",
      "Iterarion 64\n",
      "eta = \n",
      "[[ 0.2726 -0.1276]\n",
      " [ 0.0632 -0.0198]]\n",
      "loss = 1.2274\n",
      "\n",
      "\n",
      "tensor([[-0.1649,  0.0511],\n",
      "        [ 0.0135,  0.0010]])\n",
      "Iterarion 65\n",
      "eta = \n",
      "[[ 0.2745 -0.1354]\n",
      " [ 0.0633 -0.0192]]\n",
      "loss = 1.4220\n",
      "\n",
      "\n",
      "tensor([[-0.2253,  0.0603],\n",
      "        [-0.0011,  0.0127]])\n",
      "Iterarion 66\n",
      "eta = \n",
      "[[ 0.2764 -0.1431]\n",
      " [ 0.0635 -0.02  ]]\n",
      "loss = 1.3850\n",
      "\n",
      "\n",
      "tensor([[-0.0726,  0.1671],\n",
      "        [ 0.0724,  0.0071]])\n",
      "Iterarion 67\n",
      "eta = \n",
      "[[ 0.2782 -0.1513]\n",
      " [ 0.0623 -0.0216]]\n",
      "loss = 1.3534\n",
      "\n",
      "\n",
      "tensor([[-0.0734,  0.0802],\n",
      "        [ 0.0629,  0.0082]])\n",
      "Iterarion 68\n",
      "eta = \n",
      "[[ 0.2798 -0.1594]\n",
      " [ 0.06   -0.0239]]\n",
      "loss = 1.2718\n",
      "\n",
      "\n",
      "tensor([[-0.1933,  0.0165],\n",
      "        [ 0.0436,  0.0144]])\n",
      "Iterarion 69\n",
      "eta = \n",
      "[[ 0.2815 -0.1669]\n",
      " [ 0.0571 -0.0276]]\n",
      "loss = 1.2455\n",
      "\n",
      "\n",
      "tensor([[-0.1062,  0.0988],\n",
      "        [-0.0461, -0.0044]])\n",
      "Iterarion 70\n",
      "eta = \n",
      "[[ 0.283  -0.1745]\n",
      " [ 0.0554 -0.0304]]\n",
      "loss = 1.4330\n",
      "\n",
      "\n",
      "tensor([[-0.1173,  0.0751],\n",
      "        [-0.0919, -0.0128]])\n",
      "Iterarion 71\n",
      "eta = \n",
      "[[ 0.2845 -0.182 ]\n",
      " [ 0.0556 -0.0315]]\n",
      "loss = 1.2411\n",
      "\n",
      "\n",
      "tensor([[-0.1671,  0.0735],\n",
      "        [-0.0682, -0.0031]])\n",
      "Iterarion 72\n",
      "eta = \n",
      "[[ 0.286  -0.1894]\n",
      " [ 0.057  -0.0322]]\n",
      "loss = 1.3623\n",
      "\n",
      "\n",
      "tensor([[-0.0787,  0.0777],\n",
      "        [ 0.0119,  0.0020]])\n",
      "Iterarion 73\n",
      "eta = \n",
      "[[ 0.2874 -0.1968]\n",
      " [ 0.0581 -0.033 ]]\n",
      "loss = 1.3753\n",
      "\n",
      "\n",
      "tensor([[-9.6761e-02,  6.0658e-02],\n",
      "        [ 5.5010e-02, -7.3519e-05]])\n",
      "Iterarion 74\n",
      "eta = \n",
      "[[ 0.2887 -0.204 ]\n",
      " [ 0.058  -0.0337]]\n",
      "loss = 1.3717\n",
      "\n",
      "\n",
      "tensor([[-0.0280,  0.0855],\n",
      "        [ 0.0190,  0.0021]])\n",
      "Iterarion 75\n",
      "eta = \n",
      "[[ 0.29   -0.2112]\n",
      " [ 0.0576 -0.0346]]\n",
      "loss = 1.2573\n",
      "\n",
      "\n",
      "tensor([[-0.0551,  0.0708],\n",
      "        [-0.0056, -0.0043]])\n",
      "Iterarion 76\n",
      "eta = \n",
      "[[ 0.2911 -0.2183]\n",
      " [ 0.0574 -0.035 ]]\n",
      "loss = 1.3252\n",
      "\n",
      "\n",
      "tensor([[-0.0399,  0.0923],\n",
      "        [-0.0311, -0.0110]])\n",
      "Iterarion 77\n",
      "eta = \n",
      "[[ 0.2922 -0.2256]\n",
      " [ 0.0577 -0.034 ]]\n",
      "loss = 1.3812\n",
      "\n",
      "\n",
      "tensor([[-0.1039,  0.0348],\n",
      "        [ 0.0284,  0.0018]])\n",
      "Iterarion 78\n",
      "eta = \n",
      "[[ 0.2933 -0.2324]\n",
      " [ 0.0575 -0.0333]]\n",
      "loss = 1.1861\n",
      "\n",
      "\n",
      "tensor([[-0.0867,  0.0672],\n",
      "        [-0.0231, -0.0114]])\n",
      "Iterarion 79\n",
      "eta = \n",
      "[[ 0.2943 -0.2392]\n",
      " [ 0.0577 -0.0314]]\n",
      "loss = 1.2173\n",
      "\n",
      "\n",
      "tensor([[-0.0927,  0.0702],\n",
      "        [ 0.0025, -0.0043]])\n",
      "Iterarion 80\n",
      "eta = \n",
      "[[ 0.2953 -0.246 ]\n",
      " [ 0.0579 -0.0292]]\n",
      "loss = 1.2248\n",
      "\n",
      "\n",
      "tensor([[-0.0131,  0.0561],\n",
      "        [-0.0178, -0.0037]])\n",
      "Iterarion 81\n",
      "eta = \n",
      "[[ 0.2962 -0.2526]\n",
      " [ 0.0584 -0.0268]]\n",
      "loss = 1.3206\n",
      "\n",
      "\n",
      "tensor([[-0.0552,  0.0679],\n",
      "        [ 0.0069, -0.0011]])\n",
      "Iterarion 82\n",
      "eta = \n",
      "[[ 0.2971 -0.2592]\n",
      " [ 0.0587 -0.0245]]\n",
      "loss = 1.3111\n",
      "\n",
      "\n",
      "tensor([[-0.0782,  0.0515],\n",
      "        [ 0.0194, -0.0011]])\n",
      "Iterarion 83\n",
      "eta = \n",
      "[[ 0.2979 -0.2656]\n",
      " [ 0.0586 -0.0222]]\n",
      "loss = 1.2418\n",
      "\n",
      "\n",
      "tensor([[-0.0438,  0.0748],\n",
      "        [ 0.0073, -0.0025]])\n",
      "Iterarion 84\n",
      "eta = \n",
      "[[ 0.2987 -0.272 ]\n",
      " [ 0.0584 -0.0199]]\n",
      "loss = 1.4186\n",
      "\n",
      "\n",
      "tensor([[-0.1336,  0.0273],\n",
      "        [ 0.0159,  0.0087]])\n",
      "Iterarion 85\n",
      "eta = \n",
      "[[ 0.2995 -0.2781]\n",
      " [ 0.0579 -0.0188]]\n",
      "loss = 1.3992\n",
      "\n",
      "\n",
      "tensor([[-0.0438,  0.0914],\n",
      "        [ 0.0020,  0.0047]])\n",
      "Iterarion 86\n",
      "eta = \n",
      "[[ 0.3003 -0.2845]\n",
      " [ 0.0573 -0.0184]]\n",
      "loss = 1.3145\n",
      "\n",
      "\n",
      "tensor([[-0.1376,  0.0088],\n",
      "        [-0.0373,  0.0032]])\n",
      "Iterarion 87\n",
      "eta = \n",
      "[[ 0.3011 -0.2903]\n",
      " [ 0.0576 -0.0184]]\n",
      "loss = 1.2510\n",
      "\n",
      "\n",
      "tensor([[-0.0415,  0.0829],\n",
      "        [-0.0170, -0.0006]])\n",
      "Iterarion 88\n",
      "eta = \n",
      "[[ 0.3019 -0.2963]\n",
      " [ 0.0582 -0.0183]]\n",
      "loss = 1.3958\n",
      "\n",
      "\n",
      "tensor([[0.0013, 0.1046],\n",
      "        [0.0577, 0.0050]])\n",
      "Iterarion 89\n",
      "eta = \n",
      "[[ 0.3026 -0.3026]\n",
      " [ 0.0576 -0.0189]]\n",
      "loss = 1.2768\n",
      "\n",
      "\n",
      "tensor([[-0.1095,  0.0194],\n",
      "        [-0.0167,  0.0036]])\n",
      "Iterarion 90\n",
      "eta = \n",
      "[[ 0.3033 -0.3085]\n",
      " [ 0.0574 -0.0198]]\n",
      "loss = 1.2933\n",
      "\n",
      "\n",
      "tensor([[-0.0707,  0.0499],\n",
      "        [-0.0174,  0.0081]])\n",
      "Iterarion 91\n",
      "eta = \n",
      "[[ 0.3041 -0.3144]\n",
      " [ 0.0575 -0.0216]]\n",
      "loss = 1.3633\n",
      "\n",
      "\n",
      "tensor([[-0.0203,  0.0922],\n",
      "        [ 0.0040,  0.0023]])\n",
      "Iterarion 92\n",
      "eta = \n",
      "[[ 0.3047 -0.3205]\n",
      " [ 0.0576 -0.0235]]\n",
      "loss = 1.3308\n",
      "\n",
      "\n",
      "tensor([[ 0.0243,  0.0776],\n",
      "        [ 0.0003, -0.0017]])\n",
      "Iterarion 93\n",
      "eta = \n",
      "[[ 0.3053 -0.3267]\n",
      " [ 0.0576 -0.025 ]]\n",
      "loss = 1.3520\n",
      "\n",
      "\n",
      "tensor([[-0.0042,  0.0601],\n",
      "        [ 0.0183,  0.0017]])\n",
      "Iterarion 94\n",
      "eta = \n",
      "[[ 0.3058 -0.3329]\n",
      " [ 0.0573 -0.0266]]\n",
      "loss = 1.3367\n",
      "\n",
      "\n",
      "tensor([[-0.0597, -0.0017],\n",
      "        [ 0.0046,  0.0031]])\n",
      "Iterarion 95\n",
      "eta = \n",
      "[[ 0.3064 -0.3385]\n",
      " [ 0.0569 -0.0284]]\n",
      "loss = 1.3392\n",
      "\n",
      "\n",
      "tensor([[-0.0146,  0.0652],\n",
      "        [-0.0113, -0.0004]])\n",
      "Iterarion 96\n",
      "eta = \n",
      "[[ 0.3068 -0.3441]\n",
      " [ 0.0567 -0.03  ]]\n",
      "loss = 1.4044\n",
      "\n",
      "\n",
      "tensor([[-0.0151,  0.0982],\n",
      "        [-0.0283, -0.0038]])\n",
      "Iterarion 97\n",
      "eta = \n",
      "[[ 0.3073 -0.3501]\n",
      " [ 0.0572 -0.031 ]]\n",
      "loss = 1.3018\n",
      "\n",
      "\n",
      "tensor([[ 0.0069,  0.0420],\n",
      "        [-0.0076, -0.0044]])\n",
      "Iterarion 98\n",
      "eta = \n",
      "[[ 0.3077 -0.356 ]\n",
      " [ 0.0578 -0.0313]]\n",
      "loss = 1.3516\n",
      "\n",
      "\n",
      "tensor([[-0.1003,  0.0321],\n",
      "        [-0.0369, -0.0050]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterarion 99\n",
      "eta = \n",
      "[[ 0.3082 -0.3615]\n",
      " [ 0.0591 -0.031 ]]\n",
      "loss = 1.2912\n",
      "\n",
      "\n",
      "tensor([[-0.0757,  0.0446],\n",
      "        [ 0.0074, -0.0075]])\n",
      "Iterarion 100\n",
      "eta = \n",
      "[[ 0.3086 -0.367 ]\n",
      " [ 0.0602 -0.0298]]\n",
      "loss = 1.3041\n",
      "\n",
      "\n",
      "tensor([[0.0206, 0.0475],\n",
      "        [0.0018, 0.0008]])\n",
      "Iterarion 101\n",
      "eta = \n",
      "[[ 0.309  -0.3724]\n",
      " [ 0.0611 -0.0287]]\n",
      "loss = 1.3186\n",
      "\n",
      "\n",
      "tensor([[-0.0680,  0.0626],\n",
      "        [-0.0304, -0.0093]])\n",
      "Iterarion 102\n",
      "eta = \n",
      "[[ 0.3095 -0.3779]\n",
      " [ 0.0625 -0.0266]]\n",
      "loss = 1.2837\n",
      "\n",
      "\n",
      "tensor([[-0.0364,  0.0489],\n",
      "        [ 0.0004, -0.0004]])\n",
      "Iterarion 103\n",
      "eta = \n",
      "[[ 0.3099 -0.3833]\n",
      " [ 0.0638 -0.0247]]\n",
      "loss = 1.2167\n",
      "\n",
      "\n",
      "tensor([[-0.0952, -0.0358],\n",
      "        [ 0.0446,  0.0069]])\n",
      "Iterarion 104\n",
      "eta = \n",
      "[[ 0.3104 -0.3879]\n",
      " [ 0.064  -0.0238]]\n",
      "loss = 1.2480\n",
      "\n",
      "\n",
      "tensor([[-0.0738,  0.0122],\n",
      "        [ 0.1027,  0.0123]])\n",
      "Iterarion 105\n",
      "eta = \n",
      "[[ 0.3108 -0.3921]\n",
      " [ 0.0621 -0.0246]]\n",
      "loss = 1.2784\n",
      "\n",
      "\n",
      "tensor([[-0.0601, -0.0101],\n",
      "        [ 0.0676,  0.0073]])\n",
      "Iterarion 106\n",
      "eta = \n",
      "[[ 0.3113 -0.3958]\n",
      " [ 0.0589 -0.0262]]\n",
      "loss = 1.2225\n",
      "\n",
      "\n",
      "tensor([[-0.0611,  0.0116],\n",
      "        [ 0.0113,  0.0008]])\n",
      "Iterarion 107\n",
      "eta = \n",
      "[[ 0.3118 -0.3993]\n",
      " [ 0.0558 -0.0277]]\n",
      "loss = 1.2221\n",
      "\n",
      "\n",
      "tensor([[-0.1589, -0.0305],\n",
      "        [ 0.0396,  0.0041]])\n",
      "Iterarion 108\n",
      "eta = \n",
      "[[ 0.3124 -0.4022]\n",
      " [ 0.0521 -0.0296]]\n",
      "loss = 1.2933\n",
      "\n",
      "\n",
      "tensor([[-0.1159, -0.0442],\n",
      "        [-0.0645, -0.0063]])\n",
      "Iterarion 109\n",
      "eta = \n",
      "[[ 0.3131 -0.4043]\n",
      " [ 0.0502 -0.0305]]\n",
      "loss = 1.3346\n",
      "\n",
      "\n",
      "tensor([[-0.0485,  0.0368],\n",
      "        [-0.0397, -0.0055]])\n",
      "Iterarion 110\n",
      "eta = \n",
      "[[ 0.3137 -0.4066]\n",
      " [ 0.0493 -0.0307]]\n",
      "loss = 1.3236\n",
      "\n",
      "\n",
      "tensor([[ 0.0150,  0.0222],\n",
      "        [-0.0976, -0.0111]])\n",
      "Iterarion 111\n",
      "eta = \n",
      "[[ 0.3142 -0.4089]\n",
      " [ 0.0506 -0.0294]]\n",
      "loss = 1.3403\n",
      "\n",
      "\n",
      "tensor([[-0.0091,  0.0117],\n",
      "        [-0.0284, -0.0064]])\n",
      "Iterarion 112\n",
      "eta = \n",
      "[[ 0.3147 -0.4111]\n",
      " [ 0.0523 -0.0274]]\n",
      "loss = 1.2135\n",
      "\n",
      "\n",
      "tensor([[-0.1310, -0.0439],\n",
      "        [-0.0480, -0.0044]])\n",
      "Iterarion 113\n",
      "eta = \n",
      "[[ 0.3153 -0.4126]\n",
      " [ 0.0548 -0.025 ]]\n",
      "loss = 1.3598\n",
      "\n",
      "\n",
      "tensor([[-0.0228, -0.0006],\n",
      "        [ 0.0245,  0.0068]])\n",
      "Iterarion 114\n",
      "eta = \n",
      "[[ 0.3158 -0.414 ]\n",
      " [ 0.0566 -0.0238]]\n",
      "loss = 1.2794\n",
      "\n",
      "\n",
      "tensor([[-0.1298,  0.0022],\n",
      "        [ 0.0024,  0.0025]])\n",
      "Iterarion 115\n",
      "eta = \n",
      "[[ 0.3164 -0.4153]\n",
      " [ 0.0582 -0.023 ]]\n",
      "loss = 1.4227\n",
      "\n",
      "\n",
      "tensor([[-0.0167,  0.0002],\n",
      "        [-0.0424,  0.0005]])\n",
      "Iterarion 116\n",
      "eta = \n",
      "[[ 0.317  -0.4165]\n",
      " [ 0.0605 -0.0223]]\n",
      "loss = 1.2518\n",
      "\n",
      "\n",
      "tensor([[-0.0838, -0.0561],\n",
      "        [-0.0083,  0.0060]])\n",
      "Iterarion 117\n",
      "eta = \n",
      "[[ 0.3176 -0.4169]\n",
      " [ 0.0627 -0.0225]]\n",
      "loss = 1.2298\n",
      "\n",
      "\n",
      "tensor([[-0.0763, -0.0021],\n",
      "        [ 0.0517,  0.0074]])\n",
      "Iterarion 118\n",
      "eta = \n",
      "[[ 0.3182 -0.4174]\n",
      " [ 0.0636 -0.0236]]\n",
      "loss = 1.3337\n",
      "\n",
      "\n",
      "tensor([[0.0059, 0.0240],\n",
      "        [0.0790, 0.0108]])\n",
      "Iterarion 119\n",
      "eta = \n",
      "[[ 0.3187 -0.418 ]\n",
      " [ 0.0628 -0.0259]]\n",
      "loss = 1.3879\n",
      "\n",
      "\n",
      "tensor([[0.0312, 0.1004],\n",
      "        [0.0173, 0.0087]])\n",
      "Iterarion 120\n",
      "eta = \n",
      "[[ 0.3192 -0.4196]\n",
      " [ 0.0617 -0.0292]]\n",
      "loss = 1.2953\n",
      "\n",
      "\n",
      "tensor([[ 0.0220,  0.0478],\n",
      "        [-0.0136, -0.0036]])\n",
      "Iterarion 121\n",
      "eta = \n",
      "[[ 0.3196 -0.4215]\n",
      " [ 0.061  -0.0317]]\n",
      "loss = 1.3557\n",
      "\n",
      "\n",
      "tensor([[ 0.0588,  0.0486],\n",
      "        [ 0.0445, -0.0015]])\n",
      "Iterarion 122\n",
      "eta = \n",
      "[[ 0.3199 -0.4237]\n",
      " [ 0.0594 -0.0337]]\n",
      "loss = 1.3158\n",
      "\n",
      "\n",
      "tensor([[-0.0057,  0.0596],\n",
      "        [-0.0099, -0.0065]])\n",
      "Iterarion 123\n",
      "eta = \n",
      "[[ 0.3202 -0.4264]\n",
      " [ 0.0582 -0.0347]]\n",
      "loss = 1.3535\n",
      "\n",
      "\n",
      "tensor([[-0.0980, -0.0390],\n",
      "        [-0.0486, -0.0008]])\n",
      "Iterarion 124\n",
      "eta = \n",
      "[[ 0.3205 -0.4284]\n",
      " [ 0.0582 -0.0355]]\n",
      "loss = 1.1731\n",
      "\n",
      "\n",
      "tensor([[-0.0010,  0.0140],\n",
      "        [-0.0385, -0.0124]])\n",
      "Iterarion 125\n",
      "eta = \n",
      "[[ 0.3208 -0.4303]\n",
      " [ 0.0589 -0.0346]]\n",
      "loss = 1.3731\n",
      "\n",
      "\n",
      "tensor([[-0.0157,  0.0185],\n",
      "        [-0.0038, -0.0080]])\n",
      "Iterarion 126\n",
      "eta = \n",
      "[[ 0.3211 -0.4323]\n",
      " [ 0.0597 -0.0328]]\n",
      "loss = 1.4122\n",
      "\n",
      "\n",
      "tensor([[ 0.0528,  0.0004],\n",
      "        [ 0.0365, -0.0026]])\n",
      "Iterarion 127\n",
      "eta = \n",
      "[[ 0.3213 -0.434 ]\n",
      " [ 0.0596 -0.0308]]\n",
      "loss = 1.2519\n",
      "\n",
      "\n",
      "tensor([[-0.0123,  0.0389],\n",
      "        [-0.0109, -0.0026]])\n",
      "Iterarion 128\n",
      "eta = \n",
      "[[ 0.3216 -0.4361]\n",
      " [ 0.0597 -0.0287]]\n",
      "loss = 1.2819\n",
      "\n",
      "\n",
      "tensor([[-0.0474,  0.0234],\n",
      "        [ 0.0124, -0.0032]])\n",
      "Iterarion 129\n",
      "eta = \n",
      "[[ 0.3218 -0.4381]\n",
      " [ 0.0596 -0.0264]]\n",
      "loss = 1.3917\n",
      "\n",
      "\n",
      "tensor([[ 0.0310,  0.0148],\n",
      "        [ 0.0049, -0.0006]])\n",
      "Iterarion 130\n",
      "eta = \n",
      "[[ 0.322  -0.4401]\n",
      " [ 0.0594 -0.0241]]\n",
      "loss = 1.2952\n",
      "\n",
      "\n",
      "tensor([[-0.0352, -0.0296],\n",
      "        [-0.0297,  0.0015]])\n",
      "Iterarion 131\n",
      "eta = \n",
      "[[ 0.3222 -0.4417]\n",
      " [ 0.0598 -0.0224]]\n",
      "loss = 1.4021\n",
      "\n",
      "\n",
      "tensor([[-0.0003,  0.0737],\n",
      "        [-0.0375, -0.0005]])\n",
      "Iterarion 132\n",
      "eta = \n",
      "[[ 0.3223 -0.4438]\n",
      " [ 0.0611 -0.0207]]\n",
      "loss = 1.3034\n",
      "\n",
      "\n",
      "tensor([[ 0.0065,  0.0558],\n",
      "        [-0.0530, -0.0043]])\n",
      "Iterarion 133\n",
      "eta = \n",
      "[[ 0.3225 -0.4464]\n",
      " [ 0.0633 -0.0186]]\n",
      "loss = 1.3473\n",
      "\n",
      "\n",
      "tensor([[0.0200, 0.0021],\n",
      "        [0.0382, 0.0043]])\n",
      "Iterarion 134\n",
      "eta = \n",
      "[[ 0.3226 -0.4487]\n",
      " [ 0.0645 -0.0173]]\n",
      "loss = 1.2473\n",
      "\n",
      "\n",
      "tensor([[-0.0575,  0.0177],\n",
      "        [-0.0209,  0.0037]])\n",
      "Iterarion 135\n",
      "eta = \n",
      "[[ 0.3228 -0.451 ]\n",
      " [ 0.066  -0.0166]]\n",
      "loss = 1.3176\n",
      "\n",
      "\n",
      "tensor([[-0.0564,  0.0065],\n",
      "        [ 0.0300,  0.0079]])\n",
      "Iterarion 136\n",
      "eta = \n",
      "[[ 0.323  -0.4531]\n",
      " [ 0.0667 -0.017 ]]\n",
      "loss = 1.2938\n",
      "\n",
      "\n",
      "tensor([[0.0497, 0.0218],\n",
      "        [0.0499, 0.0007]])\n",
      "Iterarion 137\n",
      "eta = \n",
      "[[ 0.3231 -0.4553]\n",
      " [ 0.0663 -0.0175]]\n",
      "loss = 1.2033\n",
      "\n",
      "\n",
      "tensor([[-0.0455,  0.0077],\n",
      "        [ 0.0010,  0.0054]])\n",
      "Iterarion 138\n",
      "eta = \n",
      "[[ 0.3233 -0.4574]\n",
      " [ 0.0659 -0.0186]]\n",
      "loss = 1.3838\n",
      "\n",
      "\n",
      "tensor([[-0.0064, -0.0236],\n",
      "        [ 0.0452,  0.0123]])\n",
      "Iterarion 139\n",
      "eta = \n",
      "[[ 0.3235 -0.459 ]\n",
      " [ 0.0645 -0.0213]]\n",
      "loss = 1.3791\n",
      "\n",
      "\n",
      "tensor([[-0.0393, -0.0019],\n",
      "        [ 0.0342,  0.0028]])\n",
      "Iterarion 140\n",
      "eta = \n",
      "[[ 0.3237 -0.4604]\n",
      " [ 0.0625 -0.0241]]\n",
      "loss = 1.2516\n",
      "\n",
      "\n",
      "tensor([[-7.4835e-02,  9.2683e-03],\n",
      "        [-6.1710e-02, -6.2086e-05]])\n",
      "Iterarion 141\n",
      "eta = \n",
      "[[ 0.3239 -0.4618]\n",
      " [ 0.0621 -0.0266]]\n",
      "loss = 1.2605\n",
      "\n",
      "\n",
      "tensor([[-0.0033,  0.0078],\n",
      "        [-0.0360, -0.0029]])\n",
      "Iterarion 142\n",
      "eta = \n",
      "[[ 0.3241 -0.4631]\n",
      " [ 0.0625 -0.0284]]\n",
      "loss = 1.2836\n",
      "\n",
      "\n",
      "tensor([[-0.0377, -0.0357],\n",
      "        [ 0.0089,  0.0063]])\n",
      "Iterarion 143\n",
      "eta = \n",
      "[[ 0.3244 -0.4639]\n",
      " [ 0.0627 -0.0309]]\n",
      "loss = 1.2960\n",
      "\n",
      "\n",
      "tensor([[-0.0290,  0.0061],\n",
      "        [ 0.0886,  0.0089]])\n",
      "Iterarion 144\n",
      "eta = \n",
      "[[ 0.3246 -0.4647]\n",
      " [ 0.0609 -0.0344]]\n",
      "loss = 1.3284\n",
      "\n",
      "\n",
      "tensor([[ 0.0431, -0.0023],\n",
      "        [-0.0134, -0.0065]])\n",
      "Iterarion 145\n",
      "eta = \n",
      "[[ 0.3248 -0.4654]\n",
      " [ 0.0596 -0.0366]]\n",
      "loss = 1.3937\n",
      "\n",
      "\n",
      "tensor([[-0.0154, -0.0292],\n",
      "        [ 0.0123,  0.0002]])\n",
      "Iterarion 146\n",
      "eta = \n",
      "[[ 0.325  -0.4657]\n",
      " [ 0.0582 -0.0387]]\n",
      "loss = 1.3503\n",
      "\n",
      "\n",
      "tensor([[-0.0726, -0.0443],\n",
      "        [ 0.0052,  0.0043]])\n",
      "Iterarion 147\n",
      "eta = \n",
      "[[ 0.3252 -0.4655]\n",
      " [ 0.0567 -0.0411]]\n",
      "loss = 1.3835\n",
      "\n",
      "\n",
      "tensor([[-0.0131,  0.0319],\n",
      "        [-0.0440, -0.0107]])\n",
      "Iterarion 148\n",
      "eta = \n",
      "[[ 0.3254 -0.4656]\n",
      " [ 0.0564 -0.0419]]\n",
      "loss = 1.3126\n",
      "\n",
      "\n",
      "tensor([[ 0.0353,  0.0309],\n",
      "        [-0.0496, -0.0146]])\n",
      "Iterarion 149\n",
      "eta = \n",
      "[[ 0.3256 -0.4661]\n",
      " [ 0.0572 -0.0406]]\n",
      "loss = 1.2416\n",
      "\n",
      "\n",
      "tensor([[-0.0372, -0.0049],\n",
      "        [-0.0486, -0.0054]])\n",
      "Iterarion 150\n",
      "eta = \n",
      "[[ 0.3258 -0.4665]\n",
      " [ 0.059  -0.0387]]\n",
      "loss = 1.2904\n",
      "\n",
      "\n",
      "tensor([[ 0.0716,  0.0362],\n",
      "        [-0.0065, -0.0063]])\n",
      "Iterarion 151\n",
      "eta = \n",
      "[[ 0.3259 -0.4673]\n",
      " [ 0.0608 -0.0362]]\n",
      "loss = 1.3109\n",
      "\n",
      "\n",
      "tensor([[-0.0164,  0.0737],\n",
      "        [-0.0480, -0.0010]])\n",
      "Iterarion 152\n",
      "eta = \n",
      "[[ 0.326  -0.4688]\n",
      " [ 0.0634 -0.0337]]\n",
      "loss = 1.2540\n",
      "\n",
      "\n",
      "tensor([[-0.0719, -0.0213],\n",
      "        [ 0.0138,  0.0037]])\n",
      "Iterarion 153\n",
      "eta = \n",
      "[[ 0.3262 -0.4699]\n",
      " [ 0.0655 -0.0321]]\n",
      "loss = 1.2572\n",
      "\n",
      "\n",
      "tensor([[-0.0161,  0.0499],\n",
      "        [ 0.0656,  0.0023]])\n",
      "Iterarion 154\n",
      "eta = \n",
      "[[ 0.3263 -0.4716]\n",
      " [ 0.0659 -0.0308]]\n",
      "loss = 1.3486\n",
      "\n",
      "\n",
      "tensor([[0.0188, 0.0401],\n",
      "        [0.0429, 0.0001]])\n",
      "Iterarion 155\n",
      "eta = \n",
      "[[ 0.3265 -0.4735]\n",
      " [ 0.0653 -0.0297]]\n",
      "loss = 1.2756\n",
      "\n",
      "\n",
      "tensor([[-0.0500, -0.0252],\n",
      "        [ 0.0538,  0.0042]])\n",
      "Iterarion 156\n",
      "eta = \n",
      "[[ 0.3266 -0.4749]\n",
      " [ 0.0636 -0.0293]]\n",
      "loss = 1.3391\n",
      "\n",
      "\n",
      "tensor([[0.0116, 0.0103],\n",
      "        [0.0339, 0.0038]])\n",
      "Iterarion 157\n",
      "eta = \n",
      "[[ 0.3268 -0.4763]\n",
      " [ 0.0614 -0.0295]]\n",
      "loss = 1.3122\n",
      "\n",
      "\n",
      "tensor([[-0.0147,  0.0236],\n",
      "        [ 0.0576,  0.0051]])\n",
      "Iterarion 158\n",
      "eta = \n",
      "[[ 0.3269 -0.4779]\n",
      " [ 0.0581 -0.0303]]\n",
      "loss = 1.2547\n",
      "\n",
      "\n",
      "tensor([[-0.0587, -0.0339],\n",
      "        [-0.0053,  0.0022]])\n",
      "Iterarion 159\n",
      "eta = \n",
      "[[ 0.3271 -0.4789]\n",
      " [ 0.0552 -0.0314]]\n",
      "loss = 1.2795\n",
      "\n",
      "\n",
      "tensor([[-0.0913, -0.0111],\n",
      "        [ 0.0112,  0.0003]])\n",
      "Iterarion 160\n",
      "eta = \n",
      "[[ 0.3274 -0.4797]\n",
      " [ 0.0524 -0.0324]]\n",
      "loss = 1.2128\n",
      "\n",
      "\n",
      "tensor([[ 0.0087,  0.0272],\n",
      "        [-0.0703, -0.0125]])\n",
      "Iterarion 161\n",
      "eta = \n",
      "[[ 0.3277 -0.4807]\n",
      " [ 0.0514 -0.0316]]\n",
      "loss = 1.3346\n",
      "\n",
      "\n",
      "tensor([[-0.0600, -0.0474],\n",
      "        [-0.0588, -0.0059]])\n",
      "Iterarion 162\n",
      "eta = \n",
      "[[ 0.3279 -0.4811]\n",
      " [ 0.0518 -0.03  ]]\n",
      "loss = 1.2414\n",
      "\n",
      "\n",
      "tensor([[-0.0313, -0.0157],\n",
      "        [-0.0692, -0.0115]])\n",
      "Iterarion 163\n",
      "eta = \n",
      "[[ 0.3282 -0.4812]\n",
      " [ 0.0536 -0.0271]]\n",
      "loss = 1.3101\n",
      "\n",
      "\n",
      "tensor([[-0.1232, -0.0124],\n",
      "        [-0.0420, -0.0009]])\n",
      "Iterarion 164\n",
      "eta = \n",
      "[[ 0.3286 -0.4812]\n",
      " [ 0.0562 -0.0243]]\n",
      "loss = 1.2364\n",
      "\n",
      "\n",
      "tensor([[-0.0174, -0.0354],\n",
      "        [ 0.0178,  0.0047]])\n",
      "Iterarion 165\n",
      "eta = \n",
      "[[ 0.329  -0.4807]\n",
      " [ 0.0582 -0.0225]]\n",
      "loss = 1.3842\n",
      "\n",
      "\n",
      "tensor([[ 0.0562,  0.0332],\n",
      "        [-0.0185,  0.0004]])\n",
      "Iterarion 166\n",
      "eta = \n",
      "[[ 0.3293 -0.4807]\n",
      " [ 0.0604 -0.0208]]\n",
      "loss = 1.2834\n",
      "\n",
      "\n",
      "tensor([[-0.1135, -0.0367],\n",
      "        [ 0.0049,  0.0068]])\n",
      "Iterarion 167\n",
      "eta = \n",
      "[[ 0.3297 -0.4803]\n",
      " [ 0.0622 -0.0203]]\n",
      "loss = 1.2861\n",
      "\n",
      "\n",
      "tensor([[ 0.0032, -0.0286],\n",
      "        [ 0.0012,  0.0025]])\n",
      "Iterarion 168\n",
      "eta = \n",
      "[[ 0.33   -0.4795]\n",
      " [ 0.0639 -0.0201]]\n",
      "loss = 1.2785\n",
      "\n",
      "\n",
      "tensor([[-0.0550,  0.0443],\n",
      "        [ 0.0348,  0.0038]])\n",
      "Iterarion 169\n",
      "eta = \n",
      "[[ 0.3304 -0.4794]\n",
      " [ 0.0646 -0.0205]]\n",
      "loss = 1.2252\n",
      "\n",
      "\n",
      "tensor([[0.0479, 0.0217],\n",
      "        [0.0756, 0.0090]])\n",
      "Iterarion 170\n",
      "eta = \n",
      "[[ 0.3307 -0.4795]\n",
      " [ 0.0636 -0.0221]]\n",
      "loss = 1.3042\n",
      "\n",
      "\n",
      "tensor([[-0.0559, -0.0465],\n",
      "        [ 0.0457,  0.0028]])\n",
      "Iterarion 171\n",
      "eta = \n",
      "[[ 0.331  -0.4791]\n",
      " [ 0.0616 -0.024 ]]\n",
      "loss = 1.2309\n",
      "\n",
      "\n",
      "tensor([[-0.1215, -0.0429],\n",
      "        [ 0.0176,  0.0051]])\n",
      "Iterarion 172\n",
      "eta = \n",
      "[[ 0.3314 -0.4782]\n",
      " [ 0.0595 -0.0263]]\n",
      "loss = 1.3020\n",
      "\n",
      "\n",
      "tensor([[-0.0345, -0.0345],\n",
      "        [ 0.0266,  0.0017]])\n",
      "Iterarion 173\n",
      "eta = \n",
      "[[ 0.3318 -0.4769]\n",
      " [ 0.057  -0.0287]]\n",
      "loss = 1.4319\n",
      "\n",
      "\n",
      "tensor([[ 0.0268, -0.0173],\n",
      "        [-0.0539, -0.0087]])\n",
      "Iterarion 174\n",
      "eta = \n",
      "[[ 0.3322 -0.4756]\n",
      " [ 0.0559 -0.0296]]\n",
      "loss = 1.4020\n",
      "\n",
      "\n",
      "tensor([[ 0.1070,  0.0372],\n",
      "        [-0.0213, -0.0075]])\n",
      "Iterarion 175\n",
      "eta = \n",
      "[[ 0.3324 -0.4748]\n",
      " [ 0.0554 -0.0293]]\n",
      "loss = 1.3953\n",
      "\n",
      "\n",
      "tensor([[ 0.0777,  0.0272],\n",
      "        [-0.0126, -0.0048]])\n",
      "Iterarion 176\n",
      "eta = \n",
      "[[ 0.3325 -0.4745]\n",
      " [ 0.0553 -0.0285]]\n",
      "loss = 1.3076\n",
      "\n",
      "\n",
      "tensor([[ 1.8236e-03, -1.3955e-02],\n",
      "        [-6.4452e-05,  4.5013e-03]])\n",
      "Iterarion 177\n",
      "eta = \n",
      "[[ 0.3325 -0.474 ]\n",
      " [ 0.0551 -0.0283]]\n",
      "loss = 1.3734\n",
      "\n",
      "\n",
      "tensor([[ 0.0931,  0.0814],\n",
      "        [-0.0399, -0.0053]])\n",
      "Iterarion 178\n",
      "eta = \n",
      "[[ 0.3325 -0.4746]\n",
      " [ 0.0559 -0.0275]]\n",
      "loss = 1.3658\n",
      "\n",
      "\n",
      "tensor([[ 0.0952,  0.0532],\n",
      "        [-0.0440, -0.0054]])\n",
      "Iterarion 179\n",
      "eta = \n",
      "[[ 0.3323 -0.4757]\n",
      " [ 0.0576 -0.0259]]\n",
      "loss = 1.1730\n",
      "\n",
      "\n",
      "tensor([[-0.0259, -0.0152],\n",
      "        [-0.0487, -0.0078]])\n",
      "Iterarion 180\n",
      "eta = \n",
      "[[ 0.3322 -0.4766]\n",
      " [ 0.0601 -0.0235]]\n",
      "loss = 1.3694\n",
      "\n",
      "\n",
      "tensor([[-0.0007, -0.0471],\n",
      "        [ 0.0250,  0.0061]])\n",
      "Iterarion 181\n",
      "eta = \n",
      "[[ 0.3321 -0.4768]\n",
      " [ 0.0619 -0.0221]]\n",
      "loss = 1.3480\n",
      "\n",
      "\n",
      "tensor([[0.0151, 0.0362],\n",
      "        [0.0016, 0.0062]])\n",
      "Iterarion 182\n",
      "eta = \n",
      "[[ 0.332  -0.4774]\n",
      " [ 0.0635 -0.0217]]\n",
      "loss = 1.3070\n",
      "\n",
      "\n",
      "tensor([[-0.1031, -0.0414],\n",
      "        [ 0.0725,  0.0164]])\n",
      "Iterarion 183\n",
      "eta = \n",
      "[[ 0.3321 -0.4775]\n",
      " [ 0.0633 -0.0236]]\n",
      "loss = 1.3578\n",
      "\n",
      "\n",
      "tensor([[ 0.0734,  0.0739],\n",
      "        [-0.0063, -0.0026]])\n",
      "Iterarion 184\n",
      "eta = \n",
      "[[ 0.332  -0.4785]\n",
      " [ 0.0632 -0.025 ]]\n",
      "loss = 1.3418\n",
      "\n",
      "\n",
      "tensor([[0.0087, 0.0113],\n",
      "        [0.0299, 0.0049]])\n",
      "Iterarion 185\n",
      "eta = \n",
      "[[ 0.332  -0.4795]\n",
      " [ 0.0625 -0.0269]]\n",
      "loss = 1.3952\n",
      "\n",
      "\n",
      "tensor([[-0.0036, -0.0494],\n",
      "        [-0.0057, -0.0005]])\n",
      "Iterarion 186\n",
      "eta = \n",
      "[[ 0.3319 -0.4798]\n",
      " [ 0.062  -0.0286]]\n",
      "loss = 1.2714\n",
      "\n",
      "\n",
      "tensor([[ 0.0196,  0.0443],\n",
      "        [-0.0577, -0.0061]])\n",
      "Iterarion 187\n",
      "eta = \n",
      "[[ 0.3318 -0.4806]\n",
      " [ 0.0628 -0.0293]]\n",
      "loss = 1.2814\n",
      "\n",
      "\n",
      "tensor([[0.0184, 0.0277],\n",
      "        [0.0477, 0.0079]])\n",
      "Iterarion 188\n",
      "eta = \n",
      "[[ 0.3317 -0.4817]\n",
      " [ 0.0625 -0.031 ]]\n",
      "loss = 1.2407\n",
      "\n",
      "\n",
      "tensor([[ 0.0062,  0.0196],\n",
      "        [-0.0099,  0.0031]])\n",
      "Iterarion 189\n",
      "eta = \n",
      "[[ 0.3317 -0.483 ]\n",
      " [ 0.0624 -0.0329]]\n",
      "loss = 1.4157\n",
      "\n",
      "\n",
      "tensor([[0.0219, 0.0388],\n",
      "        [0.0377, 0.0047]])\n",
      "Iterarion 190\n",
      "eta = \n",
      "[[ 0.3316 -0.4846]\n",
      " [ 0.0615 -0.0353]]\n",
      "loss = 1.3971\n",
      "\n",
      "\n",
      "tensor([[ 0.0414,  0.0017],\n",
      "        [-0.0166, -0.0004]])\n",
      "Iterarion 191\n",
      "eta = \n",
      "[[ 0.3314 -0.486 ]\n",
      " [ 0.061  -0.0374]]\n",
      "loss = 1.3235\n",
      "\n",
      "\n",
      "tensor([[ 0.0062, -0.0006],\n",
      "        [ 0.0415, -0.0016]])\n",
      "Iterarion 192\n",
      "eta = \n",
      "[[ 0.3313 -0.4874]\n",
      " [ 0.0597 -0.0391]]\n",
      "loss = 1.3482\n",
      "\n",
      "\n",
      "tensor([[ 0.0153, -0.0175],\n",
      "        [-0.0085, -0.0020]])\n",
      "Iterarion 193\n",
      "eta = \n",
      "[[ 0.3311 -0.4883]\n",
      " [ 0.0587 -0.0404]]\n",
      "loss = 1.3529\n",
      "\n",
      "\n",
      "tensor([[ 2.7607e-02, -5.9283e-05],\n",
      "        [-9.7853e-03, -3.3849e-03]])\n",
      "Iterarion 194\n",
      "eta = \n",
      "[[ 0.331  -0.4892]\n",
      " [ 0.058  -0.041 ]]\n",
      "loss = 1.3736\n",
      "\n",
      "\n",
      "tensor([[ 0.0463,  0.0184],\n",
      "        [ 0.0448, -0.0075]])\n",
      "Iterarion 195\n",
      "eta = \n",
      "[[ 0.3308 -0.4903]\n",
      " [ 0.0563 -0.0405]]\n",
      "loss = 1.4243\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0293, -0.0093],\n",
      "        [-0.0022, -0.0032]])\n",
      "Iterarion 196\n",
      "eta = \n",
      "[[ 0.3306 -0.4911]\n",
      " [ 0.0549 -0.0397]]\n",
      "loss = 1.4500\n",
      "\n",
      "\n",
      "tensor([[ 0.0096, -0.0413],\n",
      "        [-0.0488, -0.0064]])\n",
      "Iterarion 197\n",
      "eta = \n",
      "[[ 0.3305 -0.4913]\n",
      " [ 0.0547 -0.038 ]]\n",
      "loss = 1.2615\n",
      "\n",
      "\n",
      "tensor([[ 0.0520, -0.0161],\n",
      "        [-0.0164, -0.0056]])\n",
      "Iterarion 198\n",
      "eta = \n",
      "[[ 0.3303 -0.4912]\n",
      " [ 0.0549 -0.0357]]\n",
      "loss = 1.2689\n",
      "\n",
      "\n",
      "tensor([[-0.0634,  0.0060],\n",
      "        [-0.0476, -0.0024]])\n",
      "Iterarion 199\n",
      "eta = \n",
      "[[ 0.3302 -0.4913]\n",
      " [ 0.0562 -0.0333]]\n",
      "loss = 1.3671\n",
      "\n",
      "\n",
      "tensor([[-0.0329, -0.0358],\n",
      "        [-0.0055, -0.0013]])\n",
      "Iterarion 200\n",
      "eta = \n",
      "[[ 0.3301 -0.4908]\n",
      " [ 0.0575 -0.0309]]\n",
      "loss = 1.2846\n",
      "\n",
      "\n",
      "tensor([[-0.0034,  0.0082],\n",
      "        [-0.0421, -0.0046]])\n",
      "Iterarion 201\n",
      "eta = \n",
      "[[ 0.3301 -0.4906]\n",
      " [ 0.0596 -0.0281]]\n",
      "loss = 1.3449\n",
      "\n",
      "\n",
      "tensor([[-0.0021,  0.0087],\n",
      "        [ 0.0343,  0.0015]])\n",
      "Iterarion 202\n",
      "eta = \n",
      "[[ 0.3301 -0.4904]\n",
      " [ 0.0607 -0.0258]]\n",
      "loss = 1.2176\n",
      "\n",
      "\n",
      "tensor([[-0.0575, -0.0408],\n",
      "        [ 0.0304,  0.0012]])\n",
      "Iterarion 203\n",
      "eta = \n",
      "[[ 0.3301 -0.4898]\n",
      " [ 0.061  -0.0239]]\n",
      "loss = 1.3295\n",
      "\n",
      "\n",
      "tensor([[ 0.0443,  0.0330],\n",
      "        [-0.0162, -0.0025]])\n",
      "Iterarion 204\n",
      "eta = \n",
      "[[ 0.3301 -0.4896]\n",
      " [ 0.0617 -0.0219]]\n",
      "loss = 1.3077\n",
      "\n",
      "\n",
      "tensor([[-0.0003, -0.0147],\n",
      "        [ 0.0276,  0.0025]])\n",
      "Iterarion 205\n",
      "eta = \n",
      "[[ 0.3301 -0.4893]\n",
      " [ 0.0616 -0.0203]]\n",
      "loss = 1.2796\n",
      "\n",
      "\n",
      "tensor([[-0.0087, -0.0094],\n",
      "        [ 0.0595,  0.0095]])\n",
      "Iterarion 206\n",
      "eta = \n",
      "[[ 0.3301 -0.4889]\n",
      " [ 0.0602 -0.0203]]\n",
      "loss = 1.4345\n",
      "\n",
      "\n",
      "tensor([[0.0357, 0.0428],\n",
      "        [0.0306, 0.0003]])\n",
      "Iterarion 207\n",
      "eta = \n",
      "[[ 0.33   -0.489 ]\n",
      " [ 0.0582 -0.0204]]\n",
      "loss = 1.2323\n",
      "\n",
      "\n",
      "tensor([[ 0.0013, -0.0613],\n",
      "        [ 0.0351,  0.0048]])\n",
      "Iterarion 208\n",
      "eta = \n",
      "[[ 0.33   -0.4884]\n",
      " [ 0.0557 -0.0211]]\n",
      "loss = 1.3192\n",
      "\n",
      "\n",
      "tensor([[-0.0169,  0.0072],\n",
      "        [-0.0061,  0.0031]])\n",
      "Iterarion 209\n",
      "eta = \n",
      "[[ 0.33   -0.4879]\n",
      " [ 0.0535 -0.0222]]\n",
      "loss = 1.2360\n",
      "\n",
      "\n",
      "tensor([[-0.0298,  0.0204],\n",
      "        [-0.0039, -0.0052]])\n",
      "Iterarion 210\n",
      "eta = \n",
      "[[ 0.33   -0.4877]\n",
      " [ 0.0516 -0.0224]]\n",
      "loss = 1.2817\n",
      "\n",
      "\n",
      "tensor([[-0.0411, -0.0103],\n",
      "        [-0.0587,  0.0002]])\n",
      "Iterarion 211\n",
      "eta = \n",
      "[[ 0.3301 -0.4874]\n",
      " [ 0.0512 -0.0227]]\n",
      "loss = 1.3288\n",
      "\n",
      "\n",
      "tensor([[ 0.0727,  0.0163],\n",
      "        [-0.0893, -0.0145]])\n",
      "Iterarion 212\n",
      "eta = \n",
      "[[ 0.33   -0.4874]\n",
      " [ 0.053  -0.0208]]\n",
      "loss = 1.2683\n",
      "\n",
      "\n",
      "tensor([[-0.0282,  0.0035],\n",
      "        [-0.0064,  0.0056]])\n",
      "Iterarion 213\n",
      "eta = \n",
      "[[ 0.33   -0.4874]\n",
      " [ 0.0547 -0.02  ]]\n",
      "loss = 1.2144\n",
      "\n",
      "\n",
      "tensor([[ 0.0420,  0.0111],\n",
      "        [ 0.0017, -0.0024]])\n",
      "Iterarion 214\n",
      "eta = \n",
      "[[ 0.33   -0.4875]\n",
      " [ 0.0562 -0.0188]]\n",
      "loss = 1.2201\n",
      "\n",
      "\n",
      "tensor([[-0.0082,  0.0351],\n",
      "        [-0.0300, -0.0070]])\n",
      "Iterarion 215\n",
      "eta = \n",
      "[[ 0.33   -0.4882]\n",
      " [ 0.0583 -0.0168]]\n",
      "loss = 1.2085\n",
      "\n",
      "\n",
      "tensor([[-0.0083, -0.0278],\n",
      "        [-0.0025,  0.0033]])\n",
      "Iterarion 216\n",
      "eta = \n",
      "[[ 0.3299 -0.4883]\n",
      " [ 0.0602 -0.0155]]\n",
      "loss = 1.3700\n",
      "\n",
      "\n",
      "tensor([[0.0096, 0.0138],\n",
      "        [0.0491, 0.0065]])\n",
      "Iterarion 217\n",
      "eta = \n",
      "[[ 0.3299 -0.4887]\n",
      " [ 0.0607 -0.0152]]\n",
      "loss = 1.3307\n",
      "\n",
      "\n",
      "tensor([[0.1040, 0.0555],\n",
      "        [0.0464, 0.0031]])\n",
      "Iterarion 218\n",
      "eta = \n",
      "[[ 0.3298 -0.4898]\n",
      " [ 0.0602 -0.0154]]\n",
      "loss = 1.3282\n",
      "\n",
      "\n",
      "tensor([[-0.1057,  0.0012],\n",
      "        [ 0.0026,  0.0076]])\n",
      "Iterarion 219\n",
      "eta = \n",
      "[[ 0.3298 -0.4907]\n",
      " [ 0.0596 -0.0166]]\n",
      "loss = 1.2308\n",
      "\n",
      "\n",
      "tensor([[-0.0775, -0.0051],\n",
      "        [-0.0333,  0.0046]])\n",
      "Iterarion 220\n",
      "eta = \n",
      "[[ 0.3298 -0.4916]\n",
      " [ 0.0599 -0.0184]]\n",
      "loss = 1.3886\n",
      "\n",
      "\n",
      "tensor([[0.1002, 0.0394],\n",
      "        [0.0066, 0.0003]])\n",
      "Iterarion 221\n",
      "eta = \n",
      "[[ 0.3298 -0.4928]\n",
      " [ 0.06   -0.0201]]\n",
      "loss = 1.2132\n",
      "\n",
      "\n",
      "tensor([[-0.0493, -0.0118],\n",
      "        [ 0.0407,  0.0083]])\n",
      "Iterarion 222\n",
      "eta = \n",
      "[[ 0.3298 -0.4938]\n",
      " [ 0.0592 -0.0228]]\n",
      "loss = 1.3630\n",
      "\n",
      "\n",
      "tensor([[0.0748, 0.0805],\n",
      "        [0.0300, 0.0037]])\n",
      "Iterarion 223\n",
      "eta = \n",
      "[[ 0.3298 -0.4958]\n",
      " [ 0.0577 -0.0258]]\n",
      "loss = 1.3387\n",
      "\n",
      "\n",
      "tensor([[-0.0311, -0.0203],\n",
      "        [-0.0293, -0.0010]])\n",
      "Iterarion 224\n",
      "eta = \n",
      "[[ 0.3297 -0.4973]\n",
      " [ 0.057  -0.0283]]\n",
      "loss = 1.4027\n",
      "\n",
      "\n",
      "tensor([[-0.0781, -0.0498],\n",
      "        [-0.0064, -0.0010]])\n",
      "Iterarion 225\n",
      "eta = \n",
      "[[ 0.3298 -0.498 ]\n",
      " [ 0.0566 -0.0305]]\n",
      "loss = 1.2597\n",
      "\n",
      "\n",
      "tensor([[-0.0124, -0.0273],\n",
      "        [-0.0239, -0.0057]])\n",
      "Iterarion 226\n",
      "eta = \n",
      "[[ 0.3299 -0.4983]\n",
      " [ 0.0568 -0.0316]]\n",
      "loss = 1.3934\n",
      "\n",
      "\n",
      "tensor([[-0.0492, -0.0439],\n",
      "        [-0.0016,  0.0009]])\n",
      "Iterarion 227\n",
      "eta = \n",
      "[[ 0.33   -0.4979]\n",
      " [ 0.057  -0.0327]]\n",
      "loss = 1.3313\n",
      "\n",
      "\n",
      "tensor([[-0.1020, -0.0710],\n",
      "        [-0.0038, -0.0059]])\n",
      "Iterarion 228\n",
      "eta = \n",
      "[[ 0.3303 -0.4965]\n",
      " [ 0.0572 -0.0329]]\n",
      "loss = 1.2441\n",
      "\n",
      "\n",
      "tensor([[-0.0293, -0.0053],\n",
      "        [-0.0016,  0.0011]])\n",
      "Iterarion 229\n",
      "eta = \n",
      "[[ 0.3306 -0.4953]\n",
      " [ 0.0575 -0.0332]]\n",
      "loss = 1.2505\n",
      "\n",
      "\n",
      "tensor([[ 0.0099, -0.0146],\n",
      "        [-0.0393, -0.0035]])\n",
      "Iterarion 230\n",
      "eta = \n",
      "[[ 0.3308 -0.4939]\n",
      " [ 0.0587 -0.0329]]\n",
      "loss = 1.3233\n",
      "\n",
      "\n",
      "tensor([[ 0.1382,  0.0606],\n",
      "        [-0.0297, -0.0119]])\n",
      "Iterarion 231\n",
      "eta = \n",
      "[[ 0.3308 -0.4935]\n",
      " [ 0.0604 -0.0309]]\n",
      "loss = 1.3329\n",
      "\n",
      "\n",
      "tensor([[0.0176, 0.0089],\n",
      "        [0.0407, 0.0074]])\n",
      "Iterarion 232\n",
      "eta = \n",
      "[[ 0.3308 -0.4933]\n",
      " [ 0.061  -0.0303]]\n",
      "loss = 1.1839\n",
      "\n",
      "\n",
      "tensor([[-0.0042,  0.0411],\n",
      "        [ 0.0104,  0.0030]])\n",
      "Iterarion 233\n",
      "eta = \n",
      "[[ 0.3309 -0.4937]\n",
      " [ 0.0613 -0.0301]]\n",
      "loss = 1.2143\n",
      "\n",
      "\n",
      "tensor([[-0.0344, -0.0212],\n",
      "        [-0.0062, -0.0033]])\n",
      "Iterarion 234\n",
      "eta = \n",
      "[[ 0.3309 -0.4937]\n",
      " [ 0.0618 -0.0294]]\n",
      "loss = 1.2533\n",
      "\n",
      "\n",
      "tensor([[-0.0056, -0.0406],\n",
      "        [ 0.0660,  0.0063]])\n",
      "Iterarion 235\n",
      "eta = \n",
      "[[ 0.331  -0.4932]\n",
      " [ 0.0606 -0.0298]]\n",
      "loss = 1.4338\n",
      "\n",
      "\n",
      "tensor([[ 0.1357,  0.0509],\n",
      "        [ 0.0082, -0.0066]])\n",
      "Iterarion 236\n",
      "eta = \n",
      "[[ 0.3308 -0.4934]\n",
      " [ 0.0594 -0.0291]]\n",
      "loss = 1.2087\n",
      "\n",
      "\n",
      "tensor([[-0.0117, -0.0130],\n",
      "        [-0.0492, -0.0051]])\n",
      "Iterarion 237\n",
      "eta = \n",
      "[[ 0.3307 -0.4935]\n",
      " [ 0.0594 -0.0278]]\n",
      "loss = 1.2907\n",
      "\n",
      "\n",
      "tensor([[0.0258, 0.0068],\n",
      "        [0.0379, 0.0064]])\n",
      "Iterarion 238\n",
      "eta = \n",
      "[[ 0.3306 -0.4936]\n",
      " [ 0.0585 -0.0275]]\n",
      "loss = 1.3542\n",
      "\n",
      "\n",
      "tensor([[-0.0354,  0.0124],\n",
      "        [-0.0576, -0.0054]])\n",
      "Iterarion 239\n",
      "eta = \n",
      "[[ 0.3305 -0.4939]\n",
      " [ 0.0591 -0.0265]]\n",
      "loss = 1.3425\n",
      "\n",
      "\n",
      "tensor([[-0.0616, -0.0688],\n",
      "        [ 0.0355,  0.0081]])\n",
      "Iterarion 240\n",
      "eta = \n",
      "[[ 0.3306 -0.4932]\n",
      " [ 0.0588 -0.0268]]\n",
      "loss = 1.3020\n",
      "\n",
      "\n",
      "tensor([[-0.0089, -0.0150],\n",
      "        [ 0.0095, -0.0012]])\n",
      "Iterarion 241\n",
      "eta = \n",
      "[[ 0.3306 -0.4923]\n",
      " [ 0.0583 -0.0268]]\n",
      "loss = 1.3232\n",
      "\n",
      "\n",
      "tensor([[-0.0343,  0.0165],\n",
      "        [-0.0022,  0.0019]])\n",
      "Iterarion 242\n",
      "eta = \n",
      "[[ 0.3307 -0.4918]\n",
      " [ 0.0579 -0.0272]]\n",
      "loss = 1.3912\n",
      "\n",
      "\n",
      "tensor([[ 0.0054,  0.0241],\n",
      "        [-0.0078,  0.0029]])\n",
      "Iterarion 243\n",
      "eta = \n",
      "[[ 0.3307 -0.4916]\n",
      " [ 0.0577 -0.0279]]\n",
      "loss = 1.2523\n",
      "\n",
      "\n",
      "tensor([[ 0.0120, -0.0008],\n",
      "        [-0.0222, -0.0004]])\n",
      "Iterarion 244\n",
      "eta = \n",
      "[[ 0.3308 -0.4915]\n",
      " [ 0.0581 -0.0285]]\n",
      "loss = 1.1372\n",
      "\n",
      "\n",
      "tensor([[-0.0650, -0.0278],\n",
      "        [-0.0206,  0.0033]])\n",
      "Iterarion 245\n",
      "eta = \n",
      "[[ 0.3309 -0.491 ]\n",
      " [ 0.0589 -0.0296]]\n",
      "loss = 1.2212\n",
      "\n",
      "\n",
      "tensor([[-0.0118,  0.0018],\n",
      "        [ 0.0204, -0.0039]])\n",
      "Iterarion 246\n",
      "eta = \n",
      "[[ 0.331  -0.4905]\n",
      " [ 0.0591 -0.03  ]]\n",
      "loss = 1.2156\n",
      "\n",
      "\n",
      "tensor([[-0.0300,  0.0063],\n",
      "        [-0.0562, -0.0018]])\n",
      "Iterarion 247\n",
      "eta = \n",
      "[[ 0.3312 -0.4902]\n",
      " [ 0.0607 -0.03  ]]\n",
      "loss = 1.2808\n",
      "\n",
      "\n",
      "tensor([[0.0804, 0.0437],\n",
      "        [0.0175, 0.0015]])\n",
      "Iterarion 248\n",
      "eta = \n",
      "[[ 0.3312 -0.4905]\n",
      " [ 0.0617 -0.0303]]\n",
      "loss = 1.3892\n",
      "\n",
      "\n",
      "tensor([[-0.0706, -0.0886],\n",
      "        [ 0.0235,  0.0111]])\n",
      "Iterarion 249\n",
      "eta = \n",
      "[[ 0.3313 -0.4896]\n",
      " [ 0.062  -0.0322]]\n",
      "loss = 1.4769\n",
      "\n",
      "\n",
      "tensor([[ 0.0755, -0.0163],\n",
      "        [ 0.0267,  0.0003]])\n",
      "Iterarion 250\n",
      "eta = \n",
      "[[ 0.3313 -0.4885]\n",
      " [ 0.0617 -0.034 ]]\n",
      "loss = 1.3108\n",
      "\n",
      "\n",
      "tensor([[-0.0474, -0.0165],\n",
      "        [ 0.0335,  0.0065]])\n",
      "Iterarion 251\n",
      "eta = \n",
      "[[ 0.3314 -0.4872]\n",
      " [ 0.0606 -0.0365]]\n",
      "loss = 1.2851\n",
      "\n",
      "\n",
      "tensor([[ 0.0366,  0.0402],\n",
      "        [-0.0431, -0.0066]])\n",
      "Iterarion 252\n",
      "eta = \n",
      "[[ 0.3314 -0.4867]\n",
      " [ 0.0606 -0.0378]]\n",
      "loss = 1.3667\n",
      "\n",
      "\n",
      "tensor([[-0.0121, -0.0126],\n",
      "        [-0.0198, -0.0024]])\n",
      "Iterarion 253\n",
      "eta = \n",
      "[[ 0.3315 -0.4861]\n",
      " [ 0.0611 -0.0387]]\n",
      "loss = 1.2770\n",
      "\n",
      "\n",
      "tensor([[ 0.0429,  0.0059],\n",
      "        [-0.0149, -0.0052]])\n",
      "Iterarion 254\n",
      "eta = \n",
      "[[ 0.3314 -0.4855]\n",
      " [ 0.0619 -0.0387]]\n",
      "loss = 1.2626\n",
      "\n",
      "\n",
      "tensor([[-0.0170,  0.0242],\n",
      "        [-0.0279, -0.0100]])\n",
      "Iterarion 255\n",
      "eta = \n",
      "[[ 0.3314 -0.4854]\n",
      " [ 0.0634 -0.0372]]\n",
      "loss = 1.3685\n",
      "\n",
      "\n",
      "tensor([[ 0.0956,  0.0538],\n",
      "        [ 0.0156, -0.0013]])\n",
      "Iterarion 256\n",
      "eta = \n",
      "[[ 0.3313 -0.4861]\n",
      " [ 0.0643 -0.0356]]\n",
      "loss = 1.3768\n",
      "\n",
      "\n",
      "tensor([[0.0699, 0.0102],\n",
      "        [0.0408, 0.0003]])\n",
      "Iterarion 257\n",
      "eta = \n",
      "[[ 0.3311 -0.4869]\n",
      " [ 0.0641 -0.0342]]\n",
      "loss = 1.2857\n",
      "\n",
      "\n",
      "tensor([[-0.1200, -0.0915],\n",
      "        [ 0.0300,  0.0009]])\n",
      "Iterarion 258\n",
      "eta = \n",
      "[[ 0.331  -0.4862]\n",
      " [ 0.0632 -0.0331]]\n",
      "loss = 1.3423\n",
      "\n",
      "\n",
      "tensor([[ 0.1332,  0.0304],\n",
      "        [ 0.0291, -0.0060]])\n",
      "Iterarion 259\n",
      "eta = \n",
      "[[ 0.3308 -0.4861]\n",
      " [ 0.0617 -0.0312]]\n",
      "loss = 1.3172\n",
      "\n",
      "\n",
      "tensor([[ 0.0020, -0.0234],\n",
      "        [-0.0109,  0.0013]])\n",
      "Iterarion 260\n",
      "eta = \n",
      "[[ 0.3306 -0.4856]\n",
      " [ 0.0606 -0.0297]]\n",
      "loss = 1.2586\n",
      "\n",
      "\n",
      "tensor([[-0.0372, -0.0259],\n",
      "        [-0.0468, -0.0028]])\n",
      "Iterarion 261\n",
      "eta = \n",
      "[[ 0.3305 -0.4848]\n",
      " [ 0.0608 -0.028 ]]\n",
      "loss = 1.2645\n",
      "\n",
      "\n",
      "tensor([[ 0.0859,  0.0515],\n",
      "        [-0.0228, -0.0086]])\n",
      "Iterarion 262\n",
      "eta = \n",
      "[[ 0.3302 -0.4849]\n",
      " [ 0.0614 -0.0251]]\n",
      "loss = 1.3151\n",
      "\n",
      "\n",
      "tensor([[ 0.0103,  0.0468],\n",
      "        [-0.0309,  0.0007]])\n",
      "Iterarion 263\n",
      "eta = \n",
      "[[ 0.33   -0.4856]\n",
      " [ 0.0628 -0.0226]]\n",
      "loss = 1.2750\n",
      "\n",
      "\n",
      "tensor([[-0.0542, -0.0109],\n",
      "        [ 0.0212,  0.0097]])\n",
      "Iterarion 264\n",
      "eta = \n",
      "[[ 0.3299 -0.4861]\n",
      " [ 0.0635 -0.0218]]\n",
      "loss = 1.2957\n",
      "\n",
      "\n",
      "tensor([[ 0.0297, -0.0061],\n",
      "        [ 0.0608,  0.0072]])\n",
      "Iterarion 265\n",
      "eta = \n",
      "[[ 0.3297 -0.4864]\n",
      " [ 0.0627 -0.0222]]\n",
      "loss = 1.3269\n",
      "\n",
      "\n",
      "tensor([[-0.0239, -0.0180],\n",
      "        [ 0.0544,  0.0086]])\n",
      "Iterarion 266\n",
      "eta = \n",
      "[[ 0.3296 -0.4865]\n",
      " [ 0.0607 -0.0238]]\n",
      "loss = 1.3399\n",
      "\n",
      "\n",
      "tensor([[ 0.0578,  0.0230],\n",
      "        [-0.0174,  0.0049]])\n",
      "Iterarion 267\n",
      "eta = \n",
      "[[ 0.3294 -0.4869]\n",
      " [ 0.0592 -0.026 ]]\n",
      "loss = 1.2774\n",
      "\n",
      "\n",
      "tensor([[-0.0604, -0.1022],\n",
      "        [-0.0481, -0.0030]])\n",
      "Iterarion 268\n",
      "eta = \n",
      "[[ 0.3293 -0.4857]\n",
      " [ 0.0591 -0.0275]]\n",
      "loss = 1.2730\n",
      "\n",
      "\n",
      "tensor([[-0.0484, -0.0160],\n",
      "        [ 0.0966,  0.0110]])\n",
      "Iterarion 269\n",
      "eta = \n",
      "[[ 0.3293 -0.4844]\n",
      " [ 0.0567 -0.0305]]\n",
      "loss = 1.3268\n",
      "\n",
      "\n",
      "tensor([[ 0.0198,  0.0078],\n",
      "        [ 0.0017, -0.0007]])\n",
      "Iterarion 270\n",
      "eta = \n",
      "[[ 0.3293 -0.4834]\n",
      " [ 0.0544 -0.0332]]\n",
      "loss = 1.2218\n",
      "\n",
      "\n",
      "tensor([[-0.0349, -0.0190],\n",
      "        [ 0.0022, -0.0017]])\n",
      "Iterarion 271\n",
      "eta = \n",
      "[[ 0.3293 -0.4822]\n",
      " [ 0.0524 -0.0353]]\n",
      "loss = 1.2733\n",
      "\n",
      "\n",
      "tensor([[-0.0527, -0.0663],\n",
      "        [-0.0897, -0.0135]])\n",
      "Iterarion 272\n",
      "eta = \n",
      "[[ 0.3294 -0.4801]\n",
      " [ 0.0527 -0.0351]]\n",
      "loss = 1.2445\n",
      "\n",
      "\n",
      "tensor([[ 0.0248,  0.0198],\n",
      "        [-0.0168, -0.0039]])\n",
      "Iterarion 273\n",
      "eta = \n",
      "[[ 0.3295 -0.4785]\n",
      " [ 0.0533 -0.0344]]\n",
      "loss = 1.2220\n",
      "\n",
      "\n",
      "tensor([[-0.0250,  0.0172],\n",
      "        [-0.0842, -0.0113]])\n",
      "Iterarion 274\n",
      "eta = \n",
      "[[ 0.3296 -0.4773]\n",
      " [ 0.0559 -0.0321]]\n",
      "loss = 1.3178\n",
      "\n",
      "\n",
      "tensor([[-0.0097,  0.0128],\n",
      "        [-0.0573, -0.0052]])\n",
      "Iterarion 275\n",
      "eta = \n",
      "[[ 0.3297 -0.4765]\n",
      " [ 0.0597 -0.0293]]\n",
      "loss = 1.2902\n",
      "\n",
      "\n",
      "tensor([[-0.0033, -0.0123],\n",
      "        [-0.0378, -0.0056]])\n",
      "Iterarion 276\n",
      "eta = \n",
      "[[ 0.3298 -0.4755]\n",
      " [ 0.0639 -0.0259]]\n",
      "loss = 1.3511\n",
      "\n",
      "\n",
      "tensor([[ 0.0575,  0.0548],\n",
      "        [ 0.0060, -0.0010]])\n",
      "Iterarion 277\n",
      "eta = \n",
      "[[ 0.3298 -0.4755]\n",
      " [ 0.0676 -0.0226]]\n",
      "loss = 1.2782\n",
      "\n",
      "\n",
      "tensor([[-0.0522, -0.0703],\n",
      "        [ 0.0669,  0.0132]])\n",
      "Iterarion 278\n",
      "eta = \n",
      "[[ 0.3298 -0.4744]\n",
      " [ 0.0693 -0.0217]]\n",
      "loss = 1.3028\n",
      "\n",
      "\n",
      "tensor([[-0.0783, -0.0171],\n",
      "        [ 0.0584,  0.0164]])\n",
      "Iterarion 279\n",
      "eta = \n",
      "[[ 0.33   -0.4731]\n",
      " [ 0.0694 -0.0233]]\n",
      "loss = 1.3796\n",
      "\n",
      "\n",
      "tensor([[0.0422, 0.0379],\n",
      "        [0.0776, 0.0110]])\n",
      "Iterarion 280\n",
      "eta = \n",
      "[[ 0.3301 -0.4726]\n",
      " [ 0.0677 -0.0264]]\n",
      "loss = 1.2941\n",
      "\n",
      "\n",
      "tensor([[-0.0541, -0.0508],\n",
      "        [ 0.1012,  0.0178]])\n",
      "Iterarion 281\n",
      "eta = \n",
      "[[ 0.3303 -0.4713]\n",
      " [ 0.0639 -0.0317]]\n",
      "loss = 1.2652\n",
      "\n",
      "\n",
      "tensor([[ 0.0233, -0.0002],\n",
      "        [ 0.0176, -0.0005]])\n",
      "Iterarion 282\n",
      "eta = \n",
      "[[ 0.3304 -0.4702]\n",
      " [ 0.0599 -0.0364]]\n",
      "loss = 1.2705\n",
      "\n",
      "\n",
      "tensor([[-3.1604e-02, -1.2504e-02],\n",
      "        [ 9.4941e-05,  1.4322e-03]])\n",
      "Iterarion 283\n",
      "eta = \n",
      "[[ 0.3306 -0.469 ]\n",
      " [ 0.0564 -0.0408]]\n",
      "loss = 1.3849\n",
      "\n",
      "\n",
      "tensor([[-0.0097, -0.0203],\n",
      "        [-0.0379, -0.0072]])\n",
      "Iterarion 284\n",
      "eta = \n",
      "[[ 0.3307 -0.4676]\n",
      " [ 0.0541 -0.0438]]\n",
      "loss = 1.3107\n",
      "\n",
      "\n",
      "tensor([[-0.0279, -0.0471],\n",
      "        [-0.0724, -0.0140]])\n",
      "Iterarion 285\n",
      "eta = \n",
      "[[ 0.3309 -0.4656]\n",
      " [ 0.0538 -0.0444]]\n",
      "loss = 1.3311\n",
      "\n",
      "\n",
      "tensor([[ 0.1252,  0.0570],\n",
      "        [-0.0755, -0.0187]])\n",
      "Iterarion 286\n",
      "eta = \n",
      "[[ 0.3309 -0.4647]\n",
      " [ 0.0552 -0.0423]]\n",
      "loss = 1.3175\n",
      "\n",
      "\n",
      "tensor([[ 0.0919,  0.0002],\n",
      "        [-0.0696, -0.0155]])\n",
      "Iterarion 287\n",
      "eta = \n",
      "[[ 0.3307 -0.4639]\n",
      " [ 0.0581 -0.0381]]\n",
      "loss = 1.2733\n",
      "\n",
      "\n",
      "tensor([[ 0.0391,  0.0263],\n",
      "        [-0.0302, -0.0065]])\n",
      "Iterarion 288\n",
      "eta = \n",
      "[[ 0.3305 -0.4635]\n",
      " [ 0.0614 -0.0335]]\n",
      "loss = 1.2414\n",
      "\n",
      "\n",
      "tensor([[-4.0818e-02, -2.2430e-02],\n",
      "        [ 9.8948e-05, -1.9642e-03]])\n",
      "Iterarion 289\n",
      "eta = \n",
      "[[ 0.3304 -0.4629]\n",
      " [ 0.0644 -0.0291]]\n",
      "loss = 1.2750\n",
      "\n",
      "\n",
      "tensor([[-0.0309, -0.0134],\n",
      "        [ 0.0878,  0.0122]])\n",
      "Iterarion 290\n",
      "eta = \n",
      "[[ 0.3303 -0.4621]\n",
      " [ 0.0651 -0.0268]]\n",
      "loss = 1.3340\n",
      "\n",
      "\n",
      "tensor([[ 0.0002,  0.0053],\n",
      "        [-0.0330, -0.0041]])\n",
      "Iterarion 291\n",
      "eta = \n",
      "[[ 0.3303 -0.4614]\n",
      " [ 0.0664 -0.0242]]\n",
      "loss = 1.3603\n",
      "\n",
      "\n",
      "tensor([[0.1032, 0.0691],\n",
      "        [0.0536, 0.0040]])\n",
      "Iterarion 292\n",
      "eta = \n",
      "[[ 0.33   -0.4619]\n",
      " [ 0.0664 -0.0224]]\n",
      "loss = 1.3036\n",
      "\n",
      "\n",
      "tensor([[0.0641, 0.0225],\n",
      "        [0.0174, 0.0014]])\n",
      "Iterarion 293\n",
      "eta = \n",
      "[[ 0.3298 -0.4627]\n",
      " [ 0.066  -0.021 ]]\n",
      "loss = 1.3753\n",
      "\n",
      "\n",
      "tensor([[0.0855, 0.0735],\n",
      "        [0.1155, 0.0117]])\n",
      "Iterarion 294\n",
      "eta = \n",
      "[[ 0.3294 -0.4645]\n",
      " [ 0.0629 -0.0214]]\n",
      "loss = 1.3201\n",
      "\n",
      "\n",
      "tensor([[ 0.0395,  0.0221],\n",
      "        [-0.0059,  0.0004]])\n",
      "Iterarion 295\n",
      "eta = \n",
      "[[ 0.329  -0.4665]\n",
      " [ 0.0603 -0.0218]]\n",
      "loss = 1.2993\n",
      "\n",
      "\n",
      "tensor([[ 0.1187,  0.0468],\n",
      "        [ 0.0005, -0.0040]])\n",
      "Iterarion 296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta = \n",
      "[[ 0.3284 -0.469 ]\n",
      " [ 0.058  -0.0216]]\n",
      "loss = 1.4023\n",
      "\n",
      "\n",
      "tensor([[ 0.0268,  0.0054],\n",
      "        [-0.0540, -0.0035]])\n",
      "Iterarion 297\n",
      "eta = \n",
      "[[ 0.3279 -0.4714]\n",
      " [ 0.0571 -0.0209]]\n",
      "loss = 1.2270\n",
      "\n",
      "\n",
      "tensor([[-0.0131, -0.0298],\n",
      "        [ 0.0010,  0.0047]])\n",
      "Iterarion 298\n",
      "eta = \n",
      "[[ 0.3274 -0.473 ]\n",
      " [ 0.0563 -0.021 ]]\n",
      "loss = 1.3253\n",
      "\n",
      "\n",
      "tensor([[-0.0040, -0.0131],\n",
      "        [ 0.0531,  0.0061]])\n",
      "Iterarion 299\n",
      "eta = \n",
      "[[ 0.327  -0.4743]\n",
      " [ 0.0543 -0.0219]]\n",
      "loss = 1.2961\n",
      "\n",
      "\n",
      "tensor([[-6.1151e-02, -2.0433e-04],\n",
      "        [-4.6884e-02, -2.6833e-05]])\n",
      "Iterarion 300\n",
      "eta = \n",
      "[[ 0.3267 -0.4755]\n",
      " [ 0.0537 -0.0228]]\n",
      "loss = 1.3021\n",
      "\n",
      "\n",
      "tensor([[-0.0390, -0.0535],\n",
      "        [-0.0532,  0.0033]])\n",
      "Iterarion 301\n",
      "eta = \n",
      "[[ 0.3265 -0.4757]\n",
      " [ 0.0543 -0.024 ]]\n",
      "loss = 1.3467\n",
      "\n",
      "\n",
      "tensor([[-0.0268, -0.0164],\n",
      "        [-0.0427,  0.0027]])\n",
      "Iterarion 302\n",
      "eta = \n",
      "[[ 0.3264 -0.4756]\n",
      " [ 0.0558 -0.0255]]\n",
      "loss = 1.2743\n",
      "\n",
      "\n",
      "tensor([[-0.0287, -0.0577],\n",
      "        [-0.0181,  0.0009]])\n",
      "Iterarion 303\n",
      "eta = \n",
      "[[ 0.3263 -0.4747]\n",
      " [ 0.0576 -0.027 ]]\n",
      "loss = 1.3089\n",
      "\n",
      "\n",
      "tensor([[-0.0087, -0.0104],\n",
      "        [ 0.0061, -0.0012]])\n",
      "Iterarion 304\n",
      "eta = \n",
      "[[ 0.3262 -0.4737]\n",
      " [ 0.0591 -0.0281]]\n",
      "loss = 1.3935\n",
      "\n",
      "\n",
      "tensor([[-0.0939, -0.0392],\n",
      "        [-0.0087,  0.0033]])\n",
      "Iterarion 305\n",
      "eta = \n",
      "[[ 0.3263 -0.4722]\n",
      " [ 0.0606 -0.0296]]\n",
      "loss = 1.2422\n",
      "\n",
      "\n",
      "tensor([[-0.0737,  0.0435],\n",
      "        [ 0.0697,  0.0062]])\n",
      "Iterarion 306\n",
      "eta = \n",
      "[[ 0.3265 -0.4715]\n",
      " [ 0.0604 -0.0319]]\n",
      "loss = 1.2144\n",
      "\n",
      "\n",
      "tensor([[ 0.0085,  0.0183],\n",
      "        [ 0.0249, -0.0003]])\n",
      "Iterarion 307\n",
      "eta = \n",
      "[[ 0.3267 -0.4711]\n",
      " [ 0.0596 -0.0339]]\n",
      "loss = 1.2056\n",
      "\n",
      "\n",
      "tensor([[ 0.0042,  0.0092],\n",
      "        [ 0.0114, -0.0036]])\n",
      "Iterarion 308\n",
      "eta = \n",
      "[[ 0.3269 -0.471 ]\n",
      " [ 0.0586 -0.0352]]\n",
      "loss = 1.3415\n",
      "\n",
      "\n",
      "tensor([[-0.0007,  0.0283],\n",
      "        [-0.0373, -0.0075]])\n",
      "Iterarion 309\n",
      "eta = \n",
      "[[ 0.327  -0.4713]\n",
      " [ 0.0586 -0.0352]]\n",
      "loss = 1.3285\n",
      "\n",
      "\n",
      "tensor([[-0.0639, -0.0071],\n",
      "        [-0.0104, -0.0004]])\n",
      "Iterarion 310\n",
      "eta = \n",
      "[[ 0.3272 -0.4714]\n",
      " [ 0.0589 -0.0352]]\n",
      "loss = 1.2576\n",
      "\n",
      "\n",
      "tensor([[-0.0416, -0.0617],\n",
      "        [-0.0644, -0.0076]])\n",
      "Iterarion 311\n",
      "eta = \n",
      "[[ 0.3275 -0.4706]\n",
      " [ 0.0606 -0.0341]]\n",
      "loss = 1.2731\n",
      "\n",
      "\n",
      "tensor([[-0.0358,  0.0176],\n",
      "        [ 0.0035, -0.0038]])\n",
      "Iterarion 312\n",
      "eta = \n",
      "[[ 0.3278 -0.4701]\n",
      " [ 0.062  -0.0326]]\n",
      "loss = 1.2637\n",
      "\n",
      "\n",
      "tensor([[-0.0329, -0.0448],\n",
      "        [ 0.0321,  0.0076]])\n",
      "Iterarion 313\n",
      "eta = \n",
      "[[ 0.3281 -0.469 ]\n",
      " [ 0.0626 -0.0323]]\n",
      "loss = 1.1993\n",
      "\n",
      "\n",
      "tensor([[-0.0729, -0.0236],\n",
      "        [ 0.0324,  0.0043]])\n",
      "Iterarion 314\n",
      "eta = \n",
      "[[ 0.3285 -0.4676]\n",
      " [ 0.0623 -0.0327]]\n",
      "loss = 1.2592\n",
      "\n",
      "\n",
      "tensor([[ 0.0022, -0.0098],\n",
      "        [ 0.0168,  0.0029]])\n",
      "Iterarion 315\n",
      "eta = \n",
      "[[ 0.3289 -0.4662]\n",
      " [ 0.0617 -0.0334]]\n",
      "loss = 1.2730\n",
      "\n",
      "\n",
      "tensor([[ 0.0463, -0.0038],\n",
      "        [-0.0148, -0.0047]])\n",
      "Iterarion 316\n",
      "eta = \n",
      "[[ 0.3291 -0.4649]\n",
      " [ 0.0615 -0.0334]]\n",
      "loss = 1.2878\n",
      "\n",
      "\n",
      "tensor([[ 0.0134,  0.0050],\n",
      "        [-0.0012,  0.0014]])\n",
      "Iterarion 317\n",
      "eta = \n",
      "[[ 0.3293 -0.4638]\n",
      " [ 0.0614 -0.0336]]\n",
      "loss = 1.3624\n",
      "\n",
      "\n",
      "tensor([[0.0356, 0.0309],\n",
      "        [0.0170, 0.0012]])\n",
      "Iterarion 318\n",
      "eta = \n",
      "[[ 0.3295 -0.4632]\n",
      " [ 0.0608 -0.0339]]\n",
      "loss = 1.2769\n",
      "\n",
      "\n",
      "tensor([[-0.0665, -0.0183],\n",
      "        [-0.0314,  0.0010]])\n",
      "Iterarion 319\n",
      "eta = \n",
      "[[ 0.3297 -0.4625]\n",
      " [ 0.0611 -0.0344]]\n",
      "loss = 1.2516\n",
      "\n",
      "\n",
      "tensor([[-0.1004, -0.0284],\n",
      "        [ 0.0025,  0.0024]])\n",
      "Iterarion 320\n",
      "eta = \n",
      "[[ 0.3301 -0.4613]\n",
      " [ 0.0612 -0.0352]]\n",
      "loss = 1.3192\n",
      "\n",
      "\n",
      "tensor([[-0.0431,  0.0050],\n",
      "        [-0.0191, -0.0056]])\n",
      "Iterarion 321\n",
      "eta = \n",
      "[[ 0.3304 -0.4604]\n",
      " [ 0.0618 -0.035 ]]\n",
      "loss = 1.2091\n",
      "\n",
      "\n",
      "tensor([[ 0.0838,  0.0318],\n",
      "        [-0.0294, -0.0044]])\n",
      "Iterarion 322\n",
      "eta = \n",
      "[[ 0.3307 -0.4601]\n",
      " [ 0.0631 -0.0343]]\n",
      "loss = 1.2845\n",
      "\n",
      "\n",
      "tensor([[-0.0896, -0.0357],\n",
      "        [ 0.0306,  0.0076]])\n",
      "Iterarion 323\n",
      "eta = \n",
      "[[ 0.331  -0.4592]\n",
      " [ 0.0635 -0.0347]]\n",
      "loss = 1.3251\n",
      "\n",
      "\n",
      "tensor([[0.0079, 0.0188],\n",
      "        [0.0212, 0.0012]])\n",
      "Iterarion 324\n",
      "eta = \n",
      "[[ 0.3313 -0.4587]\n",
      " [ 0.0633 -0.0352]]\n",
      "loss = 1.2565\n",
      "\n",
      "\n",
      "tensor([[ 0.0683,  0.0349],\n",
      "        [ 0.0496, -0.0003]])\n",
      "Iterarion 325\n",
      "eta = \n",
      "[[ 0.3315 -0.4588]\n",
      " [ 0.062  -0.0357]]\n",
      "loss = 1.3478\n",
      "\n",
      "\n",
      "tensor([[-0.0058,  0.0292],\n",
      "        [-0.0447, -0.0040]])\n",
      "Iterarion 326\n",
      "eta = \n",
      "[[ 0.3316 -0.4594]\n",
      " [ 0.0619 -0.0355]]\n",
      "loss = 1.1678\n",
      "\n",
      "\n",
      "tensor([[-0.0117, -0.0117],\n",
      "        [ 0.0078, -0.0032]])\n",
      "Iterarion 327\n",
      "eta = \n",
      "[[ 0.3318 -0.4597]\n",
      " [ 0.0616 -0.0349]]\n",
      "loss = 1.2751\n",
      "\n",
      "\n",
      "tensor([[-0.0438, -0.0285],\n",
      "        [ 0.0066,  0.0014]])\n",
      "Iterarion 328\n",
      "eta = \n",
      "[[ 0.332  -0.4595]\n",
      " [ 0.0612 -0.0345]]\n",
      "loss = 1.3775\n",
      "\n",
      "\n",
      "tensor([[ 0.0908,  0.0171],\n",
      "        [ 0.0312, -0.0030]])\n",
      "Iterarion 329\n",
      "eta = \n",
      "[[ 0.332  -0.4597]\n",
      " [ 0.0601 -0.0338]]\n",
      "loss = 1.2275\n",
      "\n",
      "\n",
      "tensor([[-0.0041, -0.0207],\n",
      "        [-0.0001, -0.0031]])\n",
      "Iterarion 330\n",
      "eta = \n",
      "[[ 0.3321 -0.4595]\n",
      " [ 0.0591 -0.0326]]\n",
      "loss = 1.3274\n",
      "\n",
      "\n",
      "tensor([[ 0.0508,  0.0588],\n",
      "        [-0.0086, -0.0058]])\n",
      "Iterarion 331\n",
      "eta = \n",
      "[[ 0.332  -0.4602]\n",
      " [ 0.0584 -0.0307]]\n",
      "loss = 1.2532\n",
      "\n",
      "\n",
      "tensor([[ 0.0407,  0.0086],\n",
      "        [-0.0039,  0.0007]])\n",
      "Iterarion 332\n",
      "eta = \n",
      "[[ 0.3319 -0.461 ]\n",
      " [ 0.0578 -0.0291]]\n",
      "loss = 1.3017\n",
      "\n",
      "\n",
      "tensor([[ 0.0673, -0.0012],\n",
      "        [-0.0497, -0.0050]])\n",
      "Iterarion 333\n",
      "eta = \n",
      "[[ 0.3317 -0.4617]\n",
      " [ 0.0585 -0.0269]]\n",
      "loss = 1.3265\n",
      "\n",
      "\n",
      "tensor([[ 0.0816,  0.0009],\n",
      "        [-0.0887, -0.0052]])\n",
      "Iterarion 334\n",
      "eta = \n",
      "[[ 0.3314 -0.4624]\n",
      " [ 0.0612 -0.0242]]\n",
      "loss = 1.4076\n",
      "\n",
      "\n",
      "tensor([[0.0525, 0.0427],\n",
      "        [0.0150, 0.0041]])\n",
      "Iterarion 335\n",
      "eta = \n",
      "[[ 0.331  -0.4637]\n",
      " [ 0.0633 -0.0223]]\n",
      "loss = 1.3726\n",
      "\n",
      "\n",
      "tensor([[ 0.0153, -0.0311],\n",
      "        [ 0.0320,  0.0101]])\n",
      "Iterarion 336\n",
      "eta = \n",
      "[[ 0.3307 -0.4643]\n",
      " [ 0.0644 -0.0222]]\n",
      "loss = 1.2769\n",
      "\n",
      "\n",
      "tensor([[-0.0545, -0.0010],\n",
      "        [ 0.0166,  0.0053]])\n",
      "Iterarion 337\n",
      "eta = \n",
      "[[ 0.3304 -0.4649]\n",
      " [ 0.0651 -0.0228]]\n",
      "loss = 1.2694\n",
      "\n",
      "\n",
      "tensor([[0.0466, 0.0553],\n",
      "        [0.0100, 0.0010]])\n",
      "Iterarion 338\n",
      "eta = \n",
      "[[ 0.3301 -0.4663]\n",
      " [ 0.0654 -0.0235]]\n",
      "loss = 1.3969\n",
      "\n",
      "\n",
      "tensor([[-0.0495, -0.0042],\n",
      "        [ 0.0449,  0.0066]])\n",
      "Iterarion 339\n",
      "eta = \n",
      "[[ 0.33   -0.4675]\n",
      " [ 0.0646 -0.0251]]\n",
      "loss = 1.3555\n",
      "\n",
      "\n",
      "tensor([[0.1047, 0.0344],\n",
      "        [0.0019, 0.0068]])\n",
      "Iterarion 340\n",
      "eta = \n",
      "[[ 0.3296 -0.4692]\n",
      " [ 0.0639 -0.0276]]\n",
      "loss = 1.2998\n",
      "\n",
      "\n",
      "tensor([[ 0.1159,  0.0697],\n",
      "        [-0.0225, -0.0019]])\n",
      "Iterarion 341\n",
      "eta = \n",
      "[[ 0.3291 -0.4718]\n",
      " [ 0.0637 -0.0296]]\n",
      "loss = 1.3730\n",
      "\n",
      "\n",
      "tensor([[-0.0419,  0.0165],\n",
      "        [ 0.0236,  0.0039]])\n",
      "Iterarion 342\n",
      "eta = \n",
      "[[ 0.3287 -0.4744]\n",
      " [ 0.0631 -0.0319]]\n",
      "loss = 1.2738\n",
      "\n",
      "\n",
      "tensor([[-0.0275, -0.0341],\n",
      "        [ 0.0740,  0.0057]])\n",
      "Iterarion 343\n",
      "eta = \n",
      "[[ 0.3284 -0.4763]\n",
      " [ 0.0607 -0.0349]]\n",
      "loss = 1.2743\n",
      "\n",
      "\n",
      "tensor([[ 0.0265,  0.0371],\n",
      "        [-0.0149, -0.0068]])\n",
      "Iterarion 344\n",
      "eta = \n",
      "[[ 0.3281 -0.4785]\n",
      " [ 0.0589 -0.0365]]\n",
      "loss = 1.2792\n",
      "\n",
      "\n",
      "tensor([[ 0.0827, -0.0230],\n",
      "        [ 0.0220, -0.0045]])\n",
      "Iterarion 345\n",
      "eta = \n",
      "[[ 0.3277 -0.4802]\n",
      " [ 0.0568 -0.0373]]\n",
      "loss = 1.2550\n",
      "\n",
      "\n",
      "tensor([[-0.0604, -0.0841],\n",
      "        [-0.0463, -0.0036]])\n",
      "Iterarion 346\n",
      "eta = \n",
      "[[ 0.3274 -0.4802]\n",
      " [ 0.056  -0.0375]]\n",
      "loss = 1.2555\n",
      "\n",
      "\n",
      "tensor([[ 0.0247, -0.0308],\n",
      "        [-0.0376, -0.0079]])\n",
      "Iterarion 347\n",
      "eta = \n",
      "[[ 0.3271 -0.4798]\n",
      " [ 0.0562 -0.0365]]\n",
      "loss = 1.3235\n",
      "\n",
      "\n",
      "tensor([[-0.0631, -0.0474],\n",
      "        [ 0.0432,  0.0038]])\n",
      "Iterarion 348\n",
      "eta = \n",
      "[[ 0.327  -0.4787]\n",
      " [ 0.0553 -0.0362]]\n",
      "loss = 1.3071\n",
      "\n",
      "\n",
      "tensor([[ 0.0107,  0.0243],\n",
      "        [-0.0265, -0.0093]])\n",
      "Iterarion 349\n",
      "eta = \n",
      "[[ 0.3268 -0.478 ]\n",
      " [ 0.0551 -0.0345]]\n",
      "loss = 1.3354\n",
      "\n",
      "\n",
      "tensor([[ 0.0460,  0.0629],\n",
      "        [-0.0556, -0.0101]])\n",
      "Iterarion 350\n",
      "eta = \n",
      "[[ 0.3266 -0.4785]\n",
      " [ 0.0563 -0.0315]]\n",
      "loss = 1.3382\n",
      "\n",
      "\n",
      "tensor([[-0.0667, -0.0280],\n",
      "        [-0.0015, -0.0027]])\n",
      "Iterarion 351\n",
      "eta = \n",
      "[[ 0.3265 -0.4784]\n",
      " [ 0.0574 -0.0283]]\n",
      "loss = 1.2600\n",
      "\n",
      "\n",
      "tensor([[-0.0308,  0.0180],\n",
      "        [-0.0211, -0.0040]])\n",
      "Iterarion 352\n",
      "eta = \n",
      "[[ 0.3265 -0.4787]\n",
      " [ 0.0589 -0.0249]]\n",
      "loss = 1.3141\n",
      "\n",
      "\n",
      "tensor([[ 0.0129,  0.0373],\n",
      "        [-0.0257, -0.0026]])\n",
      "Iterarion 353\n",
      "eta = \n",
      "[[ 0.3264 -0.4795]\n",
      " [ 0.0608 -0.0215]]\n",
      "loss = 1.3165\n",
      "\n",
      "\n",
      "tensor([[-0.0147,  0.0081],\n",
      "        [ 0.0454,  0.0090]])\n",
      "Iterarion 354\n",
      "eta = \n",
      "[[ 0.3264 -0.4804]\n",
      " [ 0.0615 -0.0197]]\n",
      "loss = 1.2219\n",
      "\n",
      "\n",
      "tensor([[ 0.0115, -0.0209],\n",
      "        [ 0.0312,  0.0016]])\n",
      "Iterarion 355\n",
      "eta = \n",
      "[[ 0.3264 -0.4809]\n",
      " [ 0.0614 -0.0183]]\n",
      "loss = 1.2675\n",
      "\n",
      "\n",
      "tensor([[-0.0240, -0.0172],\n",
      "        [ 0.0119,  0.0060]])\n",
      "Iterarion 356\n",
      "eta = \n",
      "[[ 0.3264 -0.481 ]\n",
      " [ 0.061  -0.018 ]]\n",
      "loss = 1.3073\n",
      "\n",
      "\n",
      "tensor([[-0.0022,  0.0027],\n",
      "        [ 0.0372,  0.0034]])\n",
      "Iterarion 357\n",
      "eta = \n",
      "[[ 0.3264 -0.4812]\n",
      " [ 0.0597 -0.0182]]\n",
      "loss = 1.3419\n",
      "\n",
      "\n",
      "tensor([[-0.1076, -0.0551],\n",
      "        [ 0.0850,  0.0150]])\n",
      "Iterarion 358\n",
      "eta = \n",
      "[[ 0.3266 -0.4804]\n",
      " [ 0.0566 -0.0206]]\n",
      "loss = 1.3515\n",
      "\n",
      "\n",
      "tensor([[-0.1123,  0.0142],\n",
      "        [ 0.0018,  0.0044]])\n",
      "Iterarion 359\n",
      "eta = \n",
      "[[ 0.327  -0.48  ]\n",
      " [ 0.0537 -0.0235]]\n",
      "loss = 1.3281\n",
      "\n",
      "\n",
      "tensor([[-0.0480, -0.0369],\n",
      "        [ 0.0110,  0.0057]])\n",
      "Iterarion 360\n",
      "eta = \n",
      "[[ 0.3274 -0.4789]\n",
      " [ 0.0508 -0.0269]]\n",
      "loss = 1.2731\n",
      "\n",
      "\n",
      "tensor([[-0.0439, -0.0166],\n",
      "        [-0.0746, -0.0051]])\n",
      "Iterarion 361\n",
      "eta = \n",
      "[[ 0.3279 -0.4777]\n",
      " [ 0.0501 -0.0292]]\n",
      "loss = 1.3024\n",
      "\n",
      "\n",
      "tensor([[-0.0378,  0.0099],\n",
      "        [-0.1022, -0.0092]])\n",
      "Iterarion 362\n",
      "eta = \n",
      "[[ 0.3283 -0.4768]\n",
      " [ 0.0518 -0.0299]]\n",
      "loss = 1.3357\n",
      "\n",
      "\n",
      "tensor([[-0.0280,  0.0027],\n",
      "        [-0.0857, -0.0154]])\n",
      "Iterarion 363\n",
      "eta = \n",
      "[[ 0.3288 -0.476 ]\n",
      " [ 0.0553 -0.0282]]\n",
      "loss = 1.4132\n",
      "\n",
      "\n",
      "tensor([[-0.0329,  0.0039],\n",
      "        [-0.0597, -0.0020]])\n",
      "Iterarion 364\n",
      "eta = \n",
      "[[ 0.3293 -0.4754]\n",
      " [ 0.0599 -0.0264]]\n",
      "loss = 1.3537\n",
      "\n",
      "\n",
      "tensor([[-0.0574, -0.0743],\n",
      "        [ 0.0597,  0.0080]])\n",
      "Iterarion 365\n",
      "eta = \n",
      "[[ 0.3298 -0.4736]\n",
      " [ 0.0626 -0.026 ]]\n",
      "loss = 1.2418\n",
      "\n",
      "\n",
      "tensor([[-0.1039, -0.0513],\n",
      "        [ 0.0525,  0.0050]])\n",
      "Iterarion 366\n",
      "eta = \n",
      "[[ 0.3305 -0.4711]\n",
      " [ 0.0638 -0.0264]]\n",
      "loss = 1.3435\n",
      "\n",
      "\n",
      "tensor([[0.0027, 0.0002],\n",
      "        [0.0160, 0.0021]])\n",
      "Iterarion 367\n",
      "eta = \n",
      "[[ 0.3311 -0.4688]\n",
      " [ 0.0645 -0.027 ]]\n",
      "loss = 1.3451\n",
      "\n",
      "\n",
      "tensor([[-0.0036,  0.0562],\n",
      "        [ 0.0317, -0.0013]])\n",
      "Iterarion 368\n",
      "eta = \n",
      "[[ 0.3317 -0.4677]\n",
      " [ 0.0644 -0.0274]]\n",
      "loss = 1.2485\n",
      "\n",
      "\n",
      "tensor([[-8.6268e-05,  2.3397e-02],\n",
      "        [ 5.8501e-02,  5.3875e-03]])\n",
      "Iterarion 369\n",
      "eta = \n",
      "[[ 0.3321 -0.4672]\n",
      " [ 0.063  -0.0286]]\n",
      "loss = 1.3548\n",
      "\n",
      "\n",
      "tensor([[-0.0277,  0.0025],\n",
      "        [ 0.0056,  0.0040]])\n",
      "Iterarion 370\n",
      "eta = \n",
      "[[ 0.3326 -0.4667]\n",
      " [ 0.0615 -0.0302]]\n",
      "loss = 1.3644\n",
      "\n",
      "\n",
      "tensor([[-0.0338, -0.0516],\n",
      "        [-0.0189, -0.0031]])\n",
      "Iterarion 371\n",
      "eta = \n",
      "[[ 0.3331 -0.4654]\n",
      " [ 0.0607 -0.0312]]\n",
      "loss = 1.2466\n",
      "\n",
      "\n",
      "tensor([[0.0954, 0.0124],\n",
      "        [0.0086, 0.0023]])\n",
      "Iterarion 372\n",
      "eta = \n",
      "[[ 0.3334 -0.4644]\n",
      " [ 0.0597 -0.0325]]\n",
      "loss = 1.3624\n",
      "\n",
      "\n",
      "tensor([[ 0.0818,  0.0458],\n",
      "        [-0.0165, -0.0050]])\n",
      "Iterarion 373\n",
      "eta = \n",
      "[[ 0.3335 -0.4643]\n",
      " [ 0.0592 -0.0328]]\n",
      "loss = 1.1833\n",
      "\n",
      "\n",
      "tensor([[ 0.0197, -0.0018],\n",
      "        [ 0.0569,  0.0010]])\n",
      "Iterarion 374\n",
      "eta = \n",
      "[[ 0.3336 -0.4642]\n",
      " [ 0.0575 -0.0333]]\n",
      "loss = 1.2603\n",
      "\n",
      "\n",
      "tensor([[-0.0074, -0.0243],\n",
      "        [-0.0139, -0.0023]])\n",
      "Iterarion 375\n",
      "eta = \n",
      "[[ 0.3337 -0.4637]\n",
      " [ 0.0562 -0.0334]]\n",
      "loss = 1.2677\n",
      "\n",
      "\n",
      "tensor([[-0.0014,  0.0282],\n",
      "        [-0.0240, -0.0032]])\n",
      "Iterarion 376\n",
      "eta = \n",
      "[[ 0.3337 -0.4637]\n",
      " [ 0.0556 -0.033 ]]\n",
      "loss = 1.2777\n",
      "\n",
      "\n",
      "tensor([[ 0.1047,  0.0191],\n",
      "        [ 0.0043, -0.0036]])\n",
      "Iterarion 377\n",
      "eta = \n",
      "[[ 0.3336 -0.464 ]\n",
      " [ 0.055  -0.0321]]\n",
      "loss = 1.3907\n",
      "\n",
      "\n",
      "tensor([[ 0.0653,  0.0452],\n",
      "        [-0.0220, -0.0029]])\n",
      "Iterarion 378\n",
      "eta = \n",
      "[[ 0.3334 -0.4651]\n",
      " [ 0.0549 -0.0309]]\n",
      "loss = 1.3400\n",
      "\n",
      "\n",
      "tensor([[-0.0255,  0.0037],\n",
      "        [-0.0817, -0.0055]])\n",
      "Iterarion 379\n",
      "eta = \n",
      "[[ 0.3332 -0.4661]\n",
      " [ 0.0568 -0.0289]]\n",
      "loss = 1.3170\n",
      "\n",
      "\n",
      "tensor([[ 0.0172,  0.0462],\n",
      "        [-0.0304, -0.0043]])\n",
      "Iterarion 380\n",
      "eta = \n",
      "[[ 0.3331 -0.4678]\n",
      " [ 0.0592 -0.0265]]\n",
      "loss = 1.3483\n",
      "\n",
      "\n",
      "tensor([[ 0.0222, -0.0058],\n",
      "        [ 0.0427,  0.0079]])\n",
      "Iterarion 381\n",
      "eta = \n",
      "[[ 0.3329 -0.4693]\n",
      " [ 0.0604 -0.0255]]\n",
      "loss = 1.1900\n",
      "\n",
      "\n",
      "tensor([[ 0.0516,  0.0046],\n",
      "        [-0.0173, -0.0037]])\n",
      "Iterarion 382\n",
      "eta = \n",
      "[[ 0.3326 -0.4706]\n",
      " [ 0.0618 -0.0241]]\n",
      "loss = 1.3687\n",
      "\n",
      "\n",
      "tensor([[ 0.0582, -0.0396],\n",
      "        [-0.0012,  0.0067]])\n",
      "Iterarion 383\n",
      "eta = \n",
      "[[ 0.3322 -0.4712]\n",
      " [ 0.0632 -0.0238]]\n",
      "loss = 1.2869\n",
      "\n",
      "\n",
      "tensor([[ 0.0573, -0.0021],\n",
      "        [ 0.0218,  0.0017]])\n",
      "Iterarion 384\n",
      "eta = \n",
      "[[ 0.3318 -0.4717]\n",
      " [ 0.0639 -0.0238]]\n",
      "loss = 1.2511\n",
      "\n",
      "\n",
      "tensor([[-0.0006, -0.0359],\n",
      "        [ 0.0475,  0.0079]])\n",
      "Iterarion 385\n",
      "eta = \n",
      "[[ 0.3314 -0.4715]\n",
      " [ 0.0634 -0.025 ]]\n",
      "loss = 1.2431\n",
      "\n",
      "\n",
      "tensor([[ 0.0362, -0.0077],\n",
      "        [ 0.0211,  0.0011]])\n",
      "Iterarion 386\n",
      "eta = \n",
      "[[ 0.331  -0.4712]\n",
      " [ 0.0624 -0.0263]]\n",
      "loss = 1.2666\n",
      "\n",
      "\n",
      "tensor([[0.0461, 0.0189],\n",
      "        [0.0019, 0.0008]])\n",
      "Iterarion 387\n",
      "eta = \n",
      "[[ 0.3306 -0.4712]\n",
      " [ 0.0615 -0.0275]]\n",
      "loss = 1.2601\n",
      "\n",
      "\n",
      "tensor([[ 0.0511, -0.0083],\n",
      "        [ 0.0060, -0.0054]])\n",
      "Iterarion 388\n",
      "eta = \n",
      "[[ 0.3301 -0.4712]\n",
      " [ 0.0606 -0.0278]]\n",
      "loss = 1.4553\n",
      "\n",
      "\n",
      "tensor([[ 0.0625, -0.0109],\n",
      "        [-0.0028,  0.0017]])\n",
      "Iterarion 389\n",
      "eta = \n",
      "[[ 0.3295 -0.4709]\n",
      " [ 0.0598 -0.0283]]\n",
      "loss = 1.2807\n",
      "\n",
      "\n",
      "tensor([[ 0.0367,  0.0214],\n",
      "        [-0.0167, -0.0029]])\n",
      "Iterarion 390\n",
      "eta = \n",
      "[[ 0.329  -0.471 ]\n",
      " [ 0.0595 -0.0284]]\n",
      "loss = 1.2763\n",
      "\n",
      "\n",
      "tensor([[-0.0367, -0.0432],\n",
      "        [ 0.0018,  0.0044]])\n",
      "Iterarion 391\n",
      "eta = \n",
      "[[ 0.3285 -0.4704]\n",
      " [ 0.0591 -0.0291]]\n",
      "loss = 1.3182\n",
      "\n",
      "\n",
      "tensor([[ 0.1091,  0.0141],\n",
      "        [-0.0100, -0.0040]])\n",
      "Iterarion 392\n",
      "eta = \n",
      "[[ 0.3279 -0.47  ]\n",
      " [ 0.0591 -0.0291]]\n",
      "loss = 1.3492\n",
      "\n",
      "\n",
      "tensor([[0.0346, 0.0127],\n",
      "        [0.0254, 0.0003]])\n",
      "Iterarion 393\n",
      "eta = \n",
      "[[ 0.3273 -0.47  ]\n",
      " [ 0.0584 -0.0291]]\n",
      "loss = 1.2577\n",
      "\n",
      "\n",
      "tensor([[ 0.0224,  0.0095],\n",
      "        [ 0.0052, -0.0028]])\n",
      "Iterarion 394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta = \n",
      "[[ 0.3267 -0.4701]\n",
      " [ 0.0577 -0.0288]]\n",
      "loss = 1.4035\n",
      "\n",
      "\n",
      "tensor([[ 0.0311,  0.0420],\n",
      "        [-0.0686, -0.0031]])\n",
      "Iterarion 395\n",
      "eta = \n",
      "[[ 0.3261 -0.4709]\n",
      " [ 0.0587 -0.0279]]\n",
      "loss = 1.3083\n",
      "\n",
      "\n",
      "tensor([[-0.0683, -0.0611],\n",
      "        [-0.0420, -0.0002]])\n",
      "Iterarion 396\n",
      "eta = \n",
      "[[ 0.3257 -0.4706]\n",
      " [ 0.0606 -0.0272]]\n",
      "loss = 1.3771\n",
      "\n",
      "\n",
      "tensor([[-0.0472, -0.0389],\n",
      "        [-0.0055,  0.0056]])\n",
      "Iterarion 397\n",
      "eta = \n",
      "[[ 0.3255 -0.4696]\n",
      " [ 0.0624 -0.0273]]\n",
      "loss = 1.2907\n",
      "\n",
      "\n",
      "tensor([[-0.0226, -0.0685],\n",
      "        [-0.0135,  0.0028]])\n",
      "Iterarion 398\n",
      "eta = \n",
      "[[ 0.3252 -0.4675]\n",
      " [ 0.0644 -0.0279]]\n",
      "loss = 1.2518\n",
      "\n",
      "\n",
      "tensor([[-0.0724, -0.0315],\n",
      "        [ 0.0141,  0.0028]])\n",
      "Iterarion 399\n",
      "eta = \n",
      "[[ 0.3252 -0.4651]\n",
      " [ 0.0659 -0.0289]]\n",
      "loss = 1.2189\n",
      "\n",
      "\n",
      "tensor([[-0.1295, -0.0384],\n",
      "        [ 0.0842,  0.0125]])\n",
      "Iterarion 400\n",
      "eta = \n",
      "[[ 0.3254 -0.4623]\n",
      " [ 0.0652 -0.0316]]\n",
      "loss = 1.3507\n",
      "\n",
      "\n",
      "tensor([[ 0.0032, -0.0215],\n",
      "        [ 0.0809,  0.0047]])\n",
      "Iterarion 401\n",
      "eta = \n",
      "[[ 0.3255 -0.4594]\n",
      " [ 0.0626 -0.0349]]\n",
      "loss = 1.2819\n",
      "\n",
      "\n",
      "tensor([[-0.0733, -0.0301],\n",
      "        [ 0.0052,  0.0004]])\n",
      "Iterarion 402\n",
      "eta = \n",
      "[[ 0.3258 -0.4562]\n",
      " [ 0.0602 -0.0378]]\n",
      "loss = 1.4435\n",
      "\n",
      "\n",
      "tensor([[-0.0093, -0.0305],\n",
      "        [-0.0142, -0.0056]])\n",
      "Iterarion 403\n",
      "eta = \n",
      "[[ 0.3261 -0.4528]\n",
      " [ 0.0583 -0.0396]]\n",
      "loss = 1.3495\n",
      "\n",
      "\n",
      "tensor([[-0.0163,  0.0168],\n",
      "        [-0.0227, -0.0009]])\n",
      "Iterarion 404\n",
      "eta = \n",
      "[[ 0.3264 -0.4501]\n",
      " [ 0.0572 -0.0411]]\n",
      "loss = 1.2880\n",
      "\n",
      "\n",
      "tensor([[-0.0767, -0.0593],\n",
      "        [-0.0614, -0.0059]])\n",
      "Iterarion 405\n",
      "eta = \n",
      "[[ 0.3268 -0.4465]\n",
      " [ 0.0576 -0.0416]]\n",
      "loss = 1.3997\n",
      "\n",
      "\n",
      "tensor([[ 0.0026, -0.0119],\n",
      "        [-0.0304, -0.0098]])\n",
      "Iterarion 406\n",
      "eta = \n",
      "[[ 0.3271 -0.4432]\n",
      " [ 0.0588 -0.0405]]\n",
      "loss = 1.3797\n",
      "\n",
      "\n",
      "tensor([[ 0.0144,  0.0091],\n",
      "        [-0.0339, -0.0088]])\n",
      "Iterarion 407\n",
      "eta = \n",
      "[[ 0.3274 -0.4403]\n",
      " [ 0.0606 -0.0381]]\n",
      "loss = 1.3824\n",
      "\n",
      "\n",
      "tensor([[ 0.0101,  0.0435],\n",
      "        [-0.0303, -0.0077]])\n",
      "Iterarion 408\n",
      "eta = \n",
      "[[ 0.3276 -0.4385]\n",
      " [ 0.0629 -0.0348]]\n",
      "loss = 1.2732\n",
      "\n",
      "\n",
      "tensor([[ 0.1181,  0.0401],\n",
      "        [ 0.0477, -0.0008]])\n",
      "Iterarion 409\n",
      "eta = \n",
      "[[ 0.3276 -0.4375]\n",
      " [ 0.0639 -0.0317]]\n",
      "loss = 1.3552\n",
      "\n",
      "\n",
      "tensor([[0.0248, 0.0099],\n",
      "        [0.0622, 0.0034]])\n",
      "Iterarion 410\n",
      "eta = \n",
      "[[ 0.3276 -0.4368]\n",
      " [ 0.0633 -0.0295]]\n",
      "loss = 1.2827\n",
      "\n",
      "\n",
      "tensor([[ 0.0003,  0.0437],\n",
      "        [ 0.0207, -0.0006]])\n",
      "Iterarion 411\n",
      "eta = \n",
      "[[ 0.3275 -0.437 ]\n",
      " [ 0.0623 -0.0273]]\n",
      "loss = 1.3548\n",
      "\n",
      "\n",
      "tensor([[0.0877, 0.0353],\n",
      "        [0.0357, 0.0082]])\n",
      "Iterarion 412\n",
      "eta = \n",
      "[[ 0.3273 -0.4377]\n",
      " [ 0.0605 -0.0267]]\n",
      "loss = 1.2313\n",
      "\n",
      "\n",
      "tensor([[-0.0170, -0.0283],\n",
      "        [ 0.0034,  0.0051]])\n",
      "Iterarion 413\n",
      "eta = \n",
      "[[ 0.3272 -0.4379]\n",
      " [ 0.0589 -0.0269]]\n",
      "loss = 1.4554\n",
      "\n",
      "\n",
      "tensor([[ 0.0444,  0.0529],\n",
      "        [-0.0326, -0.0002]])\n",
      "Iterarion 414\n",
      "eta = \n",
      "[[ 0.327  -0.439 ]\n",
      " [ 0.0581 -0.0271]]\n",
      "loss = 1.4045\n",
      "\n",
      "\n",
      "tensor([[ 0.1603,  0.1016],\n",
      "        [-0.0320, -0.0045]])\n",
      "Iterarion 415\n",
      "eta = \n",
      "[[ 0.3265 -0.4418]\n",
      " [ 0.0582 -0.0265]]\n",
      "loss = 1.2617\n",
      "\n",
      "\n",
      "tensor([[0.0364, 0.0372],\n",
      "        [0.0012, 0.0052]])\n",
      "Iterarion 416\n",
      "eta = \n",
      "[[ 0.3259 -0.4449]\n",
      " [ 0.0583 -0.0268]]\n",
      "loss = 1.3172\n",
      "\n",
      "\n",
      "tensor([[ 0.0159,  0.0185],\n",
      "        [-0.0171, -0.0049]])\n",
      "Iterarion 417\n",
      "eta = \n",
      "[[ 0.3254 -0.4481]\n",
      " [ 0.0588 -0.0263]]\n",
      "loss = 1.2307\n",
      "\n",
      "\n",
      "tensor([[-0.0880, -0.0520],\n",
      "        [ 0.0137,  0.0075]])\n",
      "Iterarion 418\n",
      "eta = \n",
      "[[ 0.3252 -0.45  ]\n",
      " [ 0.0589 -0.0271]]\n",
      "loss = 1.3115\n",
      "\n",
      "\n",
      "tensor([[ 0.0296,  0.0430],\n",
      "        [ 0.0106, -0.0053]])\n",
      "Iterarion 419\n",
      "eta = \n",
      "[[ 0.3248 -0.4525]\n",
      " [ 0.0587 -0.0269]]\n",
      "loss = 1.2764\n",
      "\n",
      "\n",
      "tensor([[ 0.0224,  0.0165],\n",
      "        [-0.0016, -0.0015]])\n",
      "Iterarion 420\n",
      "eta = \n",
      "[[ 0.3245 -0.4551]\n",
      " [ 0.0586 -0.0265]]\n",
      "loss = 1.2836\n",
      "\n",
      "\n",
      "tensor([[-0.0507,  0.0109],\n",
      "        [ 0.0085,  0.0022]])\n",
      "Iterarion 421\n",
      "eta = \n",
      "[[ 0.3243 -0.4576]\n",
      " [ 0.0583 -0.0265]]\n",
      "loss = 1.2587\n",
      "\n",
      "\n",
      "tensor([[-0.0139,  0.0052],\n",
      "        [-0.0279, -0.0092]])\n",
      "Iterarion 422\n",
      "eta = \n",
      "[[ 0.3242 -0.4599]\n",
      " [ 0.0587 -0.0251]]\n",
      "loss = 1.1916\n",
      "\n",
      "\n",
      "tensor([[-0.0232,  0.0358],\n",
      "        [-0.0389, -0.0074]])\n",
      "Iterarion 423\n",
      "eta = \n",
      "[[ 0.3241 -0.4626]\n",
      " [ 0.06   -0.0227]]\n",
      "loss = 1.2782\n",
      "\n",
      "\n",
      "tensor([[-0.0918, -0.0085],\n",
      "        [-0.0125,  0.0066]])\n",
      "Iterarion 424\n",
      "eta = \n",
      "[[ 0.3242 -0.4649]\n",
      " [ 0.0614 -0.0215]]\n",
      "loss = 1.2725\n",
      "\n",
      "\n",
      "tensor([[-0.0711, -0.0191],\n",
      "        [ 0.0447,  0.0013]])\n",
      "Iterarion 425\n",
      "eta = \n",
      "[[ 0.3244 -0.4667]\n",
      " [ 0.0617 -0.0207]]\n",
      "loss = 1.2379\n",
      "\n",
      "\n",
      "tensor([[-0.0601,  0.0714],\n",
      "        [ 0.0100,  0.0041]])\n",
      "Iterarion 426\n",
      "eta = \n",
      "[[ 0.3247 -0.4695]\n",
      " [ 0.0616 -0.0205]]\n",
      "loss = 1.1848\n",
      "\n",
      "\n",
      "tensor([[-0.1213, -0.0343],\n",
      "        [ 0.0163,  0.0060]])\n",
      "Iterarion 427\n",
      "eta = \n",
      "[[ 0.3252 -0.4715]\n",
      " [ 0.0612 -0.0214]]\n",
      "loss = 1.3201\n",
      "\n",
      "\n",
      "tensor([[-0.1033, -0.0449],\n",
      "        [ 0.0220,  0.0040]])\n",
      "Iterarion 428\n",
      "eta = \n",
      "[[ 0.3259 -0.4724]\n",
      " [ 0.0603 -0.0227]]\n",
      "loss = 1.2888\n",
      "\n",
      "\n",
      "tensor([[ 0.0135,  0.0051],\n",
      "        [ 0.0347, -0.0001]])\n",
      "Iterarion 429\n",
      "eta = \n",
      "[[ 0.3265 -0.4734]\n",
      " [ 0.0586 -0.0239]]\n",
      "loss = 1.2578\n",
      "\n",
      "\n",
      "tensor([[-0.0043, -0.0208],\n",
      "        [-0.0060,  0.0053]])\n",
      "Iterarion 430\n",
      "eta = \n",
      "[[ 0.327  -0.4739]\n",
      " [ 0.0573 -0.0258]]\n",
      "loss = 1.3134\n",
      "\n",
      "\n",
      "tensor([[ 0.0065,  0.0193],\n",
      "        [ 0.0102, -0.0044]])\n",
      "Iterarion 431\n",
      "eta = \n",
      "[[ 0.3274 -0.4746]\n",
      " [ 0.0558 -0.0268]]\n",
      "loss = 1.3409\n",
      "\n",
      "\n",
      "tensor([[-0.0988, -0.0404],\n",
      "        [-0.0090,  0.0025]])\n",
      "Iterarion 432\n",
      "eta = \n",
      "[[ 0.328  -0.4746]\n",
      " [ 0.0547 -0.0281]]\n",
      "loss = 1.2626\n",
      "\n",
      "\n",
      "tensor([[-0.0271,  0.0021],\n",
      "        [-0.0344, -0.0016]])\n",
      "Iterarion 433\n",
      "eta = \n",
      "[[ 0.3286 -0.4747]\n",
      " [ 0.0546 -0.0291]]\n",
      "loss = 1.3301\n",
      "\n",
      "\n",
      "tensor([[-0.0741, -0.0206],\n",
      "        [-0.0539, -0.0006]])\n",
      "Iterarion 434\n",
      "eta = \n",
      "[[ 0.3293 -0.4743]\n",
      " [ 0.0558 -0.0298]]\n",
      "loss = 1.3978\n",
      "\n",
      "\n",
      "tensor([[0.0954, 0.0232],\n",
      "        [0.0139, 0.0005]])\n",
      "Iterarion 435\n",
      "eta = \n",
      "[[ 0.3298 -0.4744]\n",
      " [ 0.0565 -0.0306]]\n",
      "loss = 1.3660\n",
      "\n",
      "\n",
      "tensor([[-0.0360, -0.0239],\n",
      "        [-0.0713, -0.0052]])\n",
      "Iterarion 436\n",
      "eta = \n",
      "[[ 0.3302 -0.4741]\n",
      " [ 0.0588 -0.0305]]\n",
      "loss = 1.3027\n",
      "\n",
      "\n",
      "tensor([[-0.0557, -0.0344],\n",
      "        [ 0.0090,  0.0038]])\n",
      "Iterarion 437\n",
      "eta = \n",
      "[[ 0.3307 -0.4732]\n",
      " [ 0.0608 -0.031 ]]\n",
      "loss = 1.2049\n",
      "\n",
      "\n",
      "tensor([[-0.0398, -0.0047],\n",
      "        [ 0.0029, -0.0049]])\n",
      "Iterarion 438\n",
      "eta = \n",
      "[[ 0.3313 -0.4722]\n",
      " [ 0.0624 -0.0306]]\n",
      "loss = 1.3540\n",
      "\n",
      "\n",
      "tensor([[ 0.0143, -0.0043],\n",
      "        [ 0.0109,  0.0028]])\n",
      "Iterarion 439\n",
      "eta = \n",
      "[[ 0.3317 -0.4713]\n",
      " [ 0.0637 -0.0308]]\n",
      "loss = 1.3518\n",
      "\n",
      "\n",
      "tensor([[-0.0048,  0.0193],\n",
      "        [ 0.0199,  0.0052]])\n",
      "Iterarion 440\n",
      "eta = \n",
      "[[ 0.3322 -0.4709]\n",
      " [ 0.0643 -0.0317]]\n",
      "loss = 1.3797\n",
      "\n",
      "\n",
      "tensor([[0.0454, 0.0016],\n",
      "        [0.0384, 0.0039]])\n",
      "Iterarion 441\n",
      "eta = \n",
      "[[ 0.3325 -0.4705]\n",
      " [ 0.0639 -0.0332]]\n",
      "loss = 1.2474\n",
      "\n",
      "\n",
      "tensor([[ 0.0086, -0.0084],\n",
      "        [ 0.0318,  0.0053]])\n",
      "Iterarion 442\n",
      "eta = \n",
      "[[ 0.3327 -0.47  ]\n",
      " [ 0.0628 -0.0353]]\n",
      "loss = 1.2822\n",
      "\n",
      "\n",
      "tensor([[ 0.0003,  0.0417],\n",
      "        [-0.0176, -0.0001]])\n",
      "Iterarion 443\n",
      "eta = \n",
      "[[ 0.3329 -0.4703]\n",
      " [ 0.0622 -0.0373]]\n",
      "loss = 1.3157\n",
      "\n",
      "\n",
      "tensor([[0.0430, 0.0150],\n",
      "        [0.0540, 0.0010]])\n",
      "Iterarion 444\n",
      "eta = \n",
      "[[ 0.3331 -0.4708]\n",
      " [ 0.0604 -0.0391]]\n",
      "loss = 1.2858\n",
      "\n",
      "\n",
      "tensor([[ 0.0407,  0.0375],\n",
      "        [-0.0337, -0.0069]])\n",
      "Iterarion 445\n",
      "eta = \n",
      "[[ 0.3331 -0.472 ]\n",
      " [ 0.0596 -0.0397]]\n",
      "loss = 1.3505\n",
      "\n",
      "\n",
      "tensor([[ 0.0055,  0.0498],\n",
      "        [-0.0101, -0.0070]])\n",
      "Iterarion 446\n",
      "eta = \n",
      "[[ 0.3331 -0.474 ]\n",
      " [ 0.0591 -0.0392]]\n",
      "loss = 1.4010\n",
      "\n",
      "\n",
      "tensor([[ 0.0421,  0.0014],\n",
      "        [-0.0231, -0.0063]])\n",
      "Iterarion 447\n",
      "eta = \n",
      "[[ 0.333  -0.4757]\n",
      " [ 0.0592 -0.0377]]\n",
      "loss = 1.2862\n",
      "\n",
      "\n",
      "tensor([[ 0.0478,  0.0299],\n",
      "        [-0.0227, -0.0026]])\n",
      "Iterarion 448\n",
      "eta = \n",
      "[[ 0.3329 -0.4779]\n",
      " [ 0.0598 -0.036 ]]\n",
      "loss = 1.1836\n",
      "\n",
      "\n",
      "tensor([[-0.0425, -0.0040],\n",
      "        [-0.0036,  0.0016]])\n",
      "Iterarion 449\n",
      "eta = \n",
      "[[ 0.3328 -0.4798]\n",
      " [ 0.0605 -0.0346]]\n",
      "loss = 1.2190\n",
      "\n",
      "\n",
      "tensor([[-0.0482, -0.0865],\n",
      "        [-0.0054,  0.0008]])\n",
      "Iterarion 450\n",
      "eta = \n",
      "[[ 0.3329 -0.4799]\n",
      " [ 0.0613 -0.0336]]\n",
      "loss = 1.3158\n",
      "\n",
      "\n",
      "tensor([[ 0.1221,  0.0369],\n",
      "        [-0.0156, -0.0091]])\n",
      "Iterarion 451\n",
      "eta = \n",
      "[[ 0.3327 -0.4806]\n",
      " [ 0.0623 -0.0312]]\n",
      "loss = 1.2386\n",
      "\n",
      "\n",
      "tensor([[-0.1037, -0.0576],\n",
      "        [ 0.0018,  0.0073]])\n",
      "Iterarion 452\n",
      "eta = \n",
      "[[ 0.3327 -0.4803]\n",
      " [ 0.0632 -0.0301]]\n",
      "loss = 1.3487\n",
      "\n",
      "\n",
      "tensor([[ 0.0365, -0.0127],\n",
      "        [ 0.0485, -0.0016]])\n",
      "Iterarion 453\n",
      "eta = \n",
      "[[ 0.3326 -0.4797]\n",
      " [ 0.0629 -0.029 ]]\n",
      "loss = 1.2923\n",
      "\n",
      "\n",
      "tensor([[-0.0143, -0.0191],\n",
      "        [ 0.0146,  0.0016]])\n",
      "Iterarion 454\n",
      "eta = \n",
      "[[ 0.3326 -0.4789]\n",
      " [ 0.0622 -0.0282]]\n",
      "loss = 1.3269\n",
      "\n",
      "\n",
      "tensor([[ 0.0972,  0.0482],\n",
      "        [-0.0043, -0.0029]])\n",
      "Iterarion 455\n",
      "eta = \n",
      "[[ 0.3324 -0.479 ]\n",
      " [ 0.0616 -0.027 ]]\n",
      "loss = 1.3269\n",
      "\n",
      "\n",
      "tensor([[ 0.0489, -0.0010],\n",
      "        [ 0.0395, -0.0047]])\n",
      "Iterarion 456\n",
      "eta = \n",
      "[[ 0.3321 -0.4791]\n",
      " [ 0.0602 -0.0252]]\n",
      "loss = 1.3959\n",
      "\n",
      "\n",
      "tensor([[0.0304, 0.0317],\n",
      "        [0.0093, 0.0006]])\n",
      "Iterarion 457\n",
      "eta = \n",
      "[[ 0.3318 -0.4797]\n",
      " [ 0.0587 -0.0236]]\n",
      "loss = 1.3723\n",
      "\n",
      "\n",
      "tensor([[-0.0569, -0.0977],\n",
      "        [ 0.0109,  0.0081]])\n",
      "Iterarion 458\n",
      "eta = \n",
      "[[ 0.3316 -0.4785]\n",
      " [ 0.057  -0.0235]]\n",
      "loss = 1.2956\n",
      "\n",
      "\n",
      "tensor([[ 0.0659,  0.0023],\n",
      "        [ 0.0102, -0.0006]])\n",
      "Iterarion 459\n",
      "eta = \n",
      "[[ 0.3313 -0.4775]\n",
      " [ 0.0553 -0.0234]]\n",
      "loss = 1.2810\n",
      "\n",
      "\n",
      "tensor([[ 0.0464, -0.0122],\n",
      "        [-0.0148,  0.0003]])\n",
      "Iterarion 460\n",
      "eta = \n",
      "[[ 0.331  -0.4763]\n",
      " [ 0.0541 -0.0232]]\n",
      "loss = 1.3308\n",
      "\n",
      "\n",
      "tensor([[ 0.0602, -0.0201],\n",
      "        [-0.0128, -0.0037]])\n",
      "Iterarion 461\n",
      "eta = \n",
      "[[ 0.3305 -0.4749]\n",
      " [ 0.0533 -0.0225]]\n",
      "loss = 1.3462\n",
      "\n",
      "\n",
      "tensor([[-0.0053,  0.0084],\n",
      "        [-0.0662, -0.0049]])\n",
      "Iterarion 462\n",
      "eta = \n",
      "[[ 0.3302 -0.4738]\n",
      " [ 0.0543 -0.0211]]\n",
      "loss = 1.3775\n",
      "\n",
      "\n",
      "tensor([[ 0.0176,  0.0056],\n",
      "        [-0.0452,  0.0014]])\n",
      "Iterarion 463\n",
      "eta = \n",
      "[[ 0.3298 -0.4729]\n",
      " [ 0.0562 -0.0201]]\n",
      "loss = 1.3209\n",
      "\n",
      "\n",
      "tensor([[ 0.0265, -0.0191],\n",
      "        [-0.0188,  0.0025]])\n",
      "Iterarion 464\n",
      "eta = \n",
      "[[ 0.3294 -0.4718]\n",
      " [ 0.0585 -0.0195]]\n",
      "loss = 1.3616\n",
      "\n",
      "\n",
      "tensor([[ 0.0467, -0.0528],\n",
      "        [ 0.0323,  0.0082]])\n",
      "Iterarion 465\n",
      "eta = \n",
      "[[ 0.3289 -0.4697]\n",
      " [ 0.0597 -0.0203]]\n",
      "loss = 1.2937\n",
      "\n",
      "\n",
      "tensor([[ 0.0249,  0.0012],\n",
      "        [-0.0107, -0.0003]])\n",
      "Iterarion 466\n",
      "eta = \n",
      "[[ 0.3285 -0.468 ]\n",
      " [ 0.0611 -0.021 ]]\n",
      "loss = 1.3256\n",
      "\n",
      "\n",
      "tensor([[ 0.0165, -0.0193],\n",
      "        [-0.0470, -0.0005]])\n",
      "Iterarion 467\n",
      "eta = \n",
      "[[ 0.328  -0.466 ]\n",
      " [ 0.0635 -0.0215]]\n",
      "loss = 1.1986\n",
      "\n",
      "\n",
      "tensor([[-0.1216, -0.0358],\n",
      "        [ 0.0216,  0.0074]])\n",
      "Iterarion 468\n",
      "eta = \n",
      "[[ 0.3279 -0.4635]\n",
      " [ 0.0651 -0.0232]]\n",
      "loss = 1.2786\n",
      "\n",
      "\n",
      "tensor([[-0.0495, -0.0262],\n",
      "        [ 0.1173,  0.0157]])\n",
      "Iterarion 469\n",
      "eta = \n",
      "[[ 0.3278 -0.4609]\n",
      " [ 0.0637 -0.0272]]\n",
      "loss = 1.2853\n",
      "\n",
      "\n",
      "tensor([[-0.0393, -0.0238],\n",
      "        [ 0.0139,  0.0026]])\n",
      "Iterarion 470\n",
      "eta = \n",
      "[[ 0.3279 -0.458 ]\n",
      " [ 0.062  -0.0312]]\n",
      "loss = 1.3323\n",
      "\n",
      "\n",
      "tensor([[-0.0440, -0.0315],\n",
      "        [-0.0282, -0.0049]])\n",
      "Iterarion 471\n",
      "eta = \n",
      "[[ 0.328  -0.4549]\n",
      " [ 0.0612 -0.034 ]]\n",
      "loss = 1.3370\n",
      "\n",
      "\n",
      "tensor([[-0.0296, -0.0130],\n",
      "        [ 0.0153,  0.0036]])\n",
      "Iterarion 472\n",
      "eta = \n",
      "[[ 0.3282 -0.4518]\n",
      " [ 0.0602 -0.0372]]\n",
      "loss = 1.1951\n",
      "\n",
      "\n",
      "tensor([[ 0.0094,  0.0145],\n",
      "        [-0.0182, -0.0087]])\n",
      "Iterarion 473\n",
      "eta = \n",
      "[[ 0.3283 -0.4493]\n",
      " [ 0.0596 -0.0386]]\n",
      "loss = 1.2115\n",
      "\n",
      "\n",
      "tensor([[ 0.0170,  0.0106],\n",
      "        [-0.0015, -0.0020]])\n",
      "Iterarion 474\n",
      "eta = \n",
      "[[ 0.3284 -0.4472]\n",
      " [ 0.0592 -0.0396]]\n",
      "loss = 1.2641\n",
      "\n",
      "\n",
      "tensor([[-0.0076, -0.0640],\n",
      "        [ 0.0016, -0.0051]])\n",
      "Iterarion 475\n",
      "eta = \n",
      "[[ 0.3285 -0.4442]\n",
      " [ 0.0588 -0.0397]]\n",
      "loss = 1.2675\n",
      "\n",
      "\n",
      "tensor([[ 0.0382,  0.0461],\n",
      "        [-0.0110, -0.0100]])\n",
      "Iterarion 476\n",
      "eta = \n",
      "[[ 0.3285 -0.4423]\n",
      " [ 0.0586 -0.0381]]\n",
      "loss = 1.2409\n",
      "\n",
      "\n",
      "tensor([[-0.0237,  0.0135],\n",
      "        [ 0.0027, -0.0050]])\n",
      "Iterarion 477\n",
      "eta = \n",
      "[[ 0.3286 -0.4409]\n",
      " [ 0.0585 -0.036 ]]\n",
      "loss = 1.2444\n",
      "\n",
      "\n",
      "tensor([[ 0.0585,  0.0426],\n",
      "        [-0.0295, -0.0062]])\n",
      "Iterarion 478\n",
      "eta = \n",
      "[[ 0.3285 -0.4403]\n",
      " [ 0.0591 -0.033 ]]\n",
      "loss = 1.2204\n",
      "\n",
      "\n",
      "tensor([[-0.0610, -0.0058],\n",
      "        [ 0.0147,  0.0008]])\n",
      "Iterarion 479\n",
      "eta = \n",
      "[[ 0.3286 -0.4398]\n",
      " [ 0.0592 -0.0305]]\n",
      "loss = 1.3193\n",
      "\n",
      "\n",
      "tensor([[ 0.0310, -0.0687],\n",
      "        [ 0.0304,  0.0001]])\n",
      "Iterarion 480\n",
      "eta = \n",
      "[[ 0.3285 -0.438 ]\n",
      " [ 0.0586 -0.0283]]\n",
      "loss = 1.2834\n",
      "\n",
      "\n",
      "tensor([[0.1455, 0.0872],\n",
      "        [0.0671, 0.0023]])\n",
      "Iterarion 481\n",
      "eta = \n",
      "[[ 0.3282 -0.438 ]\n",
      " [ 0.0564 -0.0266]]\n",
      "loss = 1.2984\n",
      "\n",
      "\n",
      "tensor([[ 0.0110,  0.0184],\n",
      "        [-0.0215, -0.0014]])\n",
      "Iterarion 482\n",
      "eta = \n",
      "[[ 0.3279 -0.4383]\n",
      " [ 0.0549 -0.0249]]\n",
      "loss = 1.2899\n",
      "\n",
      "\n",
      "tensor([[-0.0707, -0.0208],\n",
      "        [-0.0044, -0.0005]])\n",
      "Iterarion 483\n",
      "eta = \n",
      "[[ 0.3278 -0.4383]\n",
      " [ 0.0537 -0.0233]]\n",
      "loss = 1.3313\n",
      "\n",
      "\n",
      "tensor([[ 0.0166, -0.0417],\n",
      "        [-0.0576, -0.0026]])\n",
      "Iterarion 484\n",
      "eta = \n",
      "[[ 0.3277 -0.4374]\n",
      " [ 0.054  -0.0214]]\n",
      "loss = 1.3568\n",
      "\n",
      "\n",
      "tensor([[-0.0537, -0.0136],\n",
      "        [-0.0415, -0.0019]])\n",
      "Iterarion 485\n",
      "eta = \n",
      "[[ 0.3277 -0.4364]\n",
      " [ 0.0554 -0.0194]]\n",
      "loss = 1.4123\n",
      "\n",
      "\n",
      "tensor([[-0.0139,  0.0210],\n",
      "        [-0.0390,  0.0026]])\n",
      "Iterarion 486\n",
      "eta = \n",
      "[[ 0.3277 -0.4359]\n",
      " [ 0.0576 -0.018 ]]\n",
      "loss = 1.3262\n",
      "\n",
      "\n",
      "tensor([[0.0259, 0.0145],\n",
      "        [0.0255, 0.0071]])\n",
      "Iterarion 487\n",
      "eta = \n",
      "[[ 0.3276 -0.4357]\n",
      " [ 0.0589 -0.018 ]]\n",
      "loss = 1.4427\n",
      "\n",
      "\n",
      "tensor([[-0.0199, -0.0262],\n",
      "        [ 0.0459,  0.0111]])\n",
      "Iterarion 488\n",
      "eta = \n",
      "[[ 0.3276 -0.4351]\n",
      " [ 0.0589 -0.0196]]\n",
      "loss = 1.3346\n",
      "\n",
      "\n",
      "tensor([[ 0.0221, -0.0025],\n",
      "        [ 0.0158,  0.0025]])\n",
      "Iterarion 489\n",
      "eta = \n",
      "[[ 0.3276 -0.4344]\n",
      " [ 0.0586 -0.0216]]\n",
      "loss = 1.3424\n",
      "\n",
      "\n",
      "tensor([[0.0858, 0.0507],\n",
      "        [0.0482, 0.0003]])\n",
      "Iterarion 490\n",
      "eta = \n",
      "[[ 0.3274 -0.4348]\n",
      " [ 0.0571 -0.0233]]\n",
      "loss = 1.4075\n",
      "\n",
      "\n",
      "tensor([[ 0.0558,  0.0219],\n",
      "        [-0.0324, -0.0030]])\n",
      "Iterarion 491\n",
      "eta = \n",
      "[[ 0.327  -0.4355]\n",
      " [ 0.0565 -0.0245]]\n",
      "loss = 1.3094\n",
      "\n",
      "\n",
      "tensor([[ 0.0064,  0.0157],\n",
      "        [-0.0132, -0.0022]])\n",
      "Iterarion 492\n",
      "eta = \n",
      "[[ 0.3268 -0.4365]\n",
      " [ 0.0564 -0.0251]]\n",
      "loss = 1.3266\n",
      "\n",
      "\n",
      "tensor([[ 0.0887,  0.0531],\n",
      "        [-0.0477, -0.0029]])\n",
      "Iterarion 493\n",
      "eta = \n",
      "[[ 0.3263 -0.4383]\n",
      " [ 0.0574 -0.0252]]\n",
      "loss = 1.3634\n",
      "\n",
      "\n",
      "tensor([[-0.0664, -0.0536],\n",
      "        [-0.0171,  0.0079]])\n",
      "Iterarion 494\n",
      "eta = \n",
      "[[ 0.326  -0.439 ]\n",
      " [ 0.0588 -0.0266]]\n",
      "loss = 1.3407\n",
      "\n",
      "\n",
      "tensor([[ 0.0444,  0.0279],\n",
      "        [-0.0495, -0.0051]])\n",
      "Iterarion 495\n",
      "eta = \n",
      "[[ 0.3257 -0.4401]\n",
      " [ 0.0612 -0.027 ]]\n",
      "loss = 1.1650\n",
      "\n",
      "\n",
      "tensor([[-0.0012, -0.0171],\n",
      "        [ 0.0202,  0.0035]])\n",
      "Iterarion 496\n",
      "eta = \n",
      "[[ 0.3254 -0.4408]\n",
      " [ 0.0629 -0.028 ]]\n",
      "loss = 1.2524\n",
      "\n",
      "\n",
      "tensor([[ 0.0226, -0.0144],\n",
      "        [ 0.0203,  0.0044]])\n",
      "Iterarion 497\n",
      "eta = \n",
      "[[ 0.3251 -0.4412]\n",
      " [ 0.0639 -0.0295]]\n",
      "loss = 1.4175\n",
      "\n",
      "\n",
      "tensor([[0.0585, 0.0639],\n",
      "        [0.0697, 0.0024]])\n",
      "Iterarion 498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta = \n",
      "[[ 0.3247 -0.4427]\n",
      " [ 0.0631 -0.0313]]\n",
      "loss = 1.2098\n",
      "\n",
      "\n",
      "tensor([[-0.0418, -0.0249],\n",
      "        [ 0.0328,  0.0053]])\n",
      "Iterarion 499\n",
      "eta = \n",
      "[[ 0.3244 -0.4436]\n",
      " [ 0.0616 -0.0338]]\n",
      "loss = 1.2837\n",
      "\n",
      "\n",
      "tensor([[-0.0181, -0.0254],\n",
      "        [-0.0041, -0.0029]])\n",
      "Iterarion 500\n",
      "eta = \n",
      "[[ 0.3242 -0.4439]\n",
      " [ 0.0603 -0.0355]]\n",
      "loss = 1.3894\n",
      "\n",
      "\n",
      "tensor([[-0.0240, -0.0227],\n",
      "        [-0.0353, -0.0060]])\n",
      "Iterarion 501\n",
      "eta = \n",
      "[[ 0.324  -0.4438]\n",
      " [ 0.06   -0.0361]]\n",
      "loss = 1.3460\n",
      "\n",
      "\n",
      "tensor([[-0.0098,  0.0328],\n",
      "        [-0.0225, -0.0058]])\n",
      "Iterarion 502\n",
      "eta = \n",
      "[[ 0.3239 -0.4443]\n",
      " [ 0.0603 -0.0358]]\n",
      "loss = 1.2876\n",
      "\n",
      "\n",
      "tensor([[ 0.0232, -0.0134],\n",
      "        [-0.0270, -0.0025]])\n",
      "Iterarion 503\n",
      "eta = \n",
      "[[ 0.3238 -0.4445]\n",
      " [ 0.0613 -0.035 ]]\n",
      "loss = 1.3586\n",
      "\n",
      "\n",
      "tensor([[-0.0159,  0.0132],\n",
      "        [ 0.0859,  0.0022]])\n",
      "Iterarion 504\n",
      "eta = \n",
      "[[ 0.3237 -0.4449]\n",
      " [ 0.06   -0.0347]]\n",
      "loss = 1.2348\n",
      "\n",
      "\n",
      "tensor([[-0.0685,  0.0054],\n",
      "        [ 0.0603,  0.0017]])\n",
      "Iterarion 505\n",
      "eta = \n",
      "[[ 0.3237 -0.4454]\n",
      " [ 0.0573 -0.0346]]\n",
      "loss = 1.2596\n",
      "\n",
      "\n",
      "tensor([[ 0.0015,  0.0243],\n",
      "        [ 0.0142, -0.0010]])\n",
      "Iterarion 506\n",
      "eta = \n",
      "[[ 0.3238 -0.4463]\n",
      " [ 0.0546 -0.0344]]\n",
      "loss = 1.3714\n",
      "\n",
      "\n",
      "tensor([[ 0.0515,  0.0206],\n",
      "        [-0.0180, -0.0053]])\n",
      "Iterarion 507\n",
      "eta = \n",
      "[[ 0.3237 -0.4475]\n",
      " [ 0.0526 -0.0334]]\n",
      "loss = 1.2771\n",
      "\n",
      "\n",
      "tensor([[-0.0093,  0.0064],\n",
      "        [-0.0445, -0.0140]])\n",
      "Iterarion 508\n",
      "eta = \n",
      "[[ 0.3237 -0.4487]\n",
      " [ 0.0519 -0.0302]]\n",
      "loss = 1.2875\n",
      "\n",
      "\n",
      "tensor([[-0.1427, -0.0324],\n",
      "        [-0.0847, -0.0067]])\n",
      "Iterarion 509\n",
      "eta = \n",
      "[[ 0.3239 -0.4492]\n",
      " [ 0.0533 -0.0263]]\n",
      "loss = 1.3482\n",
      "\n",
      "\n",
      "tensor([[ 0.0388, -0.0089],\n",
      "        [-0.0225, -0.0017]])\n",
      "Iterarion 510\n",
      "eta = \n",
      "[[ 0.3241 -0.4495]\n",
      " [ 0.0552 -0.0225]]\n",
      "loss = 1.3946\n",
      "\n",
      "\n",
      "tensor([[ 0.0260,  0.0019],\n",
      "        [-0.0538, -0.0079]])\n",
      "Iterarion 511\n",
      "eta = \n",
      "[[ 0.3242 -0.4497]\n",
      " [ 0.0582 -0.0177]]\n",
      "loss = 1.2186\n",
      "\n",
      "\n",
      "tensor([[-0.0058,  0.0062],\n",
      "        [ 0.0540,  0.0047]])\n",
      "Iterarion 512\n",
      "eta = \n",
      "[[ 0.3243 -0.4501]\n",
      " [ 0.0596 -0.0143]]\n",
      "loss = 1.3310\n",
      "\n",
      "\n",
      "tensor([[0.0123, 0.0307],\n",
      "        [0.0030, 0.0069]])\n",
      "Iterarion 513\n",
      "eta = \n",
      "[[ 0.3243 -0.451 ]\n",
      " [ 0.0607 -0.0122]]\n",
      "loss = 1.2345\n",
      "\n",
      "\n",
      "tensor([[-0.1072, -0.0600],\n",
      "        [-0.0172,  0.0088]])\n",
      "Iterarion 514\n",
      "eta = \n",
      "[[ 0.3246 -0.4507]\n",
      " [ 0.0622 -0.0118]]\n",
      "loss = 1.1486\n",
      "\n",
      "\n",
      "tensor([[-0.0726, -0.0243],\n",
      "        [ 0.0675,  0.0100]])\n",
      "Iterarion 515\n",
      "eta = \n",
      "[[ 0.325  -0.4499]\n",
      " [ 0.0619 -0.0131]]\n",
      "loss = 1.3179\n",
      "\n",
      "\n",
      "tensor([[ 0.0680,  0.0580],\n",
      "        [-0.0245, -0.0048]])\n",
      "Iterarion 516\n",
      "eta = \n",
      "[[ 0.3253 -0.4503]\n",
      " [ 0.0622 -0.0134]]\n",
      "loss = 1.3639\n",
      "\n",
      "\n",
      "tensor([[0.0047, 0.0613],\n",
      "        [0.0184, 0.0066]])\n",
      "Iterarion 517\n",
      "eta = \n",
      "[[ 0.3254 -0.4519]\n",
      " [ 0.062  -0.0148]]\n",
      "loss = 1.2690\n",
      "\n",
      "\n",
      "tensor([[ 0.0137,  0.0470],\n",
      "        [-0.0633, -0.0039]])\n",
      "Iterarion 518\n",
      "eta = \n",
      "[[ 0.3256 -0.4542]\n",
      " [ 0.0634 -0.0154]]\n",
      "loss = 1.2517\n",
      "\n",
      "\n",
      "tensor([[-0.0406,  0.0529],\n",
      "        [ 0.0162,  0.0044]])\n",
      "Iterarion 519\n",
      "eta = \n",
      "[[ 0.3258 -0.4573]\n",
      " [ 0.0642 -0.0166]]\n",
      "loss = 1.3265\n",
      "\n",
      "\n",
      "tensor([[0.0691, 0.0611],\n",
      "        [0.0168, 0.0014]])\n",
      "Iterarion 520\n",
      "eta = \n",
      "[[ 0.3258 -0.4612]\n",
      " [ 0.0646 -0.018 ]]\n",
      "loss = 1.2392\n",
      "\n",
      "\n",
      "tensor([[-0.0028, -0.0109],\n",
      "        [ 0.0596,  0.0088]])\n",
      "Iterarion 521\n",
      "eta = \n",
      "[[ 0.3259 -0.4645]\n",
      " [ 0.0634 -0.0206]]\n",
      "loss = 1.3715\n",
      "\n",
      "\n",
      "tensor([[ 0.0471, -0.0111],\n",
      "        [ 0.0345,  0.0039]])\n",
      "Iterarion 522\n",
      "eta = \n",
      "[[ 0.3258 -0.4673]\n",
      " [ 0.0615 -0.0236]]\n",
      "loss = 1.3098\n",
      "\n",
      "\n",
      "tensor([[-0.0260,  0.0213],\n",
      "        [ 0.0265,  0.0086]])\n",
      "Iterarion 523\n",
      "eta = \n",
      "[[ 0.3258 -0.4702]\n",
      " [ 0.0592 -0.0277]]\n",
      "loss = 1.3584\n",
      "\n",
      "\n",
      "tensor([[-0.0192, -0.0301],\n",
      "        [ 0.0094,  0.0032]])\n",
      "Iterarion 524\n",
      "eta = \n",
      "[[ 0.3259 -0.4723]\n",
      " [ 0.0568 -0.0319]]\n",
      "loss = 1.3402\n",
      "\n",
      "\n",
      "tensor([[-0.0366,  0.0113],\n",
      "        [-0.0064,  0.0010]])\n",
      "Iterarion 525\n",
      "eta = \n",
      "[[ 0.326  -0.4744]\n",
      " [ 0.0548 -0.0359]]\n",
      "loss = 1.3184\n",
      "\n",
      "\n",
      "tensor([[-0.0551, -0.0302],\n",
      "        [-0.0544, -0.0083]])\n",
      "Iterarion 526\n",
      "eta = \n",
      "[[ 0.3262 -0.4757]\n",
      " [ 0.0544 -0.0381]]\n",
      "loss = 1.3076\n",
      "\n",
      "\n",
      "tensor([[-0.0011, -0.0013],\n",
      "        [-0.0826, -0.0099]])\n",
      "Iterarion 527\n",
      "eta = \n",
      "[[ 0.3264 -0.4768]\n",
      " [ 0.0561 -0.0385]]\n",
      "loss = 1.3503\n",
      "\n",
      "\n",
      "tensor([[-0.0857, -0.0561],\n",
      "        [-0.0564, -0.0076]])\n",
      "Iterarion 528\n",
      "eta = \n",
      "[[ 0.3268 -0.4767]\n",
      " [ 0.059  -0.0377]]\n",
      "loss = 1.3588\n",
      "\n",
      "\n",
      "tensor([[ 0.0088, -0.0336],\n",
      "        [ 0.0189, -0.0023]])\n",
      "Iterarion 529\n",
      "eta = \n",
      "[[ 0.3271 -0.476 ]\n",
      " [ 0.0611 -0.0365]]\n",
      "loss = 1.2376\n",
      "\n",
      "\n",
      "tensor([[0.0160, 0.0172],\n",
      "        [0.0791, 0.0006]])\n",
      "Iterarion 530\n",
      "eta = \n",
      "[[ 0.3274 -0.4757]\n",
      " [ 0.0611 -0.0356]]\n",
      "loss = 1.2765\n",
      "\n",
      "\n",
      "tensor([[ 0.0119,  0.0075],\n",
      "        [ 0.0003, -0.0088]])\n",
      "Iterarion 531\n",
      "eta = \n",
      "[[ 0.3276 -0.4756]\n",
      " [ 0.061  -0.0333]]\n",
      "loss = 1.2913\n",
      "\n",
      "\n",
      "tensor([[ 0.0103,  0.0015],\n",
      "        [ 0.0226, -0.0022]])\n",
      "Iterarion 532\n",
      "eta = \n",
      "[[ 0.3277 -0.4755]\n",
      " [ 0.0604 -0.031 ]]\n",
      "loss = 1.2340\n",
      "\n",
      "\n",
      "tensor([[-0.0915, -0.0141],\n",
      "        [ 0.0150,  0.0042]])\n",
      "Iterarion 533\n",
      "eta = \n",
      "[[ 0.3281 -0.4752]\n",
      " [ 0.0595 -0.0295]]\n",
      "loss = 1.2317\n",
      "\n",
      "\n",
      "tensor([[-0.0694,  0.0201],\n",
      "        [-0.0047,  0.0010]])\n",
      "Iterarion 534\n",
      "eta = \n",
      "[[ 0.3285 -0.4753]\n",
      " [ 0.0588 -0.0283]]\n",
      "loss = 1.3529\n",
      "\n",
      "\n",
      "tensor([[-0.0394, -0.0206],\n",
      "        [-0.0549, -0.0036]])\n",
      "Iterarion 535\n",
      "eta = \n",
      "[[ 0.329  -0.4749]\n",
      " [ 0.0596 -0.0267]]\n",
      "loss = 1.3653\n",
      "\n",
      "\n",
      "tensor([[ 0.0613,  0.0096],\n",
      "        [-0.0320, -0.0027]])\n",
      "Iterarion 536\n",
      "eta = \n",
      "[[ 0.3294 -0.4748]\n",
      " [ 0.061  -0.0248]]\n",
      "loss = 1.3426\n",
      "\n",
      "\n",
      "tensor([[-0.0044,  0.0045],\n",
      "        [ 0.0372,  0.0034]])\n",
      "Iterarion 537\n",
      "eta = \n",
      "[[ 0.3297 -0.4748]\n",
      " [ 0.0614 -0.0236]]\n",
      "loss = 1.3264\n",
      "\n",
      "\n",
      "tensor([[0.0094, 0.0154],\n",
      "        [0.0415, 0.0075]])\n",
      "Iterarion 538\n",
      "eta = \n",
      "[[ 0.3299 -0.4751]\n",
      " [ 0.0607 -0.0238]]\n",
      "loss = 1.2550\n",
      "\n",
      "\n",
      "tensor([[-0.0177,  0.0101],\n",
      "        [-0.0227,  0.0009]])\n",
      "Iterarion 539\n",
      "eta = \n",
      "[[ 0.3302 -0.4756]\n",
      " [ 0.0607 -0.024 ]]\n",
      "loss = 1.4142\n",
      "\n",
      "\n",
      "tensor([[ 0.0289,  0.0532],\n",
      "        [ 0.0118, -0.0022]])\n",
      "Iterarion 540\n",
      "eta = \n",
      "[[ 0.3303 -0.477 ]\n",
      " [ 0.0603 -0.0239]]\n",
      "loss = 1.3818\n",
      "\n",
      "\n",
      "tensor([[-0.0621, -0.0261],\n",
      "        [-0.0194,  0.0025]])\n",
      "Iterarion 541\n",
      "eta = \n",
      "[[ 0.3306 -0.4778]\n",
      " [ 0.0605 -0.0242]]\n",
      "loss = 1.3341\n",
      "\n",
      "\n",
      "tensor([[ 0.0603,  0.0083],\n",
      "        [-0.0051, -0.0010]])\n",
      "Iterarion 542\n",
      "eta = \n",
      "[[ 0.3308 -0.4787]\n",
      " [ 0.0608 -0.0244]]\n",
      "loss = 1.2917\n",
      "\n",
      "\n",
      "tensor([[-0.0127, -0.0392],\n",
      "        [ 0.0109,  0.0050]])\n",
      "Iterarion 543\n",
      "eta = \n",
      "[[ 0.3309 -0.4787]\n",
      " [ 0.0608 -0.0253]]\n",
      "loss = 1.3943\n",
      "\n",
      "\n",
      "tensor([[ 0.0957,  0.0192],\n",
      "        [-0.0322, -0.0037]])\n",
      "Iterarion 544\n",
      "eta = \n",
      "[[ 0.3308 -0.4791]\n",
      " [ 0.0616 -0.0255]]\n",
      "loss = 1.2483\n",
      "\n",
      "\n",
      "tensor([[0.0440, 0.0134],\n",
      "        [0.0454, 0.0010]])\n",
      "Iterarion 545\n",
      "eta = \n",
      "[[ 0.3307 -0.4797]\n",
      " [ 0.0611 -0.0259]]\n",
      "loss = 1.3362\n",
      "\n",
      "\n",
      "tensor([[0.0296, 0.0041],\n",
      "        [0.0549, 0.0037]])\n",
      "Iterarion 546\n",
      "eta = \n",
      "[[ 0.3304 -0.4804]\n",
      " [ 0.0594 -0.0268]]\n",
      "loss = 1.3355\n",
      "\n",
      "\n",
      "tensor([[0.0129, 0.0262],\n",
      "        [0.0239, 0.0018]])\n",
      "Iterarion 547\n",
      "eta = \n",
      "[[ 0.3302 -0.4814]\n",
      " [ 0.0572 -0.028 ]]\n",
      "loss = 1.3923\n",
      "\n",
      "\n",
      "tensor([[ 0.0025, -0.0380],\n",
      "        [-0.0187, -0.0037]])\n",
      "Iterarion 548\n",
      "eta = \n",
      "[[ 0.33   -0.4817]\n",
      " [ 0.0557 -0.0284]]\n",
      "loss = 1.3644\n",
      "\n",
      "\n",
      "tensor([[-0.0265, -0.0521],\n",
      "        [-0.0183,  0.0012]])\n",
      "Iterarion 549\n",
      "eta = \n",
      "[[ 0.3299 -0.4809]\n",
      " [ 0.0549 -0.0289]]\n",
      "loss = 1.2804\n",
      "\n",
      "\n",
      "tensor([[ 0.0100, -0.0456],\n",
      "        [-0.0014, -0.0006]])\n",
      "Iterarion 550\n",
      "eta = \n",
      "[[ 0.3297 -0.4792]\n",
      " [ 0.0541 -0.0294]]\n",
      "loss = 1.3402\n",
      "\n",
      "\n",
      "tensor([[ 0.0798,  0.0043],\n",
      "        [-0.0294, -0.0074]])\n",
      "Iterarion 551\n",
      "eta = \n",
      "[[ 0.3294 -0.4779]\n",
      " [ 0.0542 -0.0285]]\n",
      "loss = 1.3597\n",
      "\n",
      "\n",
      "tensor([[-0.0873, -0.0115],\n",
      "        [-0.0559,  0.0042]])\n",
      "Iterarion 552\n",
      "eta = \n",
      "[[ 0.3293 -0.4764]\n",
      " [ 0.0556 -0.0285]]\n",
      "loss = 1.2737\n",
      "\n",
      "\n",
      "tensor([[ 0.0233, -0.0051],\n",
      "        [-0.0767, -0.0064]])\n",
      "Iterarion 553\n",
      "eta = \n",
      "[[ 0.3292 -0.475 ]\n",
      " [ 0.0588 -0.0274]]\n",
      "loss = 1.1971\n",
      "\n",
      "\n",
      "tensor([[-0.0704, -0.0561],\n",
      "        [-0.0177, -0.0011]])\n",
      "Iterarion 554\n",
      "eta = \n",
      "[[ 0.3293 -0.4726]\n",
      " [ 0.0621 -0.0262]]\n",
      "loss = 1.3434\n",
      "\n",
      "\n",
      "tensor([[-0.0558, -0.0213],\n",
      "        [ 0.0609,  0.0084]])\n",
      "Iterarion 555\n",
      "eta = \n",
      "[[ 0.3294 -0.47  ]\n",
      " [ 0.0636 -0.0265]]\n",
      "loss = 1.2968\n",
      "\n",
      "\n",
      "tensor([[-0.0863, -0.0395],\n",
      "        [ 0.0077,  0.0053]])\n",
      "Iterarion 556\n",
      "eta = \n",
      "[[ 0.3298 -0.4669]\n",
      " [ 0.0647 -0.0277]]\n",
      "loss = 1.3738\n",
      "\n",
      "\n",
      "tensor([[0.0281, 0.0082],\n",
      "        [0.0435, 0.0040]])\n",
      "Iterarion 557\n",
      "eta = \n",
      "[[ 0.33   -0.4643]\n",
      " [ 0.0647 -0.0294]]\n",
      "loss = 1.4620\n",
      "\n",
      "\n",
      "tensor([[ 0.1068,  0.0343],\n",
      "        [ 0.0123, -0.0008]])\n",
      "Iterarion 558\n",
      "eta = \n",
      "[[ 0.33   -0.4626]\n",
      " [ 0.0643 -0.0308]]\n",
      "loss = 1.3711\n",
      "\n",
      "\n",
      "tensor([[0.1027, 0.0709],\n",
      "        [0.0352, 0.0046]])\n",
      "Iterarion 559\n",
      "eta = \n",
      "[[ 0.3298 -0.4625]\n",
      " [ 0.0631 -0.0328]]\n",
      "loss = 1.2722\n",
      "\n",
      "\n",
      "tensor([[ 0.0235, -0.0311],\n",
      "        [ 0.0555,  0.0069]])\n",
      "Iterarion 560\n",
      "eta = \n",
      "[[ 0.3295 -0.4618]\n",
      " [ 0.0606 -0.0357]]\n",
      "loss = 1.2789\n",
      "\n",
      "\n",
      "tensor([[-0.0144, -0.0050],\n",
      "        [-0.0043, -0.0006]])\n",
      "Iterarion 561\n",
      "eta = \n",
      "[[ 0.3293 -0.4611]\n",
      " [ 0.0585 -0.0383]]\n",
      "loss = 1.2448\n",
      "\n",
      "\n",
      "tensor([[-0.0199,  0.0029],\n",
      "        [-0.0303, -0.0069]])\n",
      "Iterarion 562\n",
      "eta = \n",
      "[[ 0.3291 -0.4604]\n",
      " [ 0.0574 -0.0394]]\n",
      "loss = 1.3135\n",
      "\n",
      "\n",
      "tensor([[-0.0279, -0.0130],\n",
      "        [-0.0345, -0.0074]])\n",
      "Iterarion 563\n",
      "eta = \n",
      "[[ 0.329  -0.4596]\n",
      " [ 0.0572 -0.0393]]\n",
      "loss = 1.2665\n",
      "\n",
      "\n",
      "tensor([[ 0.0699,  0.0614],\n",
      "        [-0.0575, -0.0110]])\n",
      "Iterarion 564\n",
      "eta = \n",
      "[[ 0.3288 -0.4601]\n",
      " [ 0.0585 -0.0373]]\n",
      "loss = 1.2731\n",
      "\n",
      "\n",
      "tensor([[ 0.1001,  0.0659],\n",
      "        [-0.0618, -0.0115]])\n",
      "Iterarion 565\n",
      "eta = \n",
      "[[ 0.3284 -0.4618]\n",
      " [ 0.0612 -0.0337]]\n",
      "loss = 1.2772\n",
      "\n",
      "\n",
      "tensor([[-0.0517, -0.0039],\n",
      "        [ 0.0294, -0.0016]])\n",
      "Iterarion 566\n",
      "eta = \n",
      "[[ 0.3281 -0.4633]\n",
      " [ 0.0629 -0.0302]]\n",
      "loss = 1.2608\n",
      "\n",
      "\n",
      "tensor([[-0.0075, -0.0414],\n",
      "        [ 0.0436,  0.0062]])\n",
      "Iterarion 567\n",
      "eta = \n",
      "[[ 0.3279 -0.4639]\n",
      " [ 0.0633 -0.0281]]\n",
      "loss = 1.2153\n",
      "\n",
      "\n",
      "tensor([[ 0.0196, -0.0298],\n",
      "        [ 0.0217,  0.0015]])\n",
      "Iterarion 568\n",
      "eta = \n",
      "[[ 0.3276 -0.4637]\n",
      " [ 0.0631 -0.0264]]\n",
      "loss = 1.3744\n",
      "\n",
      "\n",
      "tensor([[0.0164, 0.0071],\n",
      "        [0.0826, 0.0104]])\n",
      "Iterarion 569\n",
      "eta = \n",
      "[[ 0.3274 -0.4638]\n",
      " [ 0.061  -0.0265]]\n",
      "loss = 1.2152\n",
      "\n",
      "\n",
      "tensor([[0.0442, 0.0302],\n",
      "        [0.0699, 0.0025]])\n",
      "Iterarion 570\n",
      "eta = \n",
      "[[ 0.327  -0.4644]\n",
      " [ 0.0573 -0.0271]]\n",
      "loss = 1.3726\n",
      "\n",
      "\n",
      "tensor([[-0.0807, -0.0605],\n",
      "        [ 0.0131,  0.0040]])\n",
      "Iterarion 571\n",
      "eta = \n",
      "[[ 0.3269 -0.4638]\n",
      " [ 0.0536 -0.0283]]\n",
      "loss = 1.3943\n",
      "\n",
      "\n",
      "tensor([[-0.0012, -0.0582],\n",
      "        [-0.0306, -0.0019]])\n",
      "Iterarion 572\n",
      "eta = \n",
      "[[ 0.3268 -0.462 ]\n",
      " [ 0.0511 -0.029 ]]\n",
      "loss = 1.3504\n",
      "\n",
      "\n",
      "tensor([[ 0.0454,  0.0017],\n",
      "        [-0.0770, -0.0112]])\n",
      "Iterarion 573\n",
      "eta = \n",
      "[[ 0.3266 -0.4605]\n",
      " [ 0.0508 -0.0278]]\n",
      "loss = 1.3252\n",
      "\n",
      "\n",
      "tensor([[-0.1154, -0.0190],\n",
      "        [-0.1050, -0.0059]])\n",
      "Iterarion 574\n",
      "eta = \n",
      "[[ 0.3267 -0.4588]\n",
      " [ 0.053  -0.0258]]\n",
      "loss = 1.2442\n",
      "\n",
      "\n",
      "tensor([[-0.0689, -0.0419],\n",
      "        [-0.0514, -0.0039]])\n",
      "Iterarion 575\n",
      "eta = \n",
      "[[ 0.3269 -0.4564]\n",
      " [ 0.0563 -0.0234]]\n",
      "loss = 1.3805\n",
      "\n",
      "\n",
      "tensor([[ 0.0024,  0.0021],\n",
      "        [-0.0446, -0.0021]])\n",
      "Iterarion 576\n",
      "eta = \n",
      "[[ 0.3272 -0.4542]\n",
      " [ 0.0603 -0.0208]]\n",
      "loss = 1.3438\n",
      "\n",
      "\n",
      "tensor([[-0.0213, -0.0245],\n",
      "        [-0.0203,  0.0024]])\n",
      "Iterarion 577\n",
      "eta = \n",
      "[[ 0.3274 -0.4518]\n",
      " [ 0.0645 -0.0189]]\n",
      "loss = 1.2843\n",
      "\n",
      "\n",
      "tensor([[-0.0066,  0.0088],\n",
      "        [ 0.0024,  0.0070]])\n",
      "Iterarion 578\n",
      "eta = \n",
      "[[ 0.3276 -0.4498]\n",
      " [ 0.0682 -0.0184]]\n",
      "loss = 1.2618\n",
      "\n",
      "\n",
      "tensor([[0.0245, 0.0722],\n",
      "        [0.0743, 0.0117]])\n",
      "Iterarion 579\n",
      "eta = \n",
      "[[ 0.3278 -0.4495]\n",
      " [ 0.0696 -0.0197]]\n",
      "loss = 1.3538\n",
      "\n",
      "\n",
      "tensor([[-0.0208,  0.0060],\n",
      "        [ 0.0683,  0.0093]])\n",
      "Iterarion 580\n",
      "eta = \n",
      "[[ 0.328  -0.4493]\n",
      " [ 0.0693 -0.0225]]\n",
      "loss = 1.2375\n",
      "\n",
      "\n",
      "tensor([[-0.0185, -0.0185],\n",
      "        [ 0.0954,  0.0134]])\n",
      "Iterarion 581\n",
      "eta = \n",
      "[[ 0.3282 -0.4488]\n",
      " [ 0.0667 -0.0272]]\n",
      "loss = 1.2696\n",
      "\n",
      "\n",
      "tensor([[ 0.0212, -0.0013],\n",
      "        [ 0.1462,  0.0177]])\n",
      "Iterarion 582\n",
      "eta = \n",
      "[[ 0.3283 -0.4482]\n",
      " [ 0.0608 -0.0342]]\n",
      "loss = 1.3377\n",
      "\n",
      "\n",
      "tensor([[ 0.0505,  0.0152],\n",
      "        [-0.0360, -0.0045]])\n",
      "Iterarion 583\n",
      "eta = \n",
      "[[ 0.3283 -0.4481]\n",
      " [ 0.0564 -0.0397]]\n",
      "loss = 1.3482\n",
      "\n",
      "\n",
      "tensor([[-0.0218, -0.0030],\n",
      "        [-0.0402, -0.0067]])\n",
      "Iterarion 584\n",
      "eta = \n",
      "[[ 0.3284 -0.4479]\n",
      " [ 0.0534 -0.0437]]\n",
      "loss = 1.1632\n",
      "\n",
      "\n",
      "tensor([[ 0.0474,  0.0041],\n",
      "        [-0.0523, -0.0051]])\n",
      "Iterarion 585\n",
      "eta = \n",
      "[[ 0.3283 -0.4478]\n",
      " [ 0.052  -0.0464]]\n",
      "loss = 1.2974\n",
      "\n",
      "\n",
      "tensor([[-0.0022,  0.0238],\n",
      "        [-0.0358, -0.0092]])\n",
      "Iterarion 586\n",
      "eta = \n",
      "[[ 0.3283 -0.4482]\n",
      " [ 0.0516 -0.0474]]\n",
      "loss = 1.3627\n",
      "\n",
      "\n",
      "tensor([[ 0.0252, -0.0098],\n",
      "        [-0.0613, -0.0075]])\n",
      "Iterarion 587\n",
      "eta = \n",
      "[[ 0.3282 -0.4483]\n",
      " [ 0.0527 -0.0471]]\n",
      "loss = 1.2387\n",
      "\n",
      "\n",
      "tensor([[ 0.0412,  0.0136],\n",
      "        [-0.0555, -0.0082]])\n",
      "Iterarion 588\n",
      "eta = \n",
      "[[ 0.328  -0.4487]\n",
      " [ 0.055  -0.0455]]\n",
      "loss = 1.2791\n",
      "\n",
      "\n",
      "tensor([[ 0.0100,  0.0340],\n",
      "        [-0.0482, -0.0114]])\n",
      "Iterarion 589\n",
      "eta = \n",
      "[[ 0.3278 -0.4498]\n",
      " [ 0.0582 -0.0422]]\n",
      "loss = 1.3168\n",
      "\n",
      "\n",
      "tensor([[ 0.0547,  0.0245],\n",
      "        [ 0.0102, -0.0067]])\n",
      "Iterarion 590\n",
      "eta = \n",
      "[[ 0.3275 -0.4512]\n",
      " [ 0.0608 -0.0382]]\n",
      "loss = 1.2808\n",
      "\n",
      "\n",
      "tensor([[-0.0738,  0.0021],\n",
      "        [ 0.0016, -0.0013]])\n",
      "Iterarion 591\n",
      "eta = \n",
      "[[ 0.3274 -0.4525]\n",
      " [ 0.0632 -0.0344]]\n",
      "loss = 1.3171\n",
      "\n",
      "\n",
      "tensor([[-0.0005,  0.0082],\n",
      "        [ 0.0084, -0.0016]])\n",
      "Iterarion 592\n",
      "eta = \n",
      "[[ 0.3273 -0.4539]\n",
      " [ 0.0651 -0.0307]]\n",
      "loss = 1.3126\n",
      "\n",
      "\n",
      "tensor([[0.0276, 0.0447],\n",
      "        [0.0086, 0.0008]])\n",
      "Iterarion 593\n",
      "eta = \n",
      "[[ 0.3271 -0.4561]\n",
      " [ 0.0667 -0.0275]]\n",
      "loss = 1.3282\n",
      "\n",
      "\n",
      "tensor([[0.0125, 0.0044],\n",
      "        [0.0173, 0.0007]])\n",
      "Iterarion 594\n",
      "eta = \n",
      "[[ 0.327  -0.4581]\n",
      " [ 0.0676 -0.0247]]\n",
      "loss = 1.4448\n",
      "\n",
      "\n",
      "tensor([[-0.0623, -0.0329],\n",
      "        [ 0.0241,  0.0103]])\n",
      "Iterarion 595\n",
      "eta = \n",
      "[[ 0.327  -0.4592]\n",
      " [ 0.0679 -0.0238]]\n",
      "loss = 1.3099\n",
      "\n",
      "\n",
      "tensor([[-0.0104,  0.0281],\n",
      "        [ 0.0984,  0.0143]])\n",
      "Iterarion 596\n",
      "eta = \n",
      "[[ 0.327  -0.4608]\n",
      " [ 0.0658 -0.0253]]\n",
      "loss = 1.3414\n",
      "\n",
      "\n",
      "tensor([[0.0268, 0.0230],\n",
      "        [0.0912, 0.0163]])\n",
      "Iterarion 597\n",
      "eta = \n",
      "[[ 0.327  -0.4627]\n",
      " [ 0.0617 -0.0293]]\n",
      "loss = 1.2545\n",
      "\n",
      "\n",
      "tensor([[-0.0628, -0.0689],\n",
      "        [ 0.0177,  0.0031]])\n",
      "Iterarion 598\n",
      "eta = \n",
      "[[ 0.3271 -0.4631]\n",
      " [ 0.0577 -0.0333]]\n",
      "loss = 1.3458\n",
      "\n",
      "\n",
      "tensor([[ 0.0033,  0.0134],\n",
      "        [-0.0167,  0.0008]])\n",
      "Iterarion 599\n",
      "eta = \n",
      "[[ 0.3272 -0.4636]\n",
      " [ 0.0544 -0.0371]]\n",
      "loss = 1.4062\n",
      "\n",
      "\n",
      "tensor([[ 0.0056,  0.0374],\n",
      "        [-0.0539, -0.0120]])\n",
      "Iterarion 600\n",
      "eta = \n",
      "[[ 0.3273 -0.4649]\n",
      " [ 0.0527 -0.0386]]\n",
      "loss = 1.2313\n",
      "\n",
      "\n",
      "tensor([[ 0.0037, -0.0150],\n",
      "        [-0.0046,  0.0003]])\n",
      "Iterarion 601\n",
      "eta = \n",
      "[[ 0.3273 -0.4657]\n",
      " [ 0.0513 -0.04  ]]\n",
      "loss = 1.2964\n",
      "\n",
      "\n",
      "tensor([[ 0.0849,  0.0159],\n",
      "        [-0.0789, -0.0143]])\n",
      "Iterarion 602\n",
      "eta = \n",
      "[[ 0.3272 -0.4668]\n",
      " [ 0.052  -0.0389]]\n",
      "loss = 1.2957\n",
      "\n",
      "\n",
      "tensor([[-0.0016, -0.0124],\n",
      "        [-0.0806, -0.0088]])\n",
      "Iterarion 603\n",
      "eta = \n",
      "[[ 0.327  -0.4675]\n",
      " [ 0.0545 -0.0366]]\n",
      "loss = 1.3541\n",
      "\n",
      "\n",
      "tensor([[-0.0612, -0.0153],\n",
      "        [ 0.0552,  0.0039]])\n",
      "Iterarion 604\n",
      "eta = \n",
      "[[ 0.327  -0.4678]\n",
      " [ 0.0554 -0.0352]]\n",
      "loss = 1.1834\n",
      "\n",
      "\n",
      "tensor([[ 0.0814,  0.0709],\n",
      "        [-0.0196, -0.0070]])\n",
      "Iterarion 605\n",
      "eta = \n",
      "[[ 0.3269 -0.4696]\n",
      " [ 0.0567 -0.0327]]\n",
      "loss = 1.2820\n",
      "\n",
      "\n",
      "tensor([[ 0.0196,  0.0319],\n",
      "        [-0.0541, -0.0114]])\n",
      "Iterarion 606\n",
      "eta = \n",
      "[[ 0.3267 -0.4718]\n",
      " [ 0.0592 -0.0288]]\n",
      "loss = 1.3883\n",
      "\n",
      "\n",
      "tensor([[-0.0110,  0.0049],\n",
      "        [-0.0208,  0.0010]])\n",
      "Iterarion 607\n",
      "eta = \n",
      "[[ 0.3265 -0.4739]\n",
      " [ 0.0619 -0.0254]]\n",
      "loss = 1.3045\n",
      "\n",
      "\n",
      "tensor([[-0.0015, -0.0122],\n",
      "        [ 0.0485,  0.0090]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterarion 608\n",
      "eta = \n",
      "[[ 0.3264 -0.4755]\n",
      " [ 0.0632 -0.0237]]\n",
      "loss = 1.3174\n",
      "\n",
      "\n",
      "tensor([[-0.0392, -0.0197],\n",
      "        [ 0.0807,  0.0133]])\n",
      "Iterarion 609\n",
      "eta = \n",
      "[[ 0.3264 -0.4766]\n",
      " [ 0.0624 -0.0243]]\n",
      "loss = 1.2806\n",
      "\n",
      "\n",
      "tensor([[-0.0593, -0.0411],\n",
      "        [-0.0055,  0.0020]])\n",
      "Iterarion 610\n",
      "eta = \n",
      "[[ 0.3265 -0.4767]\n",
      " [ 0.0618 -0.0252]]\n",
      "loss = 1.2865\n",
      "\n",
      "\n",
      "tensor([[ 0.0401, -0.0154],\n",
      "        [-0.0116, -0.0017]])\n",
      "Iterarion 611\n",
      "eta = \n",
      "[[ 0.3265 -0.4765]\n",
      " [ 0.0616 -0.0257]]\n",
      "loss = 1.2668\n",
      "\n",
      "\n",
      "tensor([[ 0.0163,  0.0236],\n",
      "        [ 0.0213, -0.0002]])\n",
      "Iterarion 612\n",
      "eta = \n",
      "[[ 0.3265 -0.4768]\n",
      " [ 0.0609 -0.0261]]\n",
      "loss = 1.2986\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eta_method = 'random'\n",
    "check_grads = False\n",
    "max_it = 10000\n",
    "lr = 10**-2\n",
    "\n",
    "N = 2000\n",
    "batch_size = int(N)\n",
    "ub = 20\n",
    "\n",
    "t_space = torch.linspace(0, ub, N)\n",
    "x0 = torch.tensor([-1.0, 1.0])\n",
    "x0.requires_grad_()\n",
    "tol = 10**-2\n",
    "\n",
    "\n",
    "if eta_method == 'random':\n",
    "    eta0 = torch.tensor(np.random.normal(0, 0.1, (2,2)), dtype=torch.float).to(device)\n",
    "elif eta_method == 'zeros':\n",
    "    eta0 = torch.tensor(np.zeros((2,2)), dtype=torch.float).to(device)\n",
    "elif eta_method == 'actual':\n",
    "    eta0 = torch.tensor([[0.3, 0], [0, 0.05]], dtype=torch.float).to(device)\n",
    "else:\n",
    "    raise ValueError('You are trying to set eta in a way that is not supported. Check eta_method.')\n",
    "\n",
    "print(eta0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    true_eta = torch.tensor([[0.3, 0], [0, 0.05]], dtype=torch.float)\n",
    "#     true_eta = torch.tensor([[0, 0.3], [0.05, 0]], dtype=torch.float)\n",
    "    true_FN = lambda t, x : FN_torch_modified(t, x, true_eta)\n",
    "    true_soln = odeint(true_FN, x0, t_space)\n",
    "    true_diff = torch.diff(true_soln, axis=0)\n",
    "\n",
    "\n",
    "optfitz = OptimizeFitzhugh(x0, t_space, 2, eta0).to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam([optfitz.eta], lr=lr)\n",
    "# loss = DiffLoss().to(device)\n",
    "loss = torch.nn.MSELoss().to(device)\n",
    "\n",
    "print('eta_0 = \\n{}\\n'.format(optfitz.eta.detach().numpy()))\n",
    "\n",
    "loss_vec = []\n",
    "eta_log = []\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "for it in range(max_it):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    batch_ix = np.random.choice(range(N-1), batch_size)\n",
    "    batch_time = t_space[batch_ix]\n",
    "    batch_true = true_soln[batch_ix,:]\n",
    "    batch_true_diff = true_diff[batch_ix,:]\n",
    "\n",
    "#     pred_soln = odeint(optfitz, x0, t_space).to(device)\n",
    "#     pred_diff = make_predictions(t_space, true_soln, optfitz).to(device)\n",
    "    batch_pred_diff = make_predictions(batch_time, batch_true, optfitz, batched=True).to(device)\n",
    "    \n",
    "#     loss_curr = loss(pred_diff, true_diff)\n",
    "    loss_curr = loss(batch_pred_diff, batch_true_diff)\n",
    "    loss_curr.retain_grad()\n",
    "    loss_curr.backward()\n",
    "\n",
    "    if check_grads:\n",
    "        if it > 0:\n",
    "            for i in range(optfitz.eta.shape[0]):\n",
    "                for j in range(optfitz.eta.shape[1]):\n",
    "                    print('Backprop Derivative for {},{} = {:.2f}'.format(i, j, optfitz.eta.grad[i,j]))\n",
    "                    print('Checked Derivative for {},{} = {:.2f}'.format(i, j, grad_check[i,j]))\n",
    "                    # print('Error Ratio = {:.2f}'.format(optfitz.eta.grad[i,j] / grad_check[i,j]))\n",
    "                    print()\n",
    "        print('\\n')\n",
    "\n",
    "    print('Iterarion {}'.format(it+1))\n",
    "    print('eta = \\n{}'.format(optfitz.eta.detach().numpy()))\n",
    "    eta_log.append(optfitz.eta.detach().numpy())\n",
    "    print('loss = {:.4f}\\n\\n'.format(loss_curr))\n",
    "\n",
    "    if np.linalg.norm(optfitz.eta.grad.detach().numpy()) < tol:\n",
    "        if not (eta_method == 'actual' and it < 1):\n",
    "            break\n",
    "\n",
    "    print(optfitz.eta.grad)\n",
    "    loss_vec.append(loss_curr.detach().numpy())\n",
    "\n",
    "    if check_grads:\n",
    "\n",
    "        print('===Derivative Check===')\n",
    "\n",
    "        grad_check = np.zeros((optfitz.eta.shape[0], optfitz.eta.shape[1]))\n",
    "        for i in range(optfitz.eta.shape[0]):\n",
    "            for j in range(optfitz.eta.shape[1]):\n",
    "                eps = 10**(-3)\n",
    "                eta_check_0 = optfitz.eta.detach().clone()\n",
    "                eta_check_1 = optfitz.eta.detach().clone()\n",
    "\n",
    "                eta_check_0[i,j] += eps\n",
    "                eta_check_1[i,j] -= eps\n",
    "\n",
    "                FN_check_0 = lambda t, S : FN_torch_vec(t, S, eta_check_0)\n",
    "                x_pred_check_0 = FN_check_0(t_space, true_soln)\n",
    "                FN_check_1 = lambda t, S : FN_torch_vec(t, S, eta_check_1)\n",
    "                x_pred_check_1 = FN_check_1(t_space, true_soln)\n",
    "\n",
    "                L0 = loss(x_pred_check_0, true_soln)\n",
    "                L1 = loss(x_pred_check_1, true_soln)\n",
    "                grad_check[i,j] = ((L0 - L1)/(2*eps)).item()\n",
    "\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(range(len(loss_vec)), loss_vec)\n",
    "ax.set_xlabel('Iterations')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Loss as a Function of Iterations')\n",
    "ax.set_xlim((0, len(loss_vec)))\n",
    "ax.set_ylim((0, max(loss_vec) * 1.2))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3265, -0.4768],\n",
      "        [ 0.0609, -0.0261]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eta_found = optfitz.eta.detach()\n",
    "fn_found = lambda t, x : FN_torch_modified(t, x, eta_found)\n",
    "# fn_found = lambda t, x : FN_torch_modified(t, x, torch.zeros((2,2)))\n",
    "\n",
    "print(eta_found)\n",
    "\n",
    "found_soln = odeint(fn_found, x0, t_space)\n",
    "\n",
    "ax1 = plt.subplot(211)\n",
    "ax1.set_xlim(0,ub)\n",
    "plt.plot(t_space, true_soln[:,0])\n",
    "plt.plot(t_space, found_soln.detach()[:,0])\n",
    "\n",
    "ax2 = plt.subplot(212, sharex=ax1)\n",
    "plt.plot(t_space, true_soln[:,1])\n",
    "plt.plot(t_space, found_soln.detach()[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-79481a656fda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m tensor([[ 0.3285, -0.4670],\n\u001b[0m\u001b[1;32m      2\u001b[0m         [ 0.0596, -0.0284]])\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m tensor([[ 0.3285, -0.4670],\n\u001b[1;32m      5\u001b[0m         [ 0.0596, -0.0284]])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tensor' is not defined"
     ]
    }
   ],
   "source": [
    "tensor([[ 0.3285, -0.4670],\n",
    "        [ 0.0596, -0.0284]])\n",
    "\n",
    "tensor([[ 0.3285, -0.4670],\n",
    "        [ 0.0596, -0.0284]])\n",
    "\n",
    "tensor([[ 0.3278, -0.4624],\n",
    "        [ 0.0596, -0.0284]])\n",
    "\n",
    "tensor([[ 0.2944,  0.0294],\n",
    "        [ 0.0441, -0.0341]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_eta = torch.tensor([[0.3, 0], [0, 0.05]], dtype=torch.float)\n",
    "\n",
    "fn_true = lambda t, x : FN_torch_modified(t, x, true_eta)\n",
    "\n",
    "N = 200\n",
    "ub = 20\n",
    "\n",
    "t_space = torch.linspace(0, ub, N)\n",
    "x0 = torch.tensor([-1.0, 1.0])\n",
    "soln = odeint(fn_true, x0, t_space)\n",
    "\n",
    "soln_unpert = odeint(FN_torch, x0, t_space)\n",
    "\n",
    "ax1 = plt.subplot(211)\n",
    "ax1.set_xlim(0,ub)\n",
    "plt.plot(t_space, soln_unpert[:,0])\n",
    "plt.plot(t_space, soln[:,0])\n",
    "\n",
    "ax2 = plt.subplot(212, sharex=ax1)\n",
    "plt.plot(t_space, soln_unpert[:,1])\n",
    "plt.plot(t_space, soln[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizeFitzhughLarge(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, x0, t_space, n_terms, eta0):\n",
    "        super(OptimizeFitzhughLarge, self).__init__()\n",
    "        self.x0 = x0\n",
    "        self.t_space = t_space\n",
    "        self.n_terms = n_terms\n",
    "        self.eta = eta0\n",
    "        self.eta.requires_grad_()\n",
    "        \n",
    "    def rhs(self, x, t):\n",
    "        return FN_torch_modified_large(t, x, self.eta)\n",
    "    \n",
    "    def forward(self, t, x):\n",
    "        return self.rhs(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta = \n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0005, 0.0000, 0.0500, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_basis = 12\n",
    "\n",
    "true_eta = torch.zeros((2,n_basis), dtype=torch.float)\n",
    "non_zero = np.random.choice(range(2*n_basis), 3, replace=False)\n",
    "for ix in non_zero:\n",
    "    i = int(ix/n_basis)\n",
    "    j = int(ix)%n_basis\n",
    "    if j == 5 or j == 6:\n",
    "        true_eta[i,j] += 0.0005\n",
    "    else:\n",
    "        true_eta[i,j] += 0.05\n",
    "    \n",
    "# true_eta = torch.tensor([[0,0,0,0,0,0,0,0,0,0,0.05,0], [0,0.05,0,0,0,0.005,0,0,0,0,0,0]], dtype=torch.float)\n",
    "\n",
    "print('eta = \\n{}'.format(true_eta))\n",
    "\n",
    "fn_true = lambda t, x : FN_torch_modified_large(t, x, true_eta)\n",
    "\n",
    "N = 200\n",
    "ub = 20\n",
    "\n",
    "t_space = torch.linspace(0, ub, N)\n",
    "x0 = torch.tensor([-1.0, 1.0])\n",
    "soln = odeint(fn_true, x0, t_space)\n",
    "\n",
    "soln_unpert = odeint(FN_torch, x0, t_space)\n",
    "\n",
    "ax1 = plt.subplot(211)\n",
    "ax1.set_xlim(0,ub)\n",
    "plt.plot(t_space, soln_unpert[:,0])\n",
    "plt.plot(t_space, soln[:,0])\n",
    "\n",
    "ax2 = plt.subplot(212, sharex=ax1)\n",
    "plt.plot(t_space, soln_unpert[:,1])\n",
    "plt.plot(t_space, soln[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta_0 = \n",
      "[[ 0.0004 -0.0004 -0.0001  0.0004  0.0017 -0.0002 -0.0004  0.0002  0.0002\n",
      "   0.0002  0.0011 -0.0006]\n",
      " [ 0.0009 -0.0003  0.0001 -0.0009  0.0012 -0.0004 -0.0007 -0.0021  0.0001\n",
      "   0.0005  0.0001 -0.0003]]\n",
      "\n",
      "Iterarion 1\n",
      "eta = \n",
      "[[ 0.0004 -0.0004 -0.0001  0.0004  0.0017 -0.0002 -0.0004  0.0002  0.0002\n",
      "   0.0002  0.0011 -0.0006]\n",
      " [ 0.0009 -0.0003  0.0001 -0.0009  0.0012 -0.0004 -0.0007 -0.0021  0.0001\n",
      "   0.0005  0.0001 -0.0003]]\n",
      "loss = 0.0005\n",
      "\n",
      "\n",
      "tensor([[ 0.0021, -0.0031,  0.0007, -0.0154,  0.0121,  0.0109, -0.0235,  0.0064,\n",
      "          0.0006, -0.0004,  0.0015, -0.0045],\n",
      "        [-0.0223, -0.0084,  0.0103, -0.0043,  0.0426,  0.2045, -0.0272, -0.0408,\n",
      "          0.0204, -0.0028,  0.0098, -0.0052]])\n",
      "Iterarion 2\n",
      "eta = \n",
      "[[-5.8621e-04  5.8456e-04 -1.1257e-03  1.4435e-03  7.4706e-04 -1.1693e-03\n",
      "   5.7004e-04 -7.6634e-04 -8.2705e-04  1.2415e-03  7.5157e-05  4.4092e-04]\n",
      " [ 1.8995e-03  6.9268e-04 -8.8233e-04  9.0990e-05  1.9183e-04 -1.3804e-03\n",
      "   3.4832e-04 -1.0867e-03 -8.6778e-04  1.4922e-03 -8.9616e-04  6.8951e-04]]\n",
      "loss = 0.0002\n",
      "\n",
      "\n",
      "tensor([[-9.7879e-04, -1.4758e-03, -9.6109e-04, -1.7058e-02,  1.3304e-02,\n",
      "          9.8390e-03, -2.4752e-02, -6.8372e-03, -1.5120e-03, -2.2638e-04,\n",
      "          2.4849e-04, -3.3744e-03],\n",
      "        [ 7.2054e-02,  1.0468e-02,  4.1134e-04, -4.3584e-03,  5.3955e-02,\n",
      "          3.5636e-01,  2.2484e-02,  2.1846e-01,  2.3700e-02,  2.6317e-02,\n",
      "          5.2118e-03,  8.2434e-03]])\n",
      "Iterarion 3\n",
      "eta = \n",
      "[[-0.0009  0.0015 -0.0009  0.0024 -0.0003 -0.0022  0.0016 -0.0007 -0.0004\n",
      "   0.0022 -0.0007  0.0014]\n",
      " [ 0.0014  0.0005 -0.0016  0.0011 -0.0008 -0.0024  0.0004 -0.0017 -0.0019\n",
      "   0.0008 -0.0018  0.0004]]\n",
      "loss = 0.0010\n",
      "\n",
      "\n",
      "tensor([[ 7.7650e-03, -2.1552e-03,  6.0795e-03,  3.6177e-02, -2.7672e-02,\n",
      "         -1.7156e-02,  4.7596e-02,  4.1220e-02,  8.5412e-03, -7.3584e-04,\n",
      "          3.1107e-03,  2.2774e-03],\n",
      "        [-3.4329e-01, -6.4465e-02,  2.2856e-02,  9.6271e-03, -1.2941e-01,\n",
      "         -1.0225e+00, -1.5506e-01, -9.7981e-01, -4.8087e-02, -1.1446e-01,\n",
      "          2.1539e-03, -4.8488e-02]])\n",
      "Iterarion 4\n",
      "eta = \n",
      "[[-0.0016  0.0025 -0.0015  0.0023 -0.0001 -0.0022  0.0015 -0.0013 -0.0009\n",
      "   0.0031 -0.0015  0.0019]\n",
      " [ 0.0019  0.0011 -0.0024  0.001  -0.0006 -0.002   0.001  -0.0012 -0.0018\n",
      "   0.0013 -0.0027  0.001 ]]\n",
      "loss = 0.0001\n",
      "\n",
      "\n",
      "tensor([[ 2.8753e-03, -1.4400e-03,  2.2294e-03,  8.6503e-03, -6.6759e-03,\n",
      "         -3.5654e-03,  1.0454e-02,  1.4654e-02,  3.0212e-03, -3.7769e-04,\n",
      "          1.4017e-03, -2.7607e-04],\n",
      "        [-1.1651e-01, -2.2467e-02,  9.1672e-03,  2.5621e-03, -3.4107e-02,\n",
      "         -2.9482e-01, -5.5487e-02, -3.2874e-01, -1.2786e-02, -3.8036e-02,\n",
      "          2.3476e-03, -1.6682e-02]])\n",
      "Iterarion 5\n",
      "eta = \n",
      "[[-2.2719e-03  3.3781e-03 -2.1487e-03  2.1044e-03  6.8288e-05 -2.1011e-03\n",
      "   1.3457e-03 -1.9504e-03 -1.5716e-03  4.0425e-03 -2.4025e-03  2.2938e-03]\n",
      " [ 2.5274e-03  1.7855e-03 -3.2048e-03  7.4224e-04 -3.1271e-04 -1.6522e-03\n",
      "   1.7000e-03 -5.9153e-04 -1.5368e-03  1.9032e-03 -3.4633e-03  1.6419e-03]]\n",
      "loss = 0.0004\n",
      "\n",
      "\n",
      "tensor([[-5.8279e-03,  2.9761e-04, -4.1957e-03, -2.9871e-02,  2.3374e-02,\n",
      "          1.4752e-02, -4.0842e-02, -2.9806e-02, -5.6257e-03,  7.9882e-05,\n",
      "         -1.7174e-03, -3.4999e-03],\n",
      "        [ 2.5070e-01,  4.4211e-02, -1.4034e-02, -8.1052e-03,  1.0450e-01,\n",
      "          7.9882e-01,  1.0729e-01,  7.1794e-01,  4.2582e-02,  8.4676e-02,\n",
      "          1.9097e-03,  3.2941e-02]])\n",
      "Iterarion 6\n",
      "eta = \n",
      "[[-2.4669e-03  4.1195e-03 -2.3219e-03  2.2621e-03 -9.9037e-05 -2.3412e-03\n",
      "   1.5452e-03 -2.1127e-03 -1.7387e-03  4.7821e-03 -2.8336e-03  2.8638e-03]\n",
      " [ 2.6426e-03  1.9585e-03 -3.5632e-03  8.9627e-04 -4.2087e-04 -1.6911e-03\n",
      "   1.8905e-03 -4.8941e-04 -1.7081e-03  1.9941e-03 -4.2107e-03  1.8077e-03]]\n",
      "loss = 0.0005\n",
      "\n",
      "\n",
      "tensor([[-6.7241e-03,  6.5880e-04, -4.8192e-03, -3.2067e-02,  2.5117e-02,\n",
      "          1.5579e-02, -4.3537e-02, -3.4028e-02, -6.3663e-03,  1.5322e-04,\n",
      "         -2.1158e-03, -3.4817e-03],\n",
      "        [ 2.8333e-01,  5.0366e-02, -1.6882e-02, -8.9106e-03,  1.1343e-01,\n",
      "          8.7805e-01,  1.2281e-01,  8.0840e-01,  4.5563e-02,  9.5324e-02,\n",
      "          1.2070e-03,  3.7418e-02]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-2567b187b345>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mloss_curr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_soln\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_soln\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mloss_curr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretain_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mloss_curr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheck_grads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mBackwardCFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FunctionBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFunctionCtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_HookMixin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0;31m# _forward_cls is defined by derived class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;31m# The user should define either backward or vjp but never both.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eta_method = 'random'\n",
    "check_grads = False\n",
    "max_it = 1000\n",
    "\n",
    "N = 200\n",
    "ub = 20\n",
    "n_basis = 12\n",
    "\n",
    "t_space = torch.linspace(0, ub, N)\n",
    "x0 = torch.tensor([-1.0, 1.0])\n",
    "x0.requires_grad_()\n",
    "tol = 10**-4\n",
    "\n",
    "true_eta = torch.zeros((2,n_basis), dtype=torch.float)\n",
    "non_zero = np.random.choice(range(2*n_basis), 3, replace=False)\n",
    "for ix in non_zero:\n",
    "    i = int(ix/n_basis)\n",
    "    j = int(ix)%n_basis\n",
    "    if j == 5 or j == 6:\n",
    "        true_eta[i,j] += 0.0005\n",
    "    else:\n",
    "        true_eta[i,j] += 0.05\n",
    "\n",
    "\n",
    "if eta_method == 'random':\n",
    "    eta0 = torch.tensor(np.random.normal(0, 0.001, (2, n_basis)), dtype=torch.float).to(device)\n",
    "elif eta_method == 'zeros':\n",
    "    eta0 = torch.tensor(np.zeros((2, n_basis)), dtype=torch.float).to(device)\n",
    "elif eta_method == 'actual':\n",
    "    eta0 = true_eta.copy_()\n",
    "else:\n",
    "    raise ValueError('You are trying to set eta in a way that is not supported. Check eta_method.')\n",
    "\n",
    "# print(eta0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    true_FN = lambda t, x : FN_torch_modified_large(t, x, true_eta)\n",
    "    true_soln = odeint(true_FN, x0, t_space)\n",
    "\n",
    "\n",
    "optfitz = OptimizeFitzhughLarge(x0, t_space, n_basis, eta0).to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam([optfitz.eta], lr=10**-3)\n",
    "loss = DiffLoss().to(device)\n",
    "\n",
    "print('eta_0 = \\n{}\\n'.format(optfitz.eta.detach().numpy()))\n",
    "\n",
    "loss_vec = []\n",
    "eta_log = []\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "for it in range(max_it):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    pred_soln = odeint(optfitz, x0, t_space).to(device)\n",
    "\n",
    "    loss_curr = loss(pred_soln, true_soln)\n",
    "    loss_curr.retain_grad()\n",
    "    loss_curr.backward()\n",
    "\n",
    "    if check_grads:\n",
    "        if it > 0:\n",
    "            for i in range(optfitz.eta.shape[0]):\n",
    "                for j in range(optfitz.eta.shape[1]):\n",
    "                    print('Backprop Derivative for {},{} = {:.2f}'.format(i, j, optfitz.eta.grad[i,j]))\n",
    "                    print('Checked Derivative for {},{} = {:.2f}'.format(i, j, grad_check[i,j]))\n",
    "                    # print('Error Ratio = {:.2f}'.format(optfitz.eta.grad[i,j] / grad_check[i,j]))\n",
    "                    print()\n",
    "        print('\\n')\n",
    "\n",
    "    print('Iterarion {}'.format(it+1))\n",
    "    print('eta = \\n{}'.format(optfitz.eta.detach().numpy()))\n",
    "    eta_log.append(optfitz.eta.detach().numpy())\n",
    "    print('loss = {:.4f}\\n\\n'.format(loss_curr))\n",
    "\n",
    "    if np.linalg.norm(optfitz.eta.grad.detach().numpy()) < tol:\n",
    "        if not (eta_method == 'actual' and it < 1):\n",
    "            break\n",
    "\n",
    "    loss_vec.append(loss_curr.detach().numpy())\n",
    "\n",
    "    if check_grads:\n",
    "\n",
    "        print('===Derivative Check===')\n",
    "\n",
    "        grad_check = np.zeros((optfitz.eta.shape[0], optfitz.eta.shape[1]))\n",
    "        for i in range(optfitz.eta.shape[0]):\n",
    "            for j in range(optfitz.eta.shape[1]):\n",
    "                eps = 10**(-3)\n",
    "                eta_check_0 = optfitz.eta.detach().clone()\n",
    "                eta_check_1 = optfitz.eta.detach().clone()\n",
    "\n",
    "                eta_check_0[i,j] += eps\n",
    "                eta_check_1[i,j] -= eps\n",
    "\n",
    "                FN_check_0 = lambda t, S : FN_torch_modified_large(t, S, eta_check_0)\n",
    "                x_pred_check_0 = odeint(FN_check_0, x0, t_space)\n",
    "                FN_check_1 = lambda t, S : FN_torch_modified_large(t, S, eta_check_1)\n",
    "                x_pred_check_1 = odeint(FN_check_1, x0, t_space)\n",
    "\n",
    "                L0 = loss(x_pred_check_0, true_soln)\n",
    "                L1 = loss(x_pred_check_1, true_soln)\n",
    "                grad_check[i,j] = ((L0 - L1)/(2*eps)).item()\n",
    "\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(range(len(loss_vec)), loss_vec)\n",
    "ax.set_xlabel('Iterations')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Loss as a Function of Iterations')\n",
    "ax.set_xlim((0, max_it))\n",
    "ax.set_ylim((0, max(loss_vec) * 1.2))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe learn over a random subset of the basis? How to know when finished?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
