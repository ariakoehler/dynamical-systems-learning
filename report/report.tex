\documentclass[12pt]{article}

\author{Carter Koehler\\{\small Advisor: Matthew Plumlee}}
\title{Locating Error in Dynamical Systems}
\date{03/19/2022}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{float}

%% \usepackage{fullpage}


\newcommand{\cn}{$^{\textit{[citation needed]}}$}
%% \usepackage{}


\begin{document}

\maketitle



\begin{abstract}
  
\end{abstract}


\section{Notation}

\begin{itemize}

\item
  $k$: Number of dimensions of state vector

\item
  $N$: Number of time points

\item
  $t_i$: Time at point $i$

\item
  $\beta$: Parameters of a given model, usually those being estimated.
  
\item
  $x_i^* \in \mathbb{R}^k,\, i=1,\ldots, N$: State vector of the ``true'' model at time $t_i$. 

\item
  $x_i \in \mathbb{R}^k,\, i=1,\ldots, N$: State vector of the approximate model at time $t_i$. 

\item
  $y_i^*$: Diff vector for the exact model, $y_i^* = x_{i+1}^* - x_i^*$
  
\item
  $y_i$: Diff vector for the approximate model, $y_i = x_{i+1} - x_i$

\item
  $f_0: \mathbb{R}^k \to \mathbb{R}^k$: Basic model, which is known in principle.


\item
  $m^*: \mathbb{R}^k \to \mathbb{R}^k$: Unmodelled terms in a system. In principle not known.
  
\item
  $n$: Number of basis functions we search over when looking for unmodelled terms.
  
\item
  $\eta \in \mathbb{R}^n$: Parameters associated with the functions in our search basis.

\end{itemize}



\section{Introduction}

\subsection{Direction}

Dynamical Systems models have been used to great effect in a variety of different fields, and though analysis of these models is well-worn ground, some problems remain when it comes to comparing predictions by the model to real-world data.


First and foremost is the issue of parameter estimation. Though frameworks exist for estimating the constant parameters of a differential equation, such frameworks run into a variety of problems, including$\ldots$


The problem we will focus on primarily is the issue of locating sources of error in dynamical systems. If a proposed model gives us a certain quantity of error, how do we know what causes that error? Is it the result of unmodelled effects in the right-hand sides of our equations? If so, can we learn those effects given some guesses of their shapes? How much error is coming from discretizing the time steps, and can we estimate that and try to account for it when making predictions? And last, how much of the error we see can we attribute to ``true'' noise or measurement error? Many attempts have been made, with more or less success, to address these issues, but few have attempted to look at these problems in a unified way and attempted to tackle the problem of uncertainty in dynamical systems as a single problem.


These are obviously very large problems, and we won't try to solve all of them forever in this limited research span, but we think that approaching them as a unified problem will provide useful ways of thinking as the field progresses.


The dynamical systems we will look at\---and the questions we try to answer\---can take multiple different forms, but the basic problem from which all others descend concerns the general system $$\dot{x}(t) = f(x,t;\beta)$$

Though most of these methods work in the general case, all of the systems we actually look at will have eno direct dependence on $t$, so we will ignore it going forward and just write $f(x;\beta)$.


\section{Background}

\subsection{Parameter Estimation}

The first problem we are interested in is estimating $\beta$. That is, given $f(x;\beta)$ and a set of observations $y_1, \ldots, y_N$, can we find $\beta$ to within a reasonable error margin? Perhaps unsurprisingly, this is a well-worn problem with many different solution methods.

Gelman, et al. (1996) solved a particular instance of this problem, related to pharmacokinetics, using a hierarchical Bayesian approach. They began with a Bayesian prior describing the parameters of their model, under which they numerically solved the dynamical systems and then used the resulting error distributions to update their paramter distributions using fairly standard Monte Carlo methods. One advantage this gave them in their particular case was that it allowed them to jointly construct a population model and individual models by exploiting the hierarchical nature of Bayesian models.\cite{gelman} However, for a general problems their method has a litany of problems, including that there are not always obvious choices of prior, and the computation of posterior is not always tractable.

More recently, the Bayesian approach for parameter estimation has fallen out of favor and been largely replaced by collocation methods, like those used in Ramsay, et al. (2007), which treats the problem as a nested optimization, which considers the solution of the system as a sum of basis functions. They optimize in their outer loop over the parameters, checking for fit against observed values, while their inner loop finds the coefficients of the basis functions which give the optimally-fitting function to the system for a given set of parameters.\cite{ramsay} This generally gives good estimates to the parameters in question, but it gives almost no indication of how good they are.

Even more recently, methods from machine learning have been brought to bear on this problem. Levine and Stuart (2021) use RNNs to solve not only the problem of parameter estimation, but also the issue of discovering model error, which is broadly defined as errors resulting from a misspecified or underspecified model. For example, if one sets $\dot{x} \propto x$, but in reality $\dot{x} \propto x^2$, there is no way to recover the ``real'' model through simple parameter estimation. Their methods are remarkably powerful and show additionally that starting with an educated guess of the true model can cause RNNs to perform much better than they would on their own. However, there are a variety of questions that go unanswered. For example, how much uncertainty can we expect in these estimations in general? And how can we ensure that the parameters we discover, as well as our starting model, are uniquely meaningful, and that we don't just absorb the ``known'' model in our discovered model?


\subsection{Uncertainty Quantification}

In addition to finding the parameters of the dynamical systems we are interested in, we would also like to know the uncertainty associated with our estimates. This is mainly for the purpose of determining when the solution is ``found'' to within a specified tolerance. Techniques exist for determining worst-case error, but in practice the error estimates never reach below desired thresholds, leading to the need for other heuristics to determine when enough data has been collected, among other controlling factors.\cn However, precise knowledge of uncertainty can also used to better estimate the solution and parameters of the system when working under a Bayesian framework, as proposed in Chkrebtii, et al. (2016). However, this naturally requires the use of Bayesian methods, including Markov Chain Monte Carlo methods, which have a variety of problems that can arise, not the least of which that they are not guaranteed to converge, and that it can be difficult to tell when they have converged.

These problems are difficult to avoid, however, when quantifying uncertainty. Most current methods of uncertainty analysis require the use of Bayesian methods of solution, primarily because the posterior distribution of an estimated parameter typically comes packaged with a measure of variance. For example, Cockayne, et al. (2019) lays out a set of reasonable conditions under which the solution to a Dynamical Systems attained using Bayesian methods can give the average-case error\cite{cockayne}.


\section{Current Project}

Of course, solving all of the problems in the field of Numerical Solutions to Dynamical Systems, while something we would like to do, is a bit of a tall ask for a rather limited research period, and we include the above sections mostly to give a sense of the broad direction we would like to go in our research. For the time being, however, we will be content to reproduce some of the results found in the papers listed above, and to provide a limited proof of concept for some of our own methods.

Our work here will follow most closely from Levine and Stuart (2021) and will focus primarily on cases in which the main model\---including parameters\---is known, or at least hypothesized, but misses extra terms in the right-hand side of the system. In particular, if we consider the system describing the evolution of the state $x \in \mathbb{R}^m$ according to the system $$\dot{x} = f(x;\beta, \eta)$$ where we further divide the right-hand side into the known part and the unknown part, say $f(x;\beta, \eta) = f_0(x; \beta) + m^*(x; \eta)$, where $f_0$ and $\beta$ are assumed known, while $m^*$ and $\eta$ are assumed unknown. For the present project, we assume that $m_j^*(x) = \sum_{i=1}^k \eta_{ij} m_i(x)$ is a superposition of known, elementary functions of $x$, scaled by the parameters in question, $\eta$, though we expect this to generalize to cases where the form of $m^*$ is more complicated and we have to search over a set of basis functions, such as the spline functions that approximate well any function over the domain in question. Our goal is to learn the values of all the $\eta_{ij}$ through observing data generated by the perturbed system.

We should note here, in order to justify our referring to $m^*$ as a perturbation, that we will assume $||f_0|| \gg ||m^*||$.


\subsection{Sample Problems}

We mostly concern ourselves with two dynamical systems, which we perturb in known ways. We choose these two primarily because Fitzhugh-Nagumo is very well-behaved and should be easy to learn $\eta$ on, whereas Lorenz-63 is likely to be more difficult, due to its high sensitivity to changes in the model.


\subsubsection{Perturbed Fitzhugh-Nagumo System}

The Fitzhugh-Nagumo dynamical system is defined as follows:

\begin{align*}
  
\end{align}


\subsubsection{Perturbed Lorenz System}



\subsection{Backpropagation-Based Optimization}



\section{Methodologies Used}


\subsection{Other Things that We May Use for Error Quantification}



\section{Results}


\section{Future Directions}


\bibliographystyle{unsrt}
\nocite{*}
\bibliography{dynsys}


\end{document}
