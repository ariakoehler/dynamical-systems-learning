

@article{chkrebtii,
author = {Oksana A. Chkrebtii and David A. Campbell and Ben Calderhead and Mark A. Girolami},
title = {{Bayesian Solution Uncertainty Quantification for Differential Equations}},
volume = {11},
journal = {Bayesian Analysis},
number = {4},
publisher = {International Society for Bayesian Analysis},
pages = {1239 -- 1267},
keywords = {Bayesian numerical analysis, differential equation models, Gaussian processes, uncertainty in computer models, uncertainty quantification},
year = {2016},
doi = {10.1214/16-BA1017},
URL = {https://doi.org/10.1214/16-BA1017}
}


@article{cockayne,
author = {Cockayne, Jon and Oates, Chris J. and Sullivan, T. J. and Girolami, Mark},
title = {Bayesian Probabilistic Numerical Methods},
journal = {SIAM Review},
volume = {61},
number = {4},
pages = {756-789},
year = {2019},
doi = {10.1137/17M1139357},

URL = { 
        https://doi.org/10.1137/17M1139357
    
},
eprint = { 
        https://doi.org/10.1137/17M1139357
    
}
,
    abstract = { Over forty years ago average-case error was proposed in the applied mathematics literature as an alternative criterion with which to assess numerical methods. In contrast to worst-case error, this criterion relies on the construction of a probability measure over candidate numerical tasks, and numerical methods are assessed based on their average performance over those tasks with respect to the measure. This paper goes further and establishes Bayesian probabilistic numerical methods as solutions to certain inverse problems based upon the numerical task within the Bayesian framework. This allows us to establish general conditions under which Bayesian probabilistic numerical methods are well defined, encompassing both the nonlinear and non-Gaussian contexts. For general computation, a numerical approximation scheme is proposed and its asymptotic convergence established. The theoretical development is extended to pipelines of computation, wherein probabilistic numerical methods are composed to solve more challenging numerical tasks. The contribution highlights an important research frontier at the interface of numerical analysis and uncertainty quantification, and a challenging industrial application is presented. }
}


@article{gelman,
 ISSN = {01621459},
 URL = {http://www.jstor.org/stable/2291566},
 abstract = {We describe a general approach using Bayesian analysis for the estimation of parameters in physiological pharmacokinetic models. The chief statistical difficulty in estimation with these models is that any physiological model that is even approximately realistic will have a large number of parameters, often comparable to the number of observations in a typical pharmacokinetic experiment (e.g., 28 measurements and 15 parameters for each subject). In addition, the parameters are generally poorly identified, akin to the well-known ill-conditioned problem of estimating a mixture of declining exponentials. Our modeling includes (a) hierarchical population modeling, which allows partial pooling of information among different experimental subjects; (b) a pharmacokinetic model including compartments for well-perfused tissues, poorly perfused tissues, fat, and the liver; and (c) informative prior distributions for population parameters, which is possible because the parameters represent real physiological variables. We discuss how to estimate the models using Bayesian posterior simulation, a method that automatically includes the uncertainty inherent in estimating such a large number of parameters. We also discuss how to check model fit and sensitivity to the prior distribution using posterior predictive simulation. We illustrate the application to the toxicokinetics of tetrachloroethylene (perchloroethylene [PERC]), the problem that motivated this work.},
 author = {Andrew Gelman and Frederic Bois and Jiming Jiang},
 journal = {Journal of the American Statistical Association},
 number = {436},
 pages = {1400--1412},
 publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
 title = {Physiological Pharmacokinetic Analysis Using Population Modeling and Informative Prior Distributions},
 volume = {91},
 year = {1996}
}



@misc{levine,
      title={A Framework for Machine Learning of Model Error in Dynamical Systems}, 
      author={Matthew E. Levine and Andrew M. Stuart},
      year={2021},
      eprint={2107.06658},
      archivePrefix={arXiv},
      primaryClass={math.DS}
}


@article{ramsay,
author = {Ramsay, J. O. and Hooker, G. and Campbell, D. and Cao, J.},
title = {Parameter estimation for differential equations: a generalized smoothing approach},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
volume = {69},
number = {5},
pages = {741-796},
keywords = {Differential equation, Dynamic system, Estimating equation, Functional data analysis, Gauss, Newton method, Parameter cascade, Profiled estimation},
doi = {https://doi.org/10.1111/j.1467-9868.2007.00610.x},
url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.2007.00610.x},
eprint = {https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9868.2007.00610.x},
abstract = {Summary.  We propose a new method for estimating parameters in models that are defined by a system of non-linear differential equations. Such equations represent changes in system outputs by linking the behaviour of derivatives of a process to the behaviour of the process itself. Current methods for estimating parameters in differential equations from noisy data are computationally intensive and often poorly suited to the realization of statistical objectives such as inference and interval estimation. The paper describes a new method that uses noisy measurements on a subset of variables to estimate the parameters defining a system of non-linear differential equations. The approach is based on a modification of data smoothing methods along with a generalization of profiled estimation. We derive estimates and confidence intervals, and show that these have low bias and good coverage properties respectively for data that are simulated from models in chemical engineering and neurobiology. The performance of the method is demonstrated by using real world data from chemistry and from the progress of the autoimmune disease lupus.},
year = {2007}
}


@article{chung,
author = {Matthias Chung and Micka\"el Binois and Robert B. Gramacy and Johnathan M. Bardsley and David J. Moquin and Amanda P. Smith and Amber M. Smith},
title = {Parameter and Uncertainty Esitmation for Dynamical Systems Using Surrogate Staochastic Processes},
volume = {41},
journal = {SIAM Journal of Scientific Computing},
number = {4},
publisher = {Society for Industrial and Applied Mathematics},
pages = {A2212 -- A2238},
year = {2019},
doi = {10.1137/18M1213403},
}


@article{biggs,
title = {Automatic differentiation of algorithms},
journal = {Journal of Computational and Applied Mathematics},
volume = {124},
number = {1},
pages = {171-190},
year = {2000},
note = {Numerical Analysis 2000. Vol. IV: Optimization and Nonlinear Equations},
issn = {0377-0427},
doi = {https://doi.org/10.1016/S0377-0427(00)00422-2},
url = {https://www.sciencedirect.com/science/article/pii/S0377042700004222},
author = {Michael Bartholomew-Biggs and Steven Brown and Bruce Christianson and Laurence Dixon},
keywords = {Adjoint programming, Algorithm, Automatic differentiation, Checkpoints, Error analysis, Function approximation, Implicit equations, Interval analysis, Nonlinear optimization, Optimal control, Parallelism, Penalty functions, Program transformation, Variable momentum},
abstract = {We introduce the basic notions of automatic differentiation, describe some extensions which are of interest in the context of nonlinear optimization and give some illustrative examples.}
}


@article{vehtari,
author = {Aki Vehtari and Andrew Gelman and Daniel Simpson and Bob Carpenter and Paul-Christian Bürkner},
title = {{Rank-Normalization, Folding, and Localization: An Improved $\widehat{R}$ for Assessing Convergence of MCMC (with Discussion)}},
volume = {16},
journal = {Bayesian Analysis},
number = {2},
publisher = {International Society for Bayesian Analysis},
pages = {667 -- 718},
year = {2021},
doi = {10.1214/20-BA1221},
URL = {https://doi.org/10.1214/20-BA1221}
}
